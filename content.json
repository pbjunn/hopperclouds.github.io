{"meta":{"title":"聘宝研发","subtitle":"一群有追求的人","description":"做有趣的事","author":"聘宝研发","url":"http://hopperclouds.github.io"},"pages":[],"posts":[{"title":"Docker学习之路","slug":"Docker学习之路","date":"2016-10-10T12:00:00.000Z","updated":"2016-10-11T10:57:10.000Z","comments":true,"path":"2016/10/10/Docker学习之路/","link":"","permalink":"http://hopperclouds.github.io/2016/10/10/Docker学习之路/","excerpt":"作者：liudong Docker简介Docker是什么？Docker 是一个开源项目,Go 语言实现,遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。Docker 的基础是 Linux 容器（LXC）等技术。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。","text":"作者：liudong Docker简介Docker是什么？Docker 是一个开源项目,Go 语言实现,遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。Docker 的基础是 Linux 容器（LXC）等技术。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处，可见容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。 为什么要使用 Docker？首先，Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多。 其次，Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。 更快速的交付和部署开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 更高效的虚拟化Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 更轻松的迁移和扩展Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 更简单的管理使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Docker能做什么？Docker可以解决虚拟机能够解决的问题，同时也能够解决虚拟机由于资源要求过高而无法解决的问题。Docker能处理的事情包括：隔离应用依赖创建应用镜像并进行复制创建容易分发的即启即用的应用允许实例简单、快速地扩展测试应用并随后销毁它们 Docker背后的想法是创建软件程序可移植的轻量容器，让其可以在任何安装了Docker的机器上运行，而不用关心底层操作系统基本概念 Docker 镜像 （Image）镜像原理：Docker的镜像类似虚拟机的快照，但更轻量，非常非常轻量。Docker 使用 Union FS 将这些不同的层结合到一个镜像中去。通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个 disk 挂到同一个目录下,另一个更常用的就是将一个只读的分支和一个可写的分支联合在一起，Live CD 正是基于此方法可以允许在镜像不变的基础上允许用户在其上进行一些写操作；创建Docker镜像有几种方式，多数是在一个现有镜像基础上创建新镜像，因为几乎你需要的任何东西都有了公共镜像，包括所有主流Linux发行版，你应该不会找不到你需要的镜像。不过，就算你想从头构建一个镜像，也有好几种方法。要创建一个镜像，你可以拿一个镜像，对它进行修改来创建它的子镜像。实现前述目的的方式有两种：在一个文件中指定一个基础镜像及需要完成的修改；或通过“运行”一个镜像，对其进行修改并提交。不同方式各有优点，不过一般会使用文件来指定所做的变化。Docker 镜像（Image）就是一个只读的模板，可以用来创建 Docker 容器。 简单命令 （Ubuntu系统）安装Docker12$ sudo apt-get update$ wget -qO- https://get.docker.com/ | sh 注：系统会提示你输入sudo密码，输入完成之后，就会下载脚本并且安装Docker及依赖包。 Docker命令工具需要root权限才能工作。你可以将你的用户放入docker组来避免每次都要使用sudo。1$ sudo docker pull ubuntu:latest 列出docker镜像1$ sudo docker images 上传镜像1$ sudo docker push ouruser/sinatra 保存镜像1$ sudo docker save -o ubuntu_14.04.tar ubuntu:14.04 加载镜像1$ sudo docker load --input ubuntu_14.04.tar # 或者 sudo docker load &lt; ubuntu_14.04.tar 删除镜像12sudo docker rmi training/sinatra注：在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器. 清理所有未打过标签的本地镜像1$ sudo docker rmi $(docker images -q -f &quot;dangling=true&quot;) #sudo docker rmi $(docker images --quiet --filter &quot;dangling=true&quot;) Dockerfile创建镜像12345678910111213$ vim Dockerfile# This is a commentFROM ubuntu:14.04MAINTAINER Docker Newbee &lt;newbee@docker.com&gt;RUN apt-get -qq updateRUN apt-get -qqy install ruby ruby-devRUN gem install sinatra$ sudo docker build -t=&quot;ouruser/sinatra:v2&quot; .注：其中 -t 标记来添加 tag，指定新的镜像的用户信息。 “.” 是 Dockerfile 所在的路径（当前目录），也可以替换为一个具体的 Dockerfile 的路径。$ sudo docker run -t -i ouruser/sinatra:v2 /bin/bash 从本地文件系统导入1$ sudo cat ubuntu-14.04-x86_64-minimal.tar.gz |docker import - ubuntu:14.04 Docker 容器（Container）Docker 利用容器（Container）来运行应用。 容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 *注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。 新建并后台启动容器12$ sudo docker run -tid ubuntu:14.04 /bin/bash注：-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，-d 让容器进入后台运行. docker run 来创建容器时，Docker 在后台运行的标准操作包括：检查本地是否存在指定的镜像，不存在就从公有仓库下载利用镜像创建并启动一个容器分配一个文件系统，并在只读的镜像层外面挂载一层可读写层从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去从地址池配置一个 ip 地址给容器执行用户指定的应用程序执行完毕后容器被终止 查看docker容器1sudo docker ps 启动已经停止的容器1$ sudo docker start ubuntu:14.04 docker自带命令进入容器12$ sudo docker attach ubuntu #当退出容器后，容器会关闭$ docker exec -it ubuntu #进入已经开启的容器，退出后容器能继续运行 第三方工具进入容器123$ cd /tmp; curl https://www.kernel.org/pub/linux/utils/util-linux/v2.24/util-linux-2.24.tar.gz | tar -zxf-; cd util-linux-2.24;$ ./configure --without-ncurses$ make nsenter &amp;&amp; sudo cp nsenter /usr/local/bin 容器的第一个进程的 PID，可以通过下面的命令获取12$ PID=$(docker inspect --format &quot;&#123;&#123; .State.Pid &#125;&#125;&quot; &lt;container&gt;)$ nsenter --target $PID --mount --uts --ipc --net --pid 实例演示123456789$ sudo docker run -idt ubuntu243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES243c32535da7 ubuntu:latest &quot;/bin/bash&quot; 18 seconds ago Up 17 seconds nostalgic_hypatia$ PID=$(docker-pid 243c32535da7)10981$ sudo nsenter --target 10981 --mount --uts --ipc --net --pidroot@243c32535da7:/# 123456简单的方法是：下载 .bashrc_docker，并将内容放到 .bashrc 中。$ wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker;$ echo &quot;[ -f ~/.bashrc_docker ] &amp;&amp; . ~/.bashrc_docker&quot; &gt;&gt; ~/.bashrc; source ~/.bashrc$ echo $(docker-pid &lt;container&gt;)$ docker-enter &lt;container&gt; ls 获取容器日志1$ sudo docker logs ubuntu:14.04 导出容器1234$ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9c365aaa875f mysql &quot;docker-entrypoint.sh&quot; 9 days ago Exited 8 minutes ago 0.0.0.0:3308-&gt;3306/tcp mysql_3308$ sudo docker export 9c365aaa875f &gt; mysql.tar 导入容器快照12$ cat mysql.tar | sudo docker import - test/mysql:5.6$sudo docker import http://example.com/exampleimage.tgz example/imagerepo Docker 仓库（Repository）仓库（Repository）是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。 最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。*注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。 Dockerfile使用指令 指令的一般格式为 INSTRUCTION arguments，指令包括 FROM、MAINTAINER、RUN 等。 FROM格式为 FROM 或FROM :。 第一条指令必须为 FROM 指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个 FROM 指令（每个镜像一次）。 MAINTAINER格式为 MAINTAINER ，指定维护者信息。 RUN格式为 RUN 或 RUN [“executable”, “param1”, “param2”]。 前者将在 shell 终端中运行命令，即 /bin/sh -c；后者则使用 exec 执行。指定使用其它终端可以通过第二种方式实现，例如 RUN [“/bin/bash”, “-c”, “echo hello”]。 每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用 \\ 来换行。 CMD支持三种格式 CMD [“executable”,”param1”,”param2”] 使用 exec 执行，推荐方式；CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；CMD [“param1”,”param2”] 提供给 ENTRYPOINT 的默认参数；指定启动容器时执行的命令，每个 Dockerfile 只能有一条 CMD 命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时候指定了运行的命令，则会覆盖掉 CMD 指定的命令。 EXPOSE格式为 EXPOSE […]。 告诉 Docker 服务端容器暴露的端口号，供互联系统使用。在启动容器时需要通过 -P，Docker 主机会自动分配一个端口转发到指定的端口。 ENV格式为 ENV 。 指定一个环境变量，会被后续 RUN 指令使用，并在容器运行时保持。 例如 ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; …ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATHADD 格式为 ADD 。 该命令将复制指定的 到容器中的 。 其中 可以是Dockerfile所在目录的一个相对路径；也可以是一个 URL；还可以是一个 tar 文件（自动解压为目录）。 COPY格式为 COPY 。 复制本地主机的 （为 Dockerfile 所在目录的相对路径）到容器中的 。 当使用本地目录为源目录时，推荐使用 COPY。 ENTRYPOINT两种格式： ENTRYPOINT [“executable”, “param1”, “param2”]ENTRYPOINT command param1 param2（shell中执行）。配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 每个 Dockerfile 中只能有一个 ENTRYPOINT，当指定多个时，只有最后一个起效。 VOLUME格式为 VOLUME [“/data”]。 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。 USER格式为 USER daemon。 指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如：RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres。要临时获取管理员权限可以使用 gosu，而不推荐 sudo。 WORKDIR格式为 WORKDIR /path/to/workdir。 为后续的 RUN、CMD、ENTRYPOINT 指令配置工作目录。 可以使用多个 WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如 WORKDIR /aWORKDIR bWORKDIR cRUN pwd则最终路径为 /a/b/c。 ONBUILD格式为 ONBUILD [INSTRUCTION]。 配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。 例如，Dockerfile 使用如下的内容创建了镜像 image-A。 […]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build –dir /app/src[…]如果基于 image-A 创建新的镜像时，新的Dockerfile中使用 FROM image-A指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。 FROM image-A1234#Automatically run the followingADD . /app/srcRUN /usr/local/bin/python-build --dir /app/src注：使用 ONBUILD 指令的镜像，推荐在标签中注明 实例演示(dockerfile创建镜像，运行Django+uwsgi+nginx+supervisor)启动mysql容器12sudo docker run -d -e MYSQL_ROOT_PASSWORD=pinbot@123 --name mysql_3308 -v /data/mysql/data:/var/lib/mysql -p 3308:3306 mysql注：用mysql镜像后台启动容器，并设置root用户初始密码为谁pinbot123，挂载本地目录/data/mysql/data到容器mysql_3308 的/var/lib/mysql目录，映射本地3308端口到容器的3306端口 用Dockerfile创建镜像12sudo docker build -t talentbi:1.0 .注：根据Dockerfile创建镜像，并命名为talentbi:1.0； 后台启动容器12sudo docker run -d -p 8001:8080 -v /home/bigdata/github/TalentMiner/:/home/bigdata/github/TalentMiner --name talentbi1.0 talentbi:1.0注：用talentbi:1.0镜像启动容器并后台运行，映射本地端口8001到容器内8080端口，挂载本地目录等 进入容器1sudo docker exec -ti talentbi1.1 /bin/bash 端口映射1sudo iptables -t nat -A DOCKER -p tcp --dport 8080 -j DNAT --to-destination 172.17.0.3:8080 查看iptables列表1sudo iptables -t nat -nL","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://hopperclouds.github.io/tags/运维/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"JavaScript之设计模型(单例模式,构造函数模式)","slug":"JavaScript之设计模型(单例模式,构造函数模式)","date":"2016-10-10T06:08:08.000Z","updated":"2016-10-11T10:11:23.000Z","comments":true,"path":"2016/10/10/JavaScript之设计模型(单例模式,构造函数模式)/","link":"","permalink":"http://hopperclouds.github.io/2016/10/10/JavaScript之设计模型(单例模式,构造函数模式)/","excerpt":"作者: 李纯利 一、设计模型之单例模式单例模式就是保证一个类只有一个实例，实现的方法一般是先判断实例存在与否，如果存在直接返回，如果不存在就创建了再返回，这就确保了一个类只有一个实例对象。","text":"作者: 李纯利 一、设计模型之单例模式单例模式就是保证一个类只有一个实例，实现的方法一般是先判断实例存在与否，如果存在直接返回，如果不存在就创建了再返回，这就确保了一个类只有一个实例对象。下面我们来看一个单例的最佳实践： 二、设计模型之构造函数模式介绍：构造函数用于创建特定类型的对象——不仅声明了使用的对象，构造函数还可以接受参数以便第一次创建对象的时候设置对象的成员值。你可以自定义自己的构造函数，然后在里面声明自定义类型对象的属性或方法。 基本用法：JavaScript没有类的概念，但是有特殊的构造函数。通过new关键字来调用定义的否早函数，你可以告诉JavaScript你要创建一个新对象并且新对象的成员声明都是构造函数里定义的。在构造函数内部，this关键字引用的是新创建的对象。基本用法如下： 上面是一个非常简单的构造函数模式，但是使用继承就很麻烦了，而且output()在每次创建对象的时候都重新定义了，最好的方法是让所有Car类型的实例都共享这个output()方法，这样如果有大批量的实例的话，就会节约很多内存。解决方法如下： 这个方法虽然可用,但是我们还有更好的办法哟! 构造函数与原型JavaScript里函数有个原型属性叫prototype，当调用构造函数创建对象的时候，所有该构造函数原型的属性在新创建对象上都可用.下面来看一下上面扩展的代码: 这里，output()单实例可以在所有Car对象实例里共享使用。另外：我们推荐构造函数以大写字母开头，以便区分普通的函数。 强制使用new如果不是new来创建对象,直接用在全局调用函数的话,this指向的是全局对象window,下面来验证一下: 这个时候的tom是undefined,而window.output()会正确输出结果,而如果使用new关键字则没有这个问题,验证如下: 上述的例子展示了不使用new的问题，那么我们有没有办法让构造函数强制使用new关键字呢，答案是肯定的，上代码： 通过判断this的instanceof是不是Car来决定返回new Car还是继续执行代码，如果使用的是new关键字，则(this instanceof Car)为真，会继续执行下面的参数赋值，如果没有用new，(this instanceof Car)就为假，就会重新new一个实例返回。","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://hopperclouds.github.io/tags/JavaScript/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"react.js components的生命周期","slug":"react.js components的生命周期","date":"2016-10-09T16:00:00.000Z","updated":"2016-10-11T10:11:23.000Z","comments":true,"path":"2016/10/10/react.js components的生命周期/","link":"","permalink":"http://hopperclouds.github.io/2016/10/10/react.js components的生命周期/","excerpt":"react.js components的生命周期React提供了和以往不一样的方式来看待视图，它以组件开发为基础。组件是React的核心概念，React 允许将代码封装成组件（component），然后像插入普通 HTML 标签一样，在网页中插入这个组件。React.createClass 方法就用于生成一个组件类。对React应用而言，你需要分割你的页面，使其成为一个个的组件。也就是说，你的应用是由这些组件组合而成的。你可以通过分割组件的方式去开发复杂的页面或某个功能区块，组件是可以被复用的。 之前我们简单介绍了react的由来、特点、应用场景。以及，jsx语法糖，使用React.createClass生成自定义标签，插入节点，添加css样式，这些都是react的基础，接下来，我们继续react compenents的生命周期。","text":"react.js components的生命周期React提供了和以往不一样的方式来看待视图，它以组件开发为基础。组件是React的核心概念，React 允许将代码封装成组件（component），然后像插入普通 HTML 标签一样，在网页中插入这个组件。React.createClass 方法就用于生成一个组件类。对React应用而言，你需要分割你的页面，使其成为一个个的组件。也就是说，你的应用是由这些组件组合而成的。你可以通过分割组件的方式去开发复杂的页面或某个功能区块，组件是可以被复用的。 之前我们简单介绍了react的由来、特点、应用场景。以及，jsx语法糖，使用React.createClass生成自定义标签，插入节点，添加css样式，这些都是react的基础，接下来，我们继续react compenents的生命周期。组件的生命周期分成三个状态： Mounting：已插入真实 DOM，即Initial Render Updating：正在被重新渲染，即Props与State改变 Unmounting：已移出真实 DOM，即Component Unmount React 为每个状态都提供了两种处理函数，will 函数在进入状态之前调用，did 函数在进入状态之后调用，三种状态共计五种处理函数。 componentWillMount() componentDidMount() componentWillUpdate(object nextProps, object nextState) componentDidUpdate(object prevProps, object prevState) componentWillUnmount()此外，React 还提供两种特殊状态的处理函数。 componentWillReceiveProps(object nextProps)：已加载组件收到新的参数时调用 shouldComponentUpdate(object nextProps, object nextState)：组件判断是否重新渲染时调用 Mounting阶段： componentWillMount—render—componentDidMountUpdating阶段： componentWillReceiveProps—shouldCOmponentUpdate—componentWillUpdate—render—componentDidUpdateUnmounting阶段： coponentWillUnmount 一个完整的React Component的写法应该如下： var myComponent = React.createClass({ // The object returned by this method sets the initial value of this.state getInitialState: function(){ return {}; }, // The object returned by this method sets the initial value of this.props // If a complex object is returned, it is shared among all component instances getDefaultProps: function(){ return {}; }, // Returns the jsx markup for a component // Inspects this.state and this.props create the markup // Should never update this.state or this.props render: function(){ return (&lt;div&gt;&lt;/div&gt;); }, // An array of objects each of which can augment the lifecycle methods mixins: [], // Functions that can be invoked on the component without creating instances statics: { aStaticFunction: function(){} }, // -- Lifecycle Methods -- // Invoked once before first render componentWillMount: function(){ // Calling setState here does not cause a re-render }, // Invoked once after the first render componentDidMount: function(){ // You now have access to this.getDOMNode() }, // Invoked whenever there is a prop change // Called BEFORE render componentWillReceiveProps: function(nextProps){ // Not called for the initial render // Previous props can be accessed by this.props // Calling setState here does not trigger an an additional re-render }, // Determines if the render method should run in the subsequent step // Called BEFORE a render // Not called for the initial render shouldComponentUpdate: function(nextProps, nextState){ // If you want the render method to execute in the next step // return true, else return false return true; }, // Called IMMEDIATELY BEFORE a render componentWillUpdate: function(nextProps, nextState){ // You cannot use this.setState() in this method }, // Called IMMEDIATELY AFTER a render componentDidUpdate: function(prevProps, prevState){ }, // Called IMMEDIATELY before a component is unmounted componentWillUnmount: function(){ } });","categories":[{"name":"react","slug":"react","permalink":"http://hopperclouds.github.io/categories/react/"}],"tags":[{"name":"react","slug":"react","permalink":"http://hopperclouds.github.io/tags/react/"}],"keywords":[{"name":"react","slug":"react","permalink":"http://hopperclouds.github.io/categories/react/"}]},{"title":"NotImplemented","slug":"NotImplemented","date":"2016-10-09T08:00:00.000Z","updated":"2016-10-11T10:11:23.000Z","comments":true,"path":"2016/10/09/NotImplemented/","link":"","permalink":"http://hopperclouds.github.io/2016/10/09/NotImplemented/","excerpt":"在创建基类时常常会用到raise NotImplementedError这个语句, 但在写下这条语句时IDE可能会补全一个NotImplemented出来, NotImplemented是什么?","text":"在创建基类时常常会用到raise NotImplementedError这个语句, 但在写下这条语句时IDE可能会补全一个NotImplemented出来, NotImplemented是什么? NotImplemented是什么首先NotImplemented并不是一种异常, 而是Built-in的一种类型: 12&gt;&gt;&gt; type(NotImplemented)&lt;type 'NotImplementedType'&gt; 官方文档中是这么描述的: Special value which can be returned by the “rich comparison” special methods (__eq__(), __lt__(), and friends), to indicate that the comparison is not implemented with respect to the other type. NotImplemented的具体应用根据文档描述, NotImplemented常用在object.__eq__这样的比较方法中。 在下面的例子中, 比较Pants和Socks对象时, 首先会调用Pants的__eq__方法, 返回的是NotImplemented则转而调用Socks的__eq__方法。 使用NotImplemented而不是抛出异常, 给了其它对象扩展的机会。 12345678910111213141516171819class Entity(object): def __init__(self, size): self.size = sizeclass Pants(Entity): def __eq__(self, other): return NotImplementedclass Socks(Entity): def __eq__(self, other): if not isinstance(other, self.__class__): return False return self.size == other.sizeif __name__ == '__main__': print Pants(5) == Socks(5) 文末留一个小问题: 123class Foo(object): def __lt__(self, other): return NotImplemented Foo() &lt; Foo()有输出吗? 如果有, 是什么？","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://hopperclouds.github.io/tags/Python/"},{"name":"NotImplemented","slug":"NotImplemented","permalink":"http://hopperclouds.github.io/tags/NotImplemented/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"Nodejs ORM框架Sequelizejs快速入门","slug":"Nodejs-ORM框架Sequelizejs快速入门","date":"2016-09-12T15:10:10.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/09/12/Nodejs-ORM框架Sequelizejs快速入门/","link":"","permalink":"http://hopperclouds.github.io/2016/09/12/Nodejs-ORM框架Sequelizejs快速入门/","excerpt":"作者: Adam 什么是ORM？简单的讲就是对SQL查询语句的封装，让我们可以用OOP的方式操作数据库，优雅的生成安全、可维护的SQL代码。直观上，是一种Model和SQL的映射关系。","text":"作者: Adam 什么是ORM？简单的讲就是对SQL查询语句的封装，让我们可以用OOP的方式操作数据库，优雅的生成安全、可维护的SQL代码。直观上，是一种Model和SQL的映射关系。 12345678910111213141516const User = sequelize.define('user', &#123; id: &#123; type: Sequelize.INTEGER, allowNull: false, autoIncrement: true, primaryKey: true &#125;, email: &#123; type: Sequelize.STRING, allowNull: false, validate: &#123; isEmail: true &#125;, unique: true &#125;&#125;) 1234567CREATE TABLE IF NOT EXISTS `users` ( `id` INTEGER PRIMARY KEY AUTOINCREMENT, `email` VARCHAR(255) NOT NULL UNIQUE `createdAt` DATETIME NOT NULL, `updatedAt` DATETIME NOT NULL, UNIQUE (email)); 那么什么是Sequelize？Sequelize是一款基于Nodejs功能强大的异步ORM框架。同时支持PostgreSQL, MySQL, SQLite and MSSQL多种数据库，很适合作为Nodejs后端数据库的存储接口，为快速开发Nodejs应用奠定扎实、安全的基础。 既然Nodejs的强项在于异步，没有理由不找一个强大的支持异步的数据库框架，与之配合，双剑合并～ 123456789101112131415161718192021222324252627282930313233343536//引入框架var Sequelize = require('sequelize');//初始化链接（支持连接池）var sequelize = new Sequelize('database', 'username', 'password', &#123; host: 'localhost', dialect: 'mysql'|'sqlite'|'postgres'|'mssql', pool: &#123; max: 5, min: 0, idle: 10000 &#125;, // SQLite only storage: 'path/to/database.sqlite'&#125;);//定义数据模型var User = sequelize.define('user', &#123; username: Sequelize.STRING, birthday: Sequelize.DATE&#125;);//初始化数据sequelize.sync().then(function() &#123; return User.create(&#123; username: 'janedoe', birthday: new Date(1980, 6, 20) &#125;);&#125;).then(function(jane) &#123; //获取数据 console.log(jane.get(&#123; plain: true &#125;));&#125;).catch(function (err) &#123; //异常捕获 console.log('Unable to connect to the database:', err);&#125;); Sequelize有哪些特色？ 强大的模型定义，支持虚拟类型。Javascript虽然被很多人诟病杂乱无章法，但是函数即对象这个特色，可以说是我的最爱，非常灵活强大。 123456789101112131415var Foo = sequelize.define('foo', &#123; firstname: Sequelize.STRING, lastname: Sequelize.STRING&#125;, &#123; getterMethods : &#123; fullName : function() &#123; return this.firstname + ' ' + this.lastname &#125; &#125;, setterMethods : &#123; fullName : function(value) &#123; var names = value.split(' '); this.setDataValue('firstname', names.slice(0, -1).join(' ')); this.setDataValue('lastname', names.slice(-1).join(' ')); &#125;, &#125;&#125;); 支持完善的数据验证，减轻前后端的验证压力。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647var ValidateMe = sequelize.define('foo', &#123; foo: &#123; type: Sequelize.STRING, validate: &#123; is: [\"^[a-z]+$\",'i'], // 全匹配字母 is: /^[a-z]+$/i, // 全匹配字母，用规则表达式写法 not: [\"[a-z]\",'i'], // 不能包含字母 isEmail: true, // 检查邮件格式 isUrl: true, // 是否是合法网址 isIP: true, // 是否是合法IP地址 isIPv4: true, // 是否是合法IPv4地址 isIPv6: true, // 是否是合法IPv6地址 isAlpha: true, // 是否是字母 isAlphanumeric: true, // 是否是数字和字母 isNumeric: true, // 只允许数字 isInt: true, // 只允许整数 isFloat: true, // 是否是浮点数 isDecimal: true, // 是否是十进制书 isLowercase: true, // 是否是小写 isUppercase: true, // 是否大写 notNull: true, // 不允许为null isNull: true, // 是否是null notEmpty: true, // 不允许为空 equals: 'specific value', // 等于某些值 contains: 'foo', // 包含某些字符 notIn: [['foo', 'bar']], // 不在列表中 isIn: [['foo', 'bar']], // 在列表中 notContains: 'bar', // 不包含 len: [2,10], // 长度范围 isUUID: 4, // 是否是合法 uuids isDate: true, // 是否是有效日期 isAfter: \"2011-11-05\", // 是否晚于某个日期 isBefore: \"2011-11-05\", // 是否早于某个日期 max: 23, // 最大值 min: 23, // 最小值 isArray: true, // 是否是数组 isCreditCard: true, // 是否是有效信用卡号 // 自定义规则 isEven: function(value) &#123; if(parseInt(value) % 2 != 0) &#123; throw new Error('请输入偶数!') &#125; &#125; &#125; &#125;&#125;); Sequelize的查询非常全面和灵活 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Project.findAll(&#123; //复杂过滤，可嵌套 where: &#123; id: &#123; $and: &#123;a: 5&#125; // AND (a = 5) $or: [&#123;a: 5&#125;, &#123;a: 6&#125;] // (a = 5 OR a = 6) $gt: 6, // id &gt; 6 $gte: 6, // id &gt;= 6 $lt: 10, // id &lt; 10 $lte: 10, // id &lt;= 10 $ne: 20, // id != 20 $between: [6, 10], // BETWEEN 6 AND 10 $notBetween: [11, 15], // NOT BETWEEN 11 AND 15 $in: [1, 2], // IN [1, 2] $notIn: [1, 2], // NOT IN [1, 2] $like: '%hat', // LIKE '%hat' $notLike: '%hat' // NOT LIKE '%hat' $iLike: '%hat' // ILIKE '%hat' (case insensitive) (PG only) $notILike: '%hat' // NOT ILIKE '%hat' (PG only) $overlap: [1, 2] // &amp;&amp; [1, 2] (PG array overlap operator) $contains: [1, 2] // @&gt; [1, 2] (PG array contains operator) $contained: [1, 2] // &lt;@ [1, 2] (PG array contained by operator) $any: [2,3] // ANY ARRAY[2, 3]::INTEGER (PG only) &#125;, status: &#123; $not: false, // status NOT FALSE &#125; &#125;&#125;)Project.all()Project.findByIdProject.findByOneProject.findOrCreateProject.findAndCountAllProject.count()Project.max()//CRUDProject.create()Project.save()Project.update()Project.destroy()//批量User.bulkCreate([])//排序something.findOne(&#123; order: [ 'name', // 返回 `name` 'username DESC', // 返回 `username DESC` ['username', 'DESC'], // 返回 `username` DESC sequelize.fn('max', sequelize.col('age')), // 返回 max(`age`) [sequelize.fn('max', sequelize.col('age')), 'DESC'], // 返回 max(`age`) DESC [sequelize.fn('otherfunction', sequelize.col('col1'), 12, 'lalala'), 'DESC'], // 返回 otherfunction(`col1`, 12, 'lalala') DESC [sequelize.fn('otherfunction', sequelize.fn('awesomefunction', sequelize.col('col'))), 'DESC'] // 返回 otherfunction(awesomefunction(`col`)) DESC, 有可能是无限循环 [&#123; raw: 'otherfunction(awesomefunction(`col`))' &#125;, 'DESC'] // 也可以这样写 ]&#125;)// 分页查询Project.findAll(&#123; limit: 10 &#125;)Project.findAll(&#123; offset: 8 &#125;)Project.findAll(&#123; offset: 5, limit: 5 &#125;) 关联查询 include 支持嵌套，这可能是ORM里面最难的部分。 12345678910111213141516171819202122232425262728293031323334353637383940var User = sequelize.define('user', &#123; name: Sequelize.STRING &#125;) , Task = sequelize.define('task', &#123; name: Sequelize.STRING &#125;) , Tool = sequelize.define('tool', &#123; name: Sequelize.STRING &#125;)Task.belongsTo(User) // 增加外键属性 UserId 到 TaskUser.hasMany(Task) // 给 Task 增加外键属性 userIdUser.hasMany(Tool, &#123; as: 'Instruments' &#125;) // 给 Task 增加自定义外键属性 InstrumentsIdTask.findAll(&#123; include: [ User ] &#125;)User.findAll(&#123; include: [&#123; model: Tool, as: 'Instruments', where: &#123; name: &#123; $like: '%ooth%' &#125; &#125;&#125;] &#125;)User.findAll(&#123; include: ['Instruments'] &#125;)var User = this.sequelize.define('user', &#123;/* attributes */&#125;, &#123;underscored: true&#125;) , Company = this.sequelize.define('company', &#123; uuid: &#123; type: Sequelize.UUID, primaryKey: true &#125; &#125;);User.belongsTo(Company); // 增加 company_uuid 外键属性到 userUser.belongsTo(UserRole, &#123;as: 'role'&#125;);// 自定义外键属性 roleId 到 user 而不是 userRoleIdUser.belongsTo(Company, &#123;foreignKey: 'fk_companyname', targetKey: 'name'&#125;); // 增加自定义外键属性 fk_companyname 到 UserPerson.hasOne(Person, &#123;as: 'Father', foreignKey: 'DadId'&#125;)// Person 增加外键属性 DadIdCoach.hasOne(Team) // `coachId` 作为 Team 的外键属性Project.hasMany(User, &#123;as: 'Workers'&#125;)// 给 User 增加外键属性 projectId ／ project_idProject.belongsToMany(User, &#123;through: 'UserProject'&#125;);User.belongsToMany(Project, &#123;through: 'UserProject'&#125;);// 创建新的模型: UserProject 包含外键属性：projectId 和 userId Sequelize还有完善的迁移同步数据方案,migrate so easy。 12345678910//$ sequelize db:migrate //用命令直接生成模版脚本，接下来的还是写jsmodule.exports = &#123; up: function(queryInterface, Sequelize) &#123; // 需要修改数据库的操作 &#125;, down: function(queryInterface, Sequelize) &#123; // 取消修改的操作 &#125;&#125; 好的，快餐吃到这里，希望大家喜欢nodejs，能够快速开发Node App～","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"ORM","slug":"ORM","permalink":"http://hopperclouds.github.io/tags/ORM/"},{"name":"Nodejs","slug":"Nodejs","permalink":"http://hopperclouds.github.io/tags/Nodejs/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"OpenVPN服务部署使用","slug":"OpenVPN服务部署使用","date":"2016-09-08T12:00:00.000Z","updated":"2016-10-11T11:00:59.000Z","comments":true,"path":"2016/09/08/OpenVPN服务部署使用/","link":"","permalink":"http://hopperclouds.github.io/2016/09/08/OpenVPN服务部署使用/","excerpt":"作者：liudong at 2016-09-08 20:00:00 OpenVPN服务部署使用 1 服务端部署（Ubuntu）1.1 安装OpenVPN 所需插件1234$ sudo apt-get install openssl$ sudo apt-get install libssl-dev$ sudo apt-get install libpam0g-dev$ sudo apt-get install liblzo2-dev","text":"作者：liudong at 2016-09-08 20:00:00 OpenVPN服务部署使用 1 服务端部署（Ubuntu）1.1 安装OpenVPN 所需插件1234$ sudo apt-get install openssl$ sudo apt-get install libssl-dev$ sudo apt-get install libpam0g-dev$ sudo apt-get install liblzo2-dev 1.2 安装OpenVPN注:以下安装方式任选一种,推荐apt-get方式安装 1.2.1 apt-get安装OpenVPN123$apt-get install openvpn$cd /etc/openvpn$mkdir conf log 1.2.2 源码安装OpenVPN（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 1.3 开启内核转发并配置源地址路由12$ echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward $ iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE 1.4 服务端配置1.4.1 生成密钥123456789$ cd openvpn-2.2.2/easy-rsa/2.0 $ source ./vars # 在此之前，可以修改vars文件对国家省份等修改;配置dh的位数(默认是1024，可以改成export KEY_SIZE=2048)和下文生成的dh2048.pem相对应$ ./clean-all $ ./build-ca $ ./build-key-server server # 产生服务器证书，此处的server是文件名参数，可以任意修改。$ ./build-key-pass client1 # 生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码$ ./build-dh # 产生Diffie Hellman参数至此一个客户端所需的证书已经完毕，都在easy-rsa/2.0/keys文件夹下面，其中ca.crt server.crt server.csr server.key dh1024.pem是服务端所需证书文件，ca.crt ca.key client1.crt client1.csr client1.key是客户端所需证书文件。注：可以继续使用./build-key产生更多客户端证书,一个客户端证书只能同时用于一个客户端连接。 1.4.2 服务端配目录及文件123$ cd openvpn &amp;&amp; mkdir conf # openvpn就是第2步中openvpn的安装目录 $ cp openvpn-2.2.2/sample-config-files/server.conf conf/$ cp openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,server.crt,server.csr,server.key,dh1024.pem&#125; conf/ # 拷贝openvpn-2.2.2/easy-rsa/2.0/keys/下的相关证书文件到openvpn/conf/目录下，注意:2048位的key则是dh2048.pem; 1024位的key则是dh1024.pem 1.4.3 服务端配置文件参数指定123456789101112131415161718192021$ vim conf/server.confdev tapproto tcpport 1194ca /path/to/openvpn/conf/ca.crtcert /path/to/openvpn/conf/server.crtkey /path/to/openvpn/conf/server.keydh /path/to/openvpn/conf/dh1024.pemuser nobodygroup nogroupserver 10.8.0.0 255.255.255.0 # 分配给clinet的ip段second time periodkeepalive 10 120 # 每10秒ping一次，120秒内客户端没有动作就断开连接persist-keypersist-tunverb 4log-append /path/to/openvpn/log/openvpn.logstatus /path/to/openvpn/log/openvpn-status.logclient-to-clientcrl-verify /path/to/openvpn/conf/crl.pem # 客户端证书连接限制comp-lzo 1.5 启动OpenVPN服务端1sudo /path/to/openvpn/sbin/openvpn --config /path/to/openvpn/conf/server.conf --daemon 1.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.1 inet 10.8.0.1 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.1 则说明VPN服务端配置成功 1.7 设置OpenVPN服务端开机启动123$ vim /etc/rc.localiptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE/path/to/openvpn/sbin/openvpn --config /path/to/openvpn/conf/server.conf --daemon 2 OpenVPN 客户端部署(MAC系统)2.1 安装OpenVPN 所需插件1$ sudo brew install openssl 2.2 安装OpenVPN注:以下安装方式任选一种,推荐Brew方式安装 2.2.1 Brew 安装12345直接brew安装(推荐)$brew install openvpn$cd /usr/local/Cellar/openvpn/2.3.11_1$mkdir conf log$ln -s /usr/local/Cellar/openvpn/2.3.11_1/sbin/openvpn /usr/local/bin/openvpn 2.2.2 源码安装（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 2.3 服务端生成客户端所需密钥(客户端部署可忽略此步骤)2.3.1 服务端连接1234服务端所在机器：xxx.xxx.xxx.xxx $ssh root@xxx.xxx.xxx.xxx #连接方式$cd /media/openvpn/ 服务端所在路径$cd /media/openvpn-2.2.2/easy-rsa/2.0 生成密钥所需路径 2.3.2 生成密钥12$ source ./vars $ ./build-key-pass client-A #此处设置密码为：openvpn123 注：生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码1$ ./build-dh 2.3.3设置客户端密钥验证信息12$ vim /media/openvpn/conf/ccd/client-A ifconfig-push 10.8.0.119 255.255.255.0 注：此处的验证信息文件名需要和生成密钥时输入的名字保持一致;10.8.0.119 指客户端被虚拟出来的IP 2.4 客户端配置2.4.1 拷贝密钥到客户端12$scp root@xxx.xxx.xxx.xxx:/media/openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,ca.key,client-A.crt,client-A.csr,client-A.key&#125; /usr/local/Cellar/openvpn/2.3.11_1/conf/注:密钥可以由维护人员发放,联系刘东; 2.4.2 配置客户端密码文件12$ vim /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt openvpn123 注:客户端密码文件和服务端生成密钥时输入的密码一致 2.4.3 客户端配置文件1234567891011121314151617181920212223$ vim /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf client dev tap proto tcp remote xxx.xxx.xxx.xxx 1194 #指定服务端外网IP及端口nobind user nobody group nogroup ca /usr/local/Cellar/openvpn/2.3.11_1/conf/ca.crt cert /usr/local/Cellar/openvpn/2.3.11_1/conf/client-A.crt key /usr/local/Cellar/openvpn/2.3.11_1/conf/client-A.key ping 15 ping-restart 45 ping-timer-rem persist-key persist-tun ns-cert-type server comp-lzo verb 4 log-append /usr/local/Cellar/openvpn/2.3.11_1/log/openvpn.log status /usr/local/Cellar/openvpn/2.3.11_1/log/openvpn-status.log tcp-queue-limit 4096 # 256 bcast-buffers 4096 2.5 启动客户端2.5.1 命令行启动OpenVPN1$ sudo /usr/local/bin/openvpn --config /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf --askpass /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt --daemon 2.5.2 GUI启动OpenVPN 下载Tunnelblick客户端直接官网下载: https://tunnelblick.net/downloads.html 安装Tunnelblick客户端Tunnelblick具体安装使用流程见：Mac系统Tunnelblick下载以及安装流程 2.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.119 inet 10.8.0.119 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.x 则说明VPN客户端配置成功1$ ping 10.8.0.1 #检查是否能ping通内网等机器 2.7 服务加入开机自启动12vim /etc/rc.local/usr/local/bin/openvpn --config /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf --askpass /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt --daemon 3 OpenVPN 客户端部署(Ubuntu系统)3.1 安装OpenVPN 所需插件1234$ sudo apt-get install openssl$ sudo apt-get install libssl-dev$ sudo apt-get install libpam0g-dev$ sudo apt-get install liblzo2-dev 3.2 安装OpenVPN注:以下安装方式任选一种,推荐apt-get方式安装 3.2.1 apt-get安装OpenVPN123$apt-get install openvpn$cd /etc/openvpn$mkdir conf log 3.2.2 源码安装OpenVPN（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 3.3 服务端生成客户端所需密钥(客户端部署可忽略此步骤)3.3.1 服务端连接1234服务端所在机器：xxx.xxx.xxx.xxx $ssh root@xxx.xxx.xxx.xxx #连接方式$cd /media/openvpn/ 服务端所在路径$cd /media/openvpn-2.2.2/easy-rsa/2.0 生成密钥所需路径 3.3.2 生成密钥12$ source ./vars $ ./build-key-pass client-B #此处设置密码为：openvpn123 注：生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码1$ ./build-dh 3.3.3设置客户端密钥验证信息12$ vim /media/openvpn/conf/ccd/client-B ifconfig-push 10.8.0.120 255.255.255.0 注：此处的验证信息文件名需要和生成密钥时输入的名字保持一致;10.8.0.120 指客户端被虚拟出来的IP 3.4 客户端配置3.4.1 拷贝密钥到客户端12$scp root@xxx.xxx.xxx.xxx:/media/openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,ca.key,client-B.crt,client-B.csr,client-B.key&#125; /etc/openvpn/conf注:密钥可以由维护人员发放,联系刘东; 3.4.2 配置客户端密码文件12$ vim /etc/openvpn/conf/password.txt openvpn123 注:客户端密码文件和服务端生成密钥时输入的密码一致 3.4.3 客户端配置文件12345678910111213141516171819202122232425262728$ vim /etc/openvpn/conf/client.conf client dev tap proto tcp remote xxx.xxx.xxx.xxx 1194 #指定服务端外网IP及端口nobind user nobody group nogroup ca /etc/openvpn/conf/ca.crt cert /etc/openvpn/conf/client-B.crt key /etc/openvpn/conf/client-B.key ping 15 ping-restart 45 ping-timer-rem persist-key persist-tun ns-cert-type server comp-lzo verb 4 log-append /etc/openvpn/log/openvpn.log status /etc/openvpn/log/openvpn-status.log tcp-queue-limit 4096 # 256 bcast-buffers 4096 3.5 启动客户端1$ sudo openvpn --config /etc/openvpn/conf/client.conf --askpass /etc/openvpn/conf/password.txt --daemon 3.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.120 inet 10.8.0.120 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.x 则说明VPN客户端配置成功1$ ping 10.8.0.1 #检查是否能ping通内网等机器 3.7 服务加入开机自启动12vim /etc/rc.localopenvpn --config /etc/openvpn/conf/client.conf --askpass /etc/openvpn/conf/password.txt --daemon","categories":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://hopperclouds.github.io/tags/运维/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}]},{"title":"django自定义storage","slug":"django自定义storage","date":"2016-09-08T11:31:22.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/09/08/django自定义storage/","link":"","permalink":"http://hopperclouds.github.io/2016/09/08/django自定义storage/","excerpt":"最近遇到了这样的一个问题，由于某些原因，需要把静态文件放到cdn上，之前使用的是django默认的storage（FileSystemStorage）。于是这里需要自定义storage。第一次写storage，过程中遇到一些坑，记录下来。","text":"最近遇到了这样的一个问题，由于某些原因，需要把静态文件放到cdn上，之前使用的是django默认的storage（FileSystemStorage）。于是这里需要自定义storage。第一次写storage，过程中遇到一些坑，记录下来。 什么是storage其实这个玩意要我说明白，好像有点难，于是我就按我的方法说，如果有错，谢谢指正！首先，我们的web中使用了许多的模版文件，静态文件，如js,css，图片这些，我们在配置服务器的时候，让nginx对请求进行分发，将动态请求分发给uWSGI，将静态文件交由nginx处理，这里nginx将从文件系统中读取静态资源，这里的文件系统就是我们当前的storage。但是这里我们是想用cdn，于是我们这里的静态资源不在从服务器上加载，而是从我们的cdn服务提供商那里加载，这里我们又有一个问题了，cdn服务提供商怎么给出正确的资源，于是我们就需要自己来写一个storage，将原来的文件系统更换为cdn提供商的空间。 storage的结构和重写这里就需要参考django的官方文档了(原版,翻译版)，由于我的外语水平不是很好，做的时候为了图效率，就没有花时间去琢磨英文官方文档，所以这里给一个翻译的文档地址，当然，如果你能很快看明白官方的文档，那去读原版是更好的选择。首先，我们看文件系统的基类，其源码位于django/core/files/storage.py文件下。这里我就不贴它的代码了，如果需要查看结构，请自行到该文件下查看！从文档中，我们可以了解的一些东西，这个类的子类需要不带参数实例化，于是我们需要在settings中加入自定义的参数。1234567891011STATICFILES_STORAGE = 'project.storage.CustomStorage'CUSTOM_STORAGE_OPTIONS = &#123; 'AccessKeyId': 'your_accesskeyid', 'AccessKeySecret': 'your_accesskeyidsecret', 'endpoint': 'oss-cn-hangzhou.aliyuncs.com', 'oss_url': 'http://oss-cn-hangzhou.aliyuncs.com', 'bucketname': 'your_bucketname',&#125;COMPRESS_STORAGE = 'project.storage.CustomCompressorFileStorage'STATIC_URL = 'your_cdn_prefix_address' 参数说明： 这里我们指定了STATICFILES_STORAGE为我们自定义的CustomStorage,如果不指定，那么系统将会使用默认的FileSystemStorage CUSTOM_STORAGE_OPTIONS是一个你自定义的Storage初始化参数，这里我用字典来初始化，当然，你可以使用你觉得合理的任何数据类型。 COMPRESS_STORAGE是我们指定的压缩文件的存放位置，与STATICFILES_STORAGE同理。 STATIC_URL这个就是静态文件的路由前缀，例如你的文件系统中路径是’aa/bb.js’，你的cdn地址是’static.cdn.com’，这里就使用cdn地址作为你的STATIC_URL 从文档中，我们可以知道，自定义的storage，必须实现_open,_save两个方法，我们参考源码可以知道，这两个方法分别被save和open两个方法调用，而这两个方法的作用分别是‘打开文件，读取内容’、‘将文件保存到指定的位置’，由此，我们需要自己定义的存储就在这里来实现。由于这里我采用的是阿里云的oss，所以认证的过程，我们放在构造函数中完成，本着D.R.Y的原则，为了让多个自定义的storage可以使用，我们将它放在外部，只在构造函数里来使用它。123456789101112131415def authticate(option): auth = oss2.Auth( option.get('AccessKeyId'), option.get('AccessKeySecret') ) service = oss2.Service( auth, option.get('endpoint') ) bucket = oss2.Bucket( auth, option.get('oss_url'), option.get('bucketname') )return (auth, service, bucket) 认证过后，就可以重写save过程了。123456def _save(self, name, content): self.bucket.put_object( name, content ) return name 这里我们使用的是阿里云的oss，它的save就这么简单。文档可以直接google阿里云oss！这里就不贴出来了！哈哈，这里是不是很简单！其实理解了它的各个方法，真的很简单…………继续，由于open方法是打开本地文件系统的文件，我们就不重写它了。其他的方法。文档中说到，delete()，exists()，listdir()，size()，url() 这几个方法都需要被覆写，不然就会抛出NotImplementedError异常。这里我们通过源码可以解释一下，这些玩意在干嘛。 delete方法：顾名思义，就是删除，此方法被调用时，从storage中删除文件 exists方法：额，还是顾名思义，就是判断是否存在该文件，返回布尔值 listdir方法：返回文件列表 size方法：返回文件大小 url方法：这个方法需要提一下，我在之前重写的时候，直接pass了，所以，我在打开xadmin时，就会一直报错，于是我就找了很久的原因，我在这个函数中下了断点，最后发现，这个函数是必须自己重新写的（如果你的文件是静态文件，可以通过url访问的话）。因为如果不重写它，返回的是一个None，于是该文件就没有url可以访问，在某些需要判断的地方，也会报错！ 最后不同的云服务提供商的上传方式可能不一样，但是原理都是一样的，重写save方法，改为上传到云端，重写需要使用的方法。最后collectstatic,compress即可。","categories":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/tags/django/"},{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/tags/技术/"}],"keywords":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/categories/django/"}]},{"title":"从程序员到架构师的成长之路","slug":"从程序员到架构师的成长之路","date":"2016-09-07T06:08:21.000Z","updated":"2016-09-27T17:35:55.000Z","comments":true,"path":"2016/09/07/从程序员到架构师的成长之路/","link":"","permalink":"http://hopperclouds.github.io/2016/09/07/从程序员到架构师的成长之路/","excerpt":"作者: likaiguo 从程序员到架构师的成长之路 课程大纲 程序员的技术发展道路和职业规划 提升代码质量和开发效率的方法 什么是适合业务发展的好架构? 架构师日常工作,享受什么样的苦与乐?","text":"作者: likaiguo 从程序员到架构师的成长之路 课程大纲 程序员的技术发展道路和职业规划 提升代码质量和开发效率的方法 什么是适合业务发展的好架构? 架构师日常工作,享受什么样的苦与乐? 讲师简介李开国 对系统架构设计有深入理解 专注机器学习和自然语言处理 某互联网创业公司技术总监 前腾讯QQ离线数据挖掘工程师 OneAPM公开课:《推荐系统架构演进》讲师 趋势科技Big Data创意程序大赛中国区亚军,国际季军 中科大硕士研究生 weixin: likaiguoweibo : http://weibo.com/likaiguo 课程大纲 程序员的技术发展道路和职业规划 提升代码质量和开发效率的方法 什么是适合业务发展的好架构? 架构师日常工作,享受什么样的苦与乐? 一.程序员的技术发展道路和职业规划 明确入行的目的 冲着“收入高”这一点 对技术充满热爱 有改变世界的冲动 技术发展规划 软件业人才结构 程序员是技术相关的职业生涯一个不错的开始，不论你以后是要做CTO还是总监等等，只要你还做着技术大家庭中的一员，那现在的技术沉淀，都将是你未来的基石。 主要技术类岗位 选择合适的工具 语言只不过是一个工具，“与其分散进攻，不如全力一击”万变不离其宗 面向过程 面向对象 函数式编程 明确发展方向做啥??? 职业规划最关键的一点: 你的梦想(理想)是什么? O(∩_∩)O哈哈~ 角色发展路线 不仅仅是coder抽取《软技能：代码之外的生存之道》 程序员来源专业: 科班计算机/软件工程类专业; 自动化,通信,信息科学类计算机相关专业; 生物相关理科专业; 文科类专业; 大致分为以下几类: 专业科班相关专业人员半路出家基于兴趣 职位跳转图谱:软件工程师 职位跳转图谱:架构师 职业通道的路线一览 可能与有些公司的职位不符，毕竟公司不一样，规模和起名的习惯可能不一样，但是大体上是这么个路子。不要太拘泥于职位名称。 程序员职业发展路径程序员工作两三年后，基本上都会考虑自己的未来发展方向。发展的路径主要有以下三种： 程序员–系统分析员–架构师–技术经理(Team Leader)–&gt;(技术总监)–CTO； 程序员–&gt;高级工程师–&gt;资深工程师–&gt;技术专家–&gt;CTO; 程序员–项目组长–项目经理–项目总监–CTO； 程序员–&gt;产品经理–&gt;产品总监–&gt;CTO; 现在还多了另一条路，创业（创业合伙人）。现在技术创业的越来越多，大有流行趋势。 （虽然都是CTO，主要的关注点和方向上有些不一样） 不管是项目经理还是技术经理与产品经理，都要求要熟悉业务，业务是需求的来源，没有不谈业务的技术，所以不管你从哪个方向发展，都要求对业务熟悉。 产品经理要求对业务最熟悉，项目经理次之，技术经理排最后。对于程序员来说，刚开始工作的前几年可以埋头扎到技术里面，一般这个时间在2-3年的时间，然后就应该多关注业务了。 分享8年开发经验，浅谈程序员职业规划程序员的职业发展道路 从技术向业务过渡 从程序员向技术管理发展 单方面向技术发展 浅谈程序猿的职业规划，看你如何决定自己的未来吧 程序员职业发展路径开发工程师：这个大家是最熟悉的，这个角色主要负责系统中某个模块或某个功能的设计与编码，有时候还会有数据库设计的工作等等。 研发经理：主要负责项目的技术选型，技术难题的攻克，技术人员的招聘，团队成员的技术培训与熏陶等一系列与技术相关的工作。 项目经理：主要负责项目进度的规划、跟进、落实、交付以及与客户的沟通等任务，是一个项目的监督者与管理者。 小组讨论:IT行业是吃青春饭??? 程序员工作只能做到35岁吗？之后的路是怎么走的呢? 软件工程师年龄分布 高级软件工程师年龄分布 系统架构师年龄分布 IT行业是吃青春饭???关于年龄的传说: 你看的是五年前的文章吧，现在的主流说法是40岁。五年前是35岁，我大学那会儿是30岁。时代是不断发展的。 我二十二的时候，他们说程序员只能干到25 。我二十五的时候，他们说程序员只能干到27 。我三十的时候，他们说程序员只能干到 35 。我现在三十七了。我觉得再干三十年毫无压力。 编程不是青春饭，技术才是硬通货。写程序可以说像盖房子，又不能说就是盖房子。第一，盖房子要绝对的体力，人年纪越大，越吃力。写程序不一样，体力只是一部分，最重要的是智慧，同样的一个模块，你去看senior和刚毕业的小豆包们，绝对不一样。第二，程序员，与其说软件工程师，是要求有完整的思维的，同样是计算机毕业的软件系的同学，北大青鸟和MIT的肯定不一样，所以知识和思维才是软件工程的核心~第三，任何行业都会是优胜劣汰的~时间只是催化剂 成功无所谓年纪如果你仍有斗志，上天就只能让你失踪于海难，让你出车祸，让你死于滑翔伞事故，让你得阿兹海默氏症，或者诸如此类的方式，才能无耻的战胜你。 年纪大了、有家庭了、有小孩了，放不开手脚了。这个「现实」可不仅是程序员需要面对的，是所有人都需要面对的。 心态 真的太重要。 成功无所谓年纪: 你周围的人 国内外牛人各大公司的技术专家?计算机语言的设计者? 二.提升代码质量和开发效率的方法 第一原则: DRYDon’t repeat youself!!! 1.代码质量保证代码质量最简单的方法: 这个代码会给其他人review! 团队代码规范 代码review 单元测试与集成测试 功能测试与性能测试 规范的需求和设计文档 拥抱开源 阅读github上star或fork数高的代码 向开源社区提交代码 遵循开源社区的代码规范 celery对贡献者要求 Community Code of Conduct(社区行为准则) Be considerate(为别人着想) -&gt; 首先为人写程序,其次为机器 Be respectful(尊重) Be collaborative(合作) When you disagree, consult others(异见时询问他人) When you’re unsure, ask for help(不确定时,寻求帮助) Step down considerately(稳定的交接任务) 找到合适的导师(尤达)向周围的人求教 没有天才 &lt;极客与团队&gt; 最直接的方式找认识的人,特别是团队中. 找到合适导师: 书籍《代码整洁之道》《代码大全》《重构 改善既有代码的设计》 计划一年要读书的数量 StackOverflow讨论帖:哪本最具影响力的书，是每个程序员都应该读的 59本 [^books] 找到合适导师: 公开课/MOOCMOOC（Massive Open Online Courses） 国外平台:The Best MOOC Provider: A Review of Coursera, Udacity and Edx coursera https://www.coursera.org edx https://www.edx.org/ 优达学城 (Udacity) https://www.udacity.com/ 国内平台 网易公开课 http://open.163.com/ 慕课网 http://www.imooc.com/ 麦子学院 http://www.maiziedu.com/ 北京大学的公开课平台 http://mooc.pku.edu.cn/ 学堂在线 https://www.xuetangx.com/ 推荐: 在Coursera，随时都是学习的好时候–微软亚洲研究院副院长 张峥 文档 产品设计文档 软件设计文档 测试用例文档 项目部署文档 为什么需要有正式的文档? 重构: 改善既有代码的设计重构：在不改变软件可观察行为的前提下改善其内部设计 为何重构： 重构改进软件设计,提高软件质量 重构软件更容易理解,提升可读性 重构帮助找到bug,减少错误 重构提高编程速度,阻止系统腐烂变质 书: 《重构 改善既有代码的设计》 重构: 代码的坏味道 重复代码 过长函数 过大的类 过长参数列 发散式变化：类经常因为不同的原因在不同的方向上发生变化 霰弹式修改：每遇到某种变化，你都必须在许多不同的类内做出许多小修改 依恋情结：一个类的动作过分依赖其他类 数据泥团：不同地方的相同数据字段 基本类型偏执 Switch 惊悚现身：考虑用多态代替 switch 重构: 代码的坏味道 平行继承体系：为某个类增加一个子类的时候，也必须为另一个类相应增加一个子类冗赘类 夸夸其谈未来性：某个抽象类其实没啥太大作用 令人迷惑的暂时字段 过度耦合的消息链 中间人：某个类接口有一半的函数都委托给其他类 狎昵关系：两个类过于亲密 异曲同工的类：两个函数做同一件事，却有着不同的签名 不完美的库类 纯稚的数据类：单纯的数据容器 被拒绝的遗赠：子类复用超类的行为，却又不愿意支持超类的接口 过多的注释：当你感觉需要撰写注释时，请先尝试重构，试着让所有注释都变得多余 构筑测试体系测试 确保所有测试都完全自动化，让它们检查自己的测试结果 一套测试就是一个强大的 bug 侦测器，能够大大缩减查找 bug 所需要的时间 频繁地运行测试。每次编译请把测试也考虑进去——每天至少执行每个测试一次 每当你收到 bug 报告，请先写一个单元测试来暴露 bug 编写未臻完善的测试并实际运行，好过对完美测试的无尽等待 考虑可能出错的边界条件，把测试火力集中在那儿 当事情被认为应该会出错时，别忘了检查是否抛出了预期的异常 不要因为测试无法捕捉所有 bug 就不写测试，因为测试的确可以捕捉到大多数 bug 浅谈代码覆盖率有赞分层自动化测试实践敏捷开发中高质量 Java 代码开发实践写出高质量代码的10个Tips 2.开发效率效率 就是工作量除以时间。提高效率需要从这两方面着手，一是增大工作量，二是缩短工作时间。 【如何提升工作效率】1、列出具体行动和细分目标，把待办清单画成流程图；2、给每项清单任务附上优先度；3、定时轮换任务调动积极性，花1小时在重要任务上，然后换着做一项容易而优先度较低的任务；4、保持对重要任务的关注度，正在做一件事，却不时想着另外一个事，请把那件事记下来，忙完后再去做。 问:程序员上班有什么提高效率技巧？ 断网!O(∩_∩)O哈哈~(Just a joke!) 其他回答打开音乐播放器，戴上耳机，少刷sns；有条件拔掉网线，无条件关掉浏览器\\QQ，手机静音，暂时无视所有产品经理和设计师。 一切源于专注 专注并且避免重复. DRY(Don’t repeat youself!!!)原则. 首先你得设置一个小目标. O(∩_∩)O! 如何专注? 方法: 番茄工作法 设置有优先级的任务列表(Todo List) 工具: 番茄土豆 关掉微信,QQ,邮件提醒;统一的时间,集中回复; 设置可量化的目标 代码行数 文档数量 commit,bugfix数量 代码覆盖率 nose,CI 设置Deadline 美国的”自然科学基金委”(NSF)发现最近申请各种资金的科学项目提案太多了，审都审不过来，怎么办呢？结果他们发现最好的解决办法就是。。。不设置申请的截止日期 (deadline)，总的提案数量自然减半； O(∩_∩)O!!! 保持对deadline的敬畏 一鼓作气,再而衰,三而竭 我们要多线程么?为什么多任务并行一般都很糟? 不停的上下文切换带来过多消耗 什么任务适合 进行多线程/多进程 并行 例如: 跑步时候听听音乐;写程序时候听舒展的音乐 写作时候看电视??? 例子: 开车时候换挡/巡航模式 函数堆栈 好记性不如烂笔头书写 记云笔记，特别是费好大劲整理出来的资料。轻而易举就能拿到的资料没必要花时间记，利用搜索引擎即可。 桌上放一本白色草稿纸和笔，你随时需要利用图表捋顺思路。 思维导图: 捋顺思路后不妨花点时间整理成思维导图，下次看5秒的效果相当于花5分钟重整思路。 markdown让书写更美好 语法简洁 专注于内容 不去担心样式 纯文本便于版本管理 markdown使用举例: 文档书写: 强大的插件支持 书写博客: hexo等 PPT: landslide 论文: pandoc+latex 责任心 对自己负责: 对自己的承诺负责 自驱力: 自我驱动 外部问责 找到你的Time Killer找到最大的时间杀手 找到最花费时间的地方; 找到自己的节奏: 什么时间段工作效率最高; 分配好工作内和工作外; 跟踪你的时间; 是不是在: SNS 查看碎片信息: weibo,weixin,qq 看电视上花费高昂? 形成习惯行为 惯例 习惯 成就我们的恰恰是那些不断重复做的事情.因此,优秀不是一种行为,而是一种习惯. – 亚里士多德 要培养工作习惯，并且要让其他人理解尊重你的工作习惯，你知道总被人打断的碎片化编程时间会杀了你 了解习惯 习惯: 暗示,惯例,奖励 找出坏习惯 打开电脑后,查看email,各种QQ,微信,刷网页 形成新习惯 集中处理碎片任务 不加班，晚上早点睡觉，保持作息规律 工作时间设立小的计划 快速解决coding中遇到的问题 官方文档 Google(如果是技术问题避开百度吧!) Github Stackoverflow 源码 对新技术充满热情 愿意使用新东西(慎重用于生产) 爱折腾 不要重复造轮子 社会化编程的趋势越来越明显 研究和学习成熟的库 拥抱开源社区 敢于造新轮子并分享/开源它我们并不总是满意其他人的封装和开源的工具包.慎重思考发现并不那么美好的时候,要敢于动手造一个新的了; 找不到的轮子 不合适的轮子 不完美的轮子 例如: gitchangelog mkdocs flask_admin markdown_images http://img.pinbot.me:8088/ 小组讨论:阿里员工用脚本抢中秋节月饼,你怎么看??? 自动化一切Automate everything!!! 非常具有工程师思维. 只是没有做好边界条件测试; 自动化一切 各种自动化工具: fabrickk,ansible,docker等自动化测试 工程师天生是追求效率的有人说认为程序员花大量的时间做自动化的工具，还不如人肉的效率高，比如，写自动化的脚本花5个小时，而重复做这件事200次只花3个小时。有这样的理解的人根本不懂工程。一方面，这个工具可以共享重用，更多的人可以从中受益，这次我花5个小时开发这个工具，下次只用1小时改一下就可以用在别的地方，这是着眼于未来而不是眼下的成本。更重要的是，这是一种文化，一种提高效率的文化，他会鼓励和激发出更多的这样的事情发生。 人类之所以比别的动物聪明就是会使用和发明工具.而古语也有云：“工欲善其事，必先利其器”，看看美军的装备你就知道战争工具的好坏有多重要了，一个公司的强大之处在执行力，而执行力的强大之处在于你有什么样的支持工具。这些，已经不是工程师文化，而是人类发展的文化。 月饼事件-新篇章,leon lee最后回应 快捷键熟练使用快捷键，不单能提高操作之间的切换速度。更重要的是它能时刻提醒你，你的软件还有这样那样的功能（尤其是IDE上的功能）。 不要让手指离开键盘编辑器之神: vim我用到的vim模式演示 vim 所有编辑器: haroopad,Sublime,eclipse,pycharm 浏览器: vimium 命令行: oh-my-zsh vi插件 其他各种快捷键F2,F5-8,F12,C,V… 工欲善其事必先利其器效率提升工具集推荐硬件层面 跑的更快的设备(Mac经验谈,SSD) 宽度合适的屏幕,多配一块屏幕辅助，省得来回切换窗口。 键盘代码书写 合适的IDE vim/emacs/sublime 编辑器 纯文本的威力 文档书写:markdown协作工具 团队协作工具tower 代码版本管理git 持续集成Jenkinsvim模式无处不在,各种插件 浏览量网页: chrome的vimium插件 代码编辑器: 启用vim模式(eclipse,sublime) 书写文档: vim模式 命令行: oh-my-zsh,vim跳转 减少无效沟通 减少无效会议 用有效的非即时团队沟通软件如Tower、 Trello等,建立任务清单 无法快速用即时通讯软件完成的采用当面沟通或电话 没有银弹No sliver bullet!!! 不存在一个神奇的方法或技术“银弹”，实现数量级以上的程序员的工作效率的提升。 《人月神话》 三.什么是适合业务发展的好架构? 架构设计是由需求驱动，而非模型驱动。软件需求 功能需求 质量属性（非功能需求） 设计约束 不管是高层次的架构设计也好，还是最简单的功能实现也罢，对需求的把握都是至关重要的。需求才是我们付出所有努力想要达到的目的，脱离了需求，就是“答非所问”。同样，大多的反复和变更都是因为对需求的把握不够精准，因此我们要给予需求足够的重视。 一线架构师阅读体会-需求之于架构 唯一不变的就是变化本身,把握好需求 架构是不断演进的架构，平台不是买来的，也不是用一个开源就能获得的，也不是设计出来，而是长期演化才能落地生根的。 架构需要验证在系统真正地投入生产使用之前，再好的架构都只是假设，产品越晚被使用者使用，失败的成本和风险就越高，而小步行进，通过MVP快速实验，获取客户反馈，迭代演化产品，能有效地减少失败的成本和风险。 什么是软件架构 什么是架构 架构的种类 功能架构 技术架构 服务器架构 企业架构 网络架构 数据库架构 …. 软件架构定义 架构重要么? 软件架构好处 让团队跟随清晰的愿景和路线图 技术领导力和更好的协调 与人交流的刺激因素: 以便于回答与重要决策,非功能需求、限制和其他横切关注点相关的问题 识别和减轻风险的框架 方法和标准的一致性,随之而来的结构良好的代码库 正在构建的产品的坚实基础 与不同的听众,以不同层次的抽象来交流解决方案的结构 基本概念篇 解析软件架构概念 软件架构是应用程序与系统架构的结合 即从代码结构到将代码部署到生产环境,与一个软件系统重要元素相关的所有东西都是软件架构 应用程序架构 应用程序架构讨论的是软件设计低级别切面,通常只考虑单一的技术栈(如:java,.net,python) 结构单元以软件为基础 系统架构 更大规模的应用程序架构 端到端软件系统在较高层次的整体结构.组件和服务更高层次的抽象. 结构单元是各种软硬件,从编程语言框架到服务器和基础设施 架构设计基础 各种经典的设计模式(GoF) &lt;设计原本&gt; 设计的基本原则 Don’t Repeat Yourself (DRY) Keep It Simple, Stupid (KISS) Program to an interface, not an implementation设计模式中最根本的哲学，注重接口，而不是实现，依赖接口，而不是实现。接口是抽象是稳定的，实现则是多种多样的。 Command-Query Separation (CQS) – 命令-查询分离原则 You Ain’t Gonna Need It (YAGNI)- 只考虑和设计必须的功能，避免过度设计。 Law of Demeter – 迪米特法则 - “最少知识原则” 面向对象的S.O.L.I.D 原则 Single Responsibility Principle (SRP) – 职责单一原则 Open/Closed Principle (OCP) – 开闭原则 Liskov substitution principle (LSP) – 里氏代换原则 Interface Segregation Principle (ISP) – 接口隔离原则 Dependency Inversion Principle (DIP) – 依赖倒置原则 设计的基本原则 Common Closure Principle（CCP）– 共同封闭原则一个包中所有的类应该对同一种类型的变化关闭。一个变化影响一个包，便影响了包中所有的类。一个更简短的说法是：一起修改的类，应该组合在一起（同一个包里）。如果必须修改应用程序里的代码，我们希望所有的修改都发生在一个包里（修改关闭），而不是遍布在很多包里。 Common Reuse Principle (CRP) – 共同重用原则CRP原则帮助我们决定哪些类应该被放到同一个包里。 Hollywood Principle – 好莱坞原则“don’t call us, we’ll call you.”意思是，好莱坞的经纪人们不希望你去联系他们，而是他们会在需要的时候来联系你。也就是说，所有的组件都是被动的，所有的组件初始化和调用都由容器负责。组件处在一个容器当中，由容器负责管理。好莱坞原则就是IoC（Inversion of Control）或DI（Dependency Injection ）的基础原则。这个原则很像依赖倒置原则，依赖接口，而不是实例， 设计的基本原则 High Cohesion &amp; Low/Loose coupling &amp; – 高内聚， 低耦合UNIX操作系统设计的经典原则，把模块间的耦合降到最低，而努力让一个模块做到精益求精。内聚：一个模块内各个元素彼此结合的紧密程度耦合：一个软件结构内不同模块之间互连程度的度量 Convention over Configuration（CoC）– 惯例优于配置原则 Separation of Concerns (SoC) – 关注点分离 Design by Contract (DbC) – 契约式设计 Acyclic Dependencies Principle (ADP) – 无环依赖原则 一些软件设计的原则 最小可用产品(MVP)理念做出最小可用产品(Minimum Viable Product， MVP)，尽快丢给用户试用，快速获取客户反馈，在此基础上不断迭代和演化架构和产品。 过度工程（Over Engineering）的问题讲产品架构和用户之间没有形成有效的反馈闭环，架构师想的和客户想的不在一个方向上，通过最小可用产品，快速迭代反馈的策略，可以避免这种问题。 架构模式 分层架构(n层架构) SOLID原则的通用架构 事件驱动架构:一种流行的分布式异步架构模式 用于小规模或者大规模的应用程序 可以与 调停者拓扑（Mediator Topology） 或者 代理者拓扑（Broker Topology） 一起使用 微内核架构(插件架构) 核心系统和插件模块 微服务架构 核心概念是具备高可伸缩性、易于部署和交付的独立部署单元（Separately Deployable Units） 最重要的概念是包含业务逻辑和处理流程的服务组件（Service Component） 架构原则和模式 如何呈现设计的架构? 可视化软件 画有效的草图 模式设计工具(UML,工具:staruml) UML的5视图方法:4+1视图始终是架构师界最通用的东西，寻找一种向世界妥协的方式。 职责划分（逻辑视图） 程序单元组织（开发视图） 控制流组织（运行视图） 物理节点安排（物理视图） 持久化设计（数据视图） 一线架构师实践指南（二）软件架构师书籍 架构可视化:一图胜千文,图文并茂建模工具对比 建模工具 利 弊 UML 善于表达静态与动态结构 不善于表达概念、约束与行为 文字 不善于表达概念、约束与行为 善于表达静态与动态结构 (伪)代码 好的代码有很强表达能力 太细、难以反映意图、不便于非程度员阅读(非通用语言) 以文字为主体，配合以图形（可以用UML）；图形不要太大、太细；不但要表达是什么，而且要表达为什么。 不画图的专家不是好的架构师【UML 建模】UML建模语言入门-视图,事物,关系,通用机制 恰如其分的预先设计 方法学 瀑布模型: 大型预先设计,推崇写代码前每件事情都经过讨论和评审 敏捷开发: 充分自由度,快速行动,拥抱变化,反馈和交付价值. 演化架构和浮现式设计 恰如其分很难具体量化 过少设计 过分设计 为设计设置语境 最关键是明确自己的需求 为软件生成轻量的文档 代码不会讲完整的故事 软件文档即指南 语境 功能性概览 质量属性 约束 原则 软件架构 外部接口 代码: 呈现底层细节,解释工作原理 文档化的代码 支持自动化生产部分文档 数据文档 数据字典 数据模型 物理架构 服务器架构 网络架构 部署文档 架构实例剖析包括聘宝平台的Web端系统架构、推荐系统架构、分布式存储/计算系统、底层服务器架构 聘宝系统架构演进路线 其中一些的问题 人员架构: 应对需求与团队规模 两个人 5个人 20个人 服务器架构: 2台服务器: 1+1 10台服务器: 5+5 30台: 10+20 60台+: 15+35 架构演进 web端系统: MVC模式–&gt;前端分离 web端架构 微内核架构: 核心系统 和 插件模块 web端系统与推荐系统解耦 RPC架构: 消息队列 华为内部如何实施微服务架构？华为内部如何实施微服务架构？ 架构之道-规划、简化和演化规划还是演化 好的架构是设计出来的 好的性能,好的质量主要源于好的设计,而不是依赖测试 架构设计的质量直接影响演化的难以程度 联想高级架构师分享：架构之道-规划、简化和演化 缺少规划难以演化单靠演化，即使能使架构越来越优化，也可能需要很长的周期，而对于产品或者项目，时间这个约束条件往往是苛刻的。迭代是有条件的。建议：在有规划的基础上进行演化。我们无法得到普适的架构，但可以得到确定领域的通用架构，可以在特定领域通过演化使应用架构逐步优化，逐步与业务架构想适应，提高匹配度。 四.架构师日常工作,享受什么样的苦与乐? ##软件架构师的职责 架构师的基本分类 根据职能: 前端架构师,后端架构师,算法架构师,分布式架构师,运维架构师 其承担的责任 确保概念的完整性，合理的切分工作，制定接口 架构师是最重要的，以确保概念的完整性，合理的切分工作，制定接口。行政领导应当尊重架构师的权威。 软件架构师的职责架构师需要参与项目开发的全部过程，包括需求分析、架构设计、系统实现、集成、测试和部署各个阶段，负责在整个项目中对技术活动和技术说明进行指导和协调。 小组讨论:架构师需要写代码么??? 尽可能要写,找到合理的平衡架构师要尽可能写代码，做测试，纸上谈兵式做架构而后丢给团队的作法非常不靠谱（除非是已经非常清晰成熟的领域） 软件工程师角色和职责区别简单地将写程序的工程师分成三类: 第一，写程序的人 （Coder、Employee、Worker）这种类型的人单纯的只是为了工作、功课、任务而写程序，虽然职务名称叫做工程师，但是写程序对他们来说只是获取成绩、金钱的工具，写程序对他们来说枯燥无味，但为了生活，他们继续产出他们的程序码。 第二，有目标而写程序的人 （Hacker、Doer、Entrepreneur）这种类型的人并不是因为热爱「程序」本身而开始写程序，他们写程序是为了要达成某些目的。 第三，热爱程序本身的人 （Architect、Theorists、Change Maker、Geek）这类工程师喜欢程序本身，他们欣赏程序设计的架构、可扩充性、可被测试性。他们喜欢最新的科技，并且会主动的去接触、试用它们。他们喜欢写有架构、能够被别人重复使用的套件 （Library）。 在我们的环境中，有太多的 Coder、也有许多从 Coder 变成的 Hacker（他们的差别只在有没有目标，还有去实作的毅力），但比较少真正愿意奉献、热爱程序的 Architect。 三种软件工程师——编码员、程序师和架构师 coder vs hacker 架构师的必备技能 架构师的必备技能 项目技能 技术技能 想象力技能 1.一个好的架构师首先是一个合格的工程师；2.具有抽象的思维能力，能把业务抽象在抽象；3.了解技术前沿知识，并深知其优劣；4.沟通；5.权衡取舍，能够在设计系统时综合考虑；6.业务精良，同时具有多领域知识，因为有时候业务是相通的; 进度评估人月 换算 &lt;人月神话&gt; “测试的时间至少需要整个开发流程时间的一半”。 团队协作外科手术队伍: 专业 用好tower进行任务分配和进度管理 用好版本管理工具(git) 用好github,进行代码review 一个人每天200行有效代码 vs 20个人 * 150行/每天 团队文化建设你不是一个人在战斗. 谦逊、尊重、信任-HRT(Honest,Respect,Trust)原则. 团队技术分享 拥抱开源社区 极客与团队 &lt;极客与团队-软件工程师的团队生存秘笈&gt; 与人打交道 架构师与研发团队 关系技能: 架构师和各个业务需求方 商务技能 必要的会议 项目产品需求评审 每日研发内部站立晨会 研发内部关键模块技术评审 除此之外还有一些非研发团队沟通会议 架构师必知软件架构师应该知道的97件事（极致总结） 工具集讲义中提到的各个工具集 用途 推荐工具 你喜欢的 版本管理 git 番茄工作法 番茄工作法 …. … 架构师的每日工作流程案例敏捷开发总的流程如下： 需求规划和分期 需求评审 需求讲解 方案评审 每日晨会 性能测试 CodeReview Demo 测试阶段10.线上Bug修改流程 程序员简易成长指南:学习 如何更高效地学习？ 做一个全流程的demo,即使不理解也要做完 体系化的学习。抱着厚书硬啃了一遍，突然有种豁然开朗的感觉. 做笔记,画思维导图 再去看一些文章 带着问题学习更有效率 架构师应不应该写代码？ 应该 在代码和和其他工作之间平衡 程序员简易成长指南:职责从菜鸟码农到架构师 架构师职责 在代码中第一时间发现可能存在的问题，向其他人提出警告， 或是给予其他人改进的意见， 必要的时候或是给其他人演示一下正确的姿势。 保持大局观需要适度参与“核心模块”开发总的来说，架构师和程序员在某些方面上有点像产品经理和用户的关系，大部分程序员并不会主动告诉你他们想要什么、哪里需要优化，甚至自己也不知道这些。想要做出好的产品，捷径之一就是跟用户做同样的事情。 程序员简易成长指南:沟通 实践：开会是个技术活吗？ 是 大多数的会议都是在毫无意义的交流中浪费时间 这并不是会议才有的问题 大多数时候，沟通的核心不是你说了什么，而是你想要让对方了解什么、让他做什么。 良好的沟通能在工作中显著提升效率，但很多人忽略了这个事情。 程序员简易成长指南:沟通 恰到好处的进行沟通的原则 确保各方对背景的理解一致，比如开会之前先简单通过邮件交流一下，对新加入会议的人花个30秒钟做个前情提要，或者在讨论过程中让对方说一下他的理解。 去掉对方不能/不需要理解的内容，比如跟产品说“这个队列在高并发下因为锁的实现有问题导致CPU性能瓶颈”不如改成“我们发现了性能问题，持续10分钟了，10万用户收不到运营发的无节操广告，大概5分钟后扩容解决”。 确保在对方失去注意力前尽快说出重点， 不要说没有意义的内容浪费其他人的时间，比如”这需求做不了“或者”这里不可能出bug“，没有人想听到这些废话。 程序员简易成长指南:沟通 还有更好的办法吗？成为技术专家/架构师之后的工作可以说是痛并快乐着，会有很多人找你咨询问题，另一方面，会有太多人找你咨询问题。甚至有一段时间每天的工作就是解答问题，小到工具使用中到疑难bug，大到架构设计，从早上到晚上基本都是在给各种各样的小伙伴提供咨询服务。 简化到三个问题: “他们要你解决什么问题？” “你解决的是什么问题？“ ”还有更好的办法吗？“ 现在第三句已经很少问到了。 程序员简易成长指南:门槛 成为架构师最困难的门槛是？ 知易行难。架构师虽然听起来很高大上，但本质上 仍然是工程师，不是科学家，也不是忽悠人的江湖骗子。学习再多，也需要 实践落地。设计架构方案更多的是在做一些抽象和权衡：把复杂的需求抽象成简单的模型，从功能、性能、可用性、研发成本等等方面规划如何构建一个系统，这些内容需要更多的实践练习。 没有实战平台。没有工作在类似平台天天需要接触架构设计的地方，而很多公司没有架构方面的工作可供练级，于是就想办法从理论上下功夫，这类人的特征非常明显：在信息不足，甚至不了解实际场景的情况下就开始做架构设计，这种所谓的架构往往理解比较肤浅，经不住推敲。 需要经验和磨砺。每次招人之后我们都会做一些针对新人的架构方面的培训，课程材料基本上包括了系统架构相关的主要方面，但是学完这些材料之后就能成为独当一面的架构师了吗？并没有。相反，这仅仅是开始，新人真正做了实际生产的系统之后才算是正式入门：面对压力时才会懂得权衡，走过弯路之后才会寻找捷径。 程序员简易成长指南从菜鸟码农到架构师 1）大部分烂代码并不是架构师的设计问题；2）想要做出好的产品，捷径之一就是跟用户做同样的事情；3）大多数的会议都是在毫无意义的交流中浪费时间；4）程序员之间的差距或许比人和猴子之间的差距还大 参考书籍人月神话程序员的职业素养作为公司的架构师，一直致力于如何更好的设计架构，如何优化项目架构，如何提高开发效率和质量，却很少让团队成员理解和明白，为何要这样做。下一个小目标，让团队每个人都理解设计。程序员修炼之道：从小工到专家代码整洁之道代码大全软件架构师的12项修炼软件架构设计：程序员向架构师转型必备程序员必读之软件架构:告诉你怎么像架构师一样思考极客与团队重构 改善既有代码的设计深入理解计算机系统（原书第2版） [Computer Systems]编程珠玑（续 修订版） 参考文章StackOverflow讨论帖:哪本最具影响力的书，是每个程序员都应该读的 59本物理量纲失效了-论《人月神话》程序员简易成长指南：从菜鸟码农到架构师秦迪，微博平台及大数据技术专家. 爱折腾，喜欢研究从内核到前端的所有方向，近几年重点关注大规模系统的架构设计和性能优化，重度代码洁癖：以code review己任，重度工具控：有现成工具的问题就用工具解决，没有工具能解决的问题就写个工具解决。业余时间喜欢偶尔换个语言写代码放松一下。程序员如何才能晋升为优秀的高薪架构师？&lt;重构 改善既有代码的设计&gt;读书笔记软件架构师不等同于资深程序员高质量的工程代码为什么难写不是实现了业务需求就结束了呢，其实远没有，这其实只是写代码的开始，除了正向的逻辑实现外，任何一个点的异常的分支逻辑怎么处理才是工程化的代码中更难处理的部分，这个问题在单机式的系统中会相对还好处理，在分布式的环境会变得非常的复杂异常分支逻辑处理好后，通常还需要增加必要的日志信息，以便在出问题时方便排查吃掉重要的异常信息不抛出这种行为在写代码中是非常可耻的对于高质量的工程代码而言，其实实现业务逻辑只是其中占比很小的一部分，甚至花的时间是相对最少的一部分;好的工程代码，说难也难，说不难也不难，均体现在“工程”二字之上。除了代码之外，想想其他被冠以“工程”二字的，如：大厦、桥梁、船舶、水电站等等等等，高质量“工程”都有共性：安全、易用、可维护、美观… 综合多个维度，缺一不可。 系统设计案例支付宝系统架构（内部架构图） 微信联系我 THANK YOU","categories":[{"name":"UML","slug":"UML","permalink":"http://hopperclouds.github.io/categories/UML/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"http://hopperclouds.github.io/tags/面向对象/"},{"name":"设计模式","slug":"设计模式","permalink":"http://hopperclouds.github.io/tags/设计模式/"}],"keywords":[{"name":"UML","slug":"UML","permalink":"http://hopperclouds.github.io/categories/UML/"}]},{"title":"react入门介绍","slug":"react入门介绍","date":"2016-09-06T10:30:30.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/09/06/react入门介绍/","link":"","permalink":"http://hopperclouds.github.io/2016/09/06/react入门介绍/","excerpt":"react.js介绍react.js的提出react.js的首次提出是在2014年Facebook的f8大会上。顺便科普一下f8大会，f8大会是由Facebook组织的年度的技术峰会，之所以叫f8，就是看大家在8小时以内能做出哪些有意思的东西。react.js称为颠覆式前端UI开发框架。目前基于html的前端开发变得越来越复杂，传统的开发方式基于来自服务器和来自用户输入的交互数据,动态反应到复杂界面的时候，代码量变得越来越大，难以维护。比如，前端开发框架jquey，每次数据更新，必须手动把数据更新渲染到ui界面上,代码量极大。基于此，google推出的angular.js的双向数据绑定很好的解决了这个问题。但是angular.js也有自身的一些不足。1：angular过重，不适用于对性能要求特别高的站点。2：ui组件封装比较复杂，不利于重用。而react解决了所有的这些问题。ReactJS官网地址：http://facebook.github.io/react/Github地址：https://github.com/facebook/react","text":"react.js介绍react.js的提出react.js的首次提出是在2014年Facebook的f8大会上。顺便科普一下f8大会，f8大会是由Facebook组织的年度的技术峰会，之所以叫f8，就是看大家在8小时以内能做出哪些有意思的东西。react.js称为颠覆式前端UI开发框架。目前基于html的前端开发变得越来越复杂，传统的开发方式基于来自服务器和来自用户输入的交互数据,动态反应到复杂界面的时候，代码量变得越来越大，难以维护。比如，前端开发框架jquey，每次数据更新，必须手动把数据更新渲染到ui界面上,代码量极大。基于此，google推出的angular.js的双向数据绑定很好的解决了这个问题。但是angular.js也有自身的一些不足。1：angular过重，不适用于对性能要求特别高的站点。2：ui组件封装比较复杂，不利于重用。而react解决了所有的这些问题。ReactJS官网地址：http://facebook.github.io/react/Github地址：https://github.com/facebook/react react.js的特点1、就是轻，数据渲染响应非常快。复杂或频繁的DOM操作通常是性能瓶颈产生的原因。React为此引入了虚拟DOM（Virtual DOM）的机制：在浏览器端用Javascript实现了一套DOM API。基于React进行开发时所有的DOM构造都是通过虚拟DOM进行，每当数据变化时，React都会重新构建整个DOM树，然后React将当前整个DOM树和上一次的DOM树进行对比，得到DOM结构的区别，然后仅仅将需要变化的部分进行实际的浏览器DOM更新。尽管每一次都需要构造完整的虚拟DOM树，但是因为虚拟DOM是内存数据，性能是极高的，而对实际DOM进行操作的仅仅是Diff部分，因而能达到提高性能的目的。 2：组件化开发思想。React推荐以组件的方式去重新思考UI构成，将UI上每一个功能相对独立的模块定义成组件，然后将小的组件通过组合或者嵌套的方式构成大的组件，最终完成整体UI的构建。 react试用场景react 这么厉害到底适用于哪些场景呢？1、复杂场景下的高性能要求。2、重用组件库，组件组合。 react html、css基础实践下面让我们来看看一组代码： 1234567891011121314151617181920212223242526272829&lt;html&gt;&lt;head&gt; &lt;script src=\"../build/react.js\"&gt;&lt;/script&gt; &lt;script src=\"../build/react-dom.js\"&gt;&lt;/script&gt; &lt;script src=\"../build/browser.min.js\"&gt;&lt;/script&gt; &lt;style type=\"text/css\"&gt; .redColor&#123; color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"example\"&gt;&lt;/div&gt; &lt;script type=\"text/babel\"&gt; var Hello = React.createClass(&#123; render:function()&#123; var styleObj = &#123; textDecoration:'underline' &#125;; return &lt;div className=\"redColor\" style=&#123;&#123;fontSize:'18px'&#125;&#125;&gt;Hello &#123;this.props.name&#125;&lt;/div&gt; &#125; &#125;); ReactDOM.render( &lt;Hello name=\"World\"/&gt;, document.getElementById('example') ); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 现在来解释一下这段代码1.react用的是jsx，是facebook为react开发的一套语法糖。语法糖是计算机中添加的一种语法，对语言的功能没有影响，但是更方便程序员使用，增加可读性减少程序出错机会。类似的还有CoffeeScript、TypeScript等。最终都被解析库解析成js。这里引入的browser.js 就是jsx的解析库。作用是将 JSX 语法转为 JavaScript 语法。另外 &lt;script&gt; 标签的 type 属性为 text/babel 。表明这是jsx语法。 2.jsx为我们带来的便利就是，我们可以在js里写类dom的结构，比我们用原生js拼接字符串要简单方便许多。jsx语法允许我们生成原生的dom标签，还可以生成自定义标签。比如hello，这些统称为react components.通过调用ReactDOM将react components呈现在页面上。 3.ReactDOM.render是React的最基本方法，用于将模板转为 HTML 语言，并插入指定的 DOM 节点。第一个参数是要插入的components，第二个参数是要插入的容器。自定义的标签是通过React.createClass申明，参数是一个js的对象。return的内容就是渲染的结构。遇到 HTML 标签（以 &lt; 开头），就用 HTML 规则解析；遇到代码块（以 { 开头），就用 JavaScript 规则解析。 4.给标签添加css属性有两种： 一种：用外联样式，注意这里是className，因为这是jsx语法，class在js中已经是一个保留关键字。 二种：内联样式。在react中内联样式必须用样式对象来表示，在react中内联样式必须用样式对象来表示，必须用驼峰。且用｛｛｝｝包裹。这里为什么要用｛｛｝｝，让我们再看看另一种写法就一目了然了。 123456789101112131415&lt;div id=\"example\"&gt;&lt;/div&gt;&lt;script type=\"text/babel\"&gt; var Hello = React.createClass(&#123; render:function()&#123; var styleObj = &#123; fontSize:'18px' &#125;; return &lt;div className=\"redColor\" style=&#123;styleObj&#125;&gt;Hello &#123;this.props.name&#125;&lt;/div&gt; &#125; &#125;); ReactDOM.render( &lt;Hello name=\"World\"/&gt;, document.getElementById('example') );&lt;/script&gt; 这里申明一个样式对象，用｛｝包裹就能以js的方式来解析。和｛｛fontSize:&quot;18px&quot;｝｝异曲同工。可以隐约的看到，react的组件通过样式对象的申明可以，react组件是html、css、js的集合，成为真正意义上的独立组件。 这次我们简单介绍了react的由来、特点、应用场景。以及，jsx语法糖，如何生成自定义标签，插入节点，添加css样式，这些都是react的基础，接下来，我们继续react compenents的生命周期。","categories":[],"tags":[],"keywords":[]},{"title":"Python-Web并发重复数据防守策略","slug":"Python-Web并发重复数据防守策略","date":"2016-09-02T09:51:45.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/09/02/Python-Web并发重复数据防守策略/","link":"","permalink":"http://hopperclouds.github.io/2016/09/02/Python-Web并发重复数据防守策略/","excerpt":"作者：jackie 1.重复数据提交原因 恶意用户脚本攻击 web页面按钮卡顿重复点击引起","text":"作者：jackie 1.重复数据提交原因 恶意用户脚本攻击 web页面按钮卡顿重复点击引起 2.服务器优化方向 web服务器层防御，如nginx可以限制单一IP每秒钟的访问次数 应用层防御，通过web应用程序进行控制 数据层防御 3.常规防冲击 nginx 配置 –访问速率控制12345server &#123; ... location /download/ &#123; limit_conn addr 100; #单一IP每秒钟最多访问100次 &#125; 在代理层防御主要应对于大规模高并发，例如有恶意用户高速率抓取本网站数据，导致网站服务性能下降时，就需要进行IP访问速率限制；但是考虑到国内网络环境，基本绝大用户都是共享公共IP进行上网，所以此限制也并不是一定会打开。 黑名单机制 –防恶意攻击 网络服务商控制，例如使用阿里云的可以通过阿里云的安全策略配置进行设置黑名单。 服务器 本地防火墙策略 web服务器 nginx配置黑名单 web应用中通过缓存黑名单进行控制 4.异常访问带来的数据重复如何规避 数据表多字段进行联合唯一索引，通过数据库的限制进行脏数据的排除。 (推荐) 数据库加锁，分悲观锁和乐观锁，具体概念不做讲述，一旦加了锁，也就给开发者自己加了锁，自己琢磨去吧。 具体业务进行单一服务化，单实例进行处理，可通过MQ与主业务服务进行交互。（推荐） 5.具体的某个应用服务如何进行访问速率限制 直接上代码了，通过redis的原子操作机制设定计数器，也可称为限速器。123456789101112131415161718192021def limit_api_call(key, limit, timeout): \"\"\" API限速器 :param key: :param limit:限制次数 :param timeout: 单位时间 :return: True or False \"\"\" lua_incr = \"\"\" local current current = redis.call(\"incr\",KEYS[1]) if tonumber(current) == 1 then redis.call(\"expire\",KEYS[1],ARGV[1]) end return current \"\"\" current = client.eval(lua_incr, 1, key, timeout) current = int(current) if current &gt; limit: return False return True Reids官方文档中也提供了其他几种实现方式，但是除了是用lua脚本原子操作进行辅助，其他都只能概率限制，无法准确限速。","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://hopperclouds.github.io/tags/python/"},{"name":"HTTP","slug":"HTTP","permalink":"http://hopperclouds.github.io/tags/HTTP/"},{"name":"并发","slug":"并发","permalink":"http://hopperclouds.github.io/tags/并发/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"JavaScript之递归","slug":"JavaScript之递归","date":"2016-09-01T16:52:45.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/09/02/JavaScript之递归/","link":"","permalink":"http://hopperclouds.github.io/2016/09/02/JavaScript之递归/","excerpt":"作者：纯利 那么什么叫递归呢？所谓递归函数就是在函数体内调用本函数。最简单的例子就是计算阶乘。0和1的阶乘都会被定义为1，更大的数的阶乘是通过计算11…来求得的，每次增加1，直至达到要计算阶乘的那个数。","text":"作者：纯利 那么什么叫递归呢？所谓递归函数就是在函数体内调用本函数。最简单的例子就是计算阶乘。0和1的阶乘都会被定义为1，更大的数的阶乘是通过计算11…来求得的，每次增加1，直至达到要计算阶乘的那个数。 递归的缺点：如果递归函数的终止条件不明确或者缺少终止条件会导致函数长时间运行，是用户界面处于假死状态。值得注意的是：浏览器对递归的支持熟练与JS调用栈大小直接相关，当使用太多递归甚至超过最大调用栈容量时，浏览器会报错误信息，各个浏览器对报错的提示信息也不一样。 下面我们先来看一下一个经典的递归阶乘函数：1234567function test(num)&#123; if(num &lt;= 1)&#123; return 1; &#125;else&#123; return num * test(num-1); &#125;&#125; 上面的的这个函数表面上没有什么问题，但是以下的代码却可能会导致问题：123var f = test;test = null;console.log(f(2));//报错 Uncaught TypeError: test is not a function 指向原始函数的引用就剩下一个，当调用f()函数时，而test已经不再是一个函数了，所以会导致错误，但是我们可以使用arguments.callee来解决这个问题。 大家都知道，arguments.callee是一个指向正在执行的函数的指针，因此可以用它来实现函数的递归调用,看如下代码：1234567function test(num)&#123; if(num &lt;= 1)&#123; return 1; &#125;else&#123; return num * arguments.callee(num-1); &#125;&#125; 这样即使函数赋值给了另外一个变量，f()函数依然是有效的，所以递归调用能正常完成。而且这种方式在严格模式和非严格模式下都可以使用哦。","categories":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://hopperclouds.github.io/tags/javascript/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}]},{"title":"数据处理/分析/可视化飞艇(zeppelin)介绍","slug":"数据处理-分析-可视化飞艇-zeppelin-介绍","date":"2016-08-31T17:35:55.000Z","updated":"2016-08-31T17:35:55.000Z","comments":true,"path":"2016/09/01/数据处理-分析-可视化飞艇-zeppelin-介绍/","link":"","permalink":"http://hopperclouds.github.io/2016/09/01/数据处理-分析-可视化飞艇-zeppelin-介绍/","excerpt":"author: likaiguo Zeppelin(飞艇)Zeppelin思维导图 推荐查看思维导图中的各个链接,尤其是官方文档和中文翻译.","text":"author: likaiguo Zeppelin(飞艇)Zeppelin思维导图 推荐查看思维导图中的各个链接,尤其是官方文档和中文翻译. 快速搭建Zeppelin环境安装过程 到官网下载二进制包（http://zeppelin.apache.org/download.html） 解压到本地(保证已经设置好Java环境) 运行Zeppelin服务bin/zeppelin-daemon.sh start|stop|restart 浏览器中打开：http://localhost:8080 即可进入Zeppelin首页。 Zeppelin是什么?A web-based notebook that enables interactive data analytics.You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. 一款基于web页面的笔记本(类似ipython中的notebook),其提供交互式数据分析功能.使用Zeppelin(飞艇)我们能使用如SQL,Scala等后端语言制作出数据驱动的,交互式的并且易于协作的文档. Zeppelin基本概念1.支持多种后端语言,Interpreter(解释器) 抽象出解释器概念,运行各种语言和数据处理后端工具.在Zeppelin中解释器被设计为可插拔的模块.目前支持各种各样的解释器,如上图所示包括Apache Spark, Python, JDBC, Markdown and Shell等等. 同时也可以写自己需要的解释器. 在现有的解释器的基础上配置对应的参数生成新的解释器 写相关的Java或者scala程序开发更加特定的解释器[参考文献2] 2.强大的数据可视化能力 Zeppelin具有较为常用的数据可视化的图表. 如上图所示,表格,柱状图,饼图,趋势图,散点图一应俱全. 数据可视化不仅限于Spark SQL,任意一种语言的表格输出都能被完美转译成对应的图表. 并且能够导出对应的CSV等类型数据. 3.数据透视表Apache Zeppelin aggregates values and displays them in pivot chart with simple drag and drop. You can easily create chart with multiple aggregated values including sum, count, average, min, max. 飞艇能够在页面上通过简单的拖拽进行各种聚合操作,并且展示出对应的数据透视表.同时也可以很容易通过求和,计数,平均,最小,最大创建各种聚合值的图表. 4.动态表格Zeppelin可以通过动态表格方式在notebook中添加诸如: 文本框,复选框,单选框等表单元素.通过这种方式,我们可以快速进行对应的动态操作. 典型应用: 这里${maxAge=30}的写法表示一个文本框元素,并且默认值为30。当修改对应的值是下方的图表会对应产生变化。 https://zeppelin.apache.org/docs/latest/manual/dynamicform.html 文档很重要. 遇到一个奇怪的问题:当使用下拉框时,对应的值可以实时变化. 其他如文本框,复选框都不实时变化,需要点击三角形run按钮才能生效. 5.将notebook共享给他人,更好的协作 可以直接将写好的notebook发送给其他人,放入工程的notebook目录下即可 可以将生成的图表共享给他人(复制对应的link,参见文献2和官方文档) Zeppelin使用场景(特点)?apache zeppelin应该会很吸引分布式计算、数据分析从业者,是个值得把玩的算比较前卫的项目。 代码量少， 模块很清楚， 可以尝试接入多种不同计算引擎， 实时任务运行、可视化效果 没有过多复杂的操作，只是区分了多个notebook， 每个notebook里做单独的分析处理工作，流程和结果会被保存下来。 此外，为spark做了更好的支持，比如默认是scala环境，默认sc已经创建好，即spark local可跑，默认spark sql有可视化效果。 一站式数据分析: 文档,不同工具集一应俱全 Zeppelin怎样服务于我们的业务? 应用于快速导入数据并且进行可视化 将多种数据处理技术和语言融合在一起 优美文档书写 快速给客户提供数据可视化服务 Zeppelin常见问题参考文献 Apache Zeppelin简介 Apache Zeppelin安装及介绍 让Spark如虎添翼的Zeppelin – 基础篇 Zeppelin 小试牛刀 – 使用Zeppelin展示MySQL的数据 Hadoop - Zeppelin 使用心得","categories":[{"name":"大数据","slug":"大数据","permalink":"http://hopperclouds.github.io/categories/大数据/"}],"tags":[{"name":"spark","slug":"spark","permalink":"http://hopperclouds.github.io/tags/spark/"},{"name":"pyspark","slug":"pyspark","permalink":"http://hopperclouds.github.io/tags/pyspark/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"http://hopperclouds.github.io/categories/大数据/"}]},{"title":"Lucene学习总结之一：全文检索的基本原理","slug":"Lucene学习总结之一","date":"2016-08-31T10:00:04.000Z","updated":"2016-10-11T11:00:08.000Z","comments":true,"path":"2016/08/31/Lucene学习总结之一/","link":"","permalink":"http://hopperclouds.github.io/2016/08/31/Lucene学习总结之一/","excerpt":"一、总论根据http://lucene.apache.org/java/docs/index.html定义： Lucene是一个高效的，基于Java的全文检索库。 所以在了解Lucene之前要费一番工夫了解一下全文检索。 那么什么叫做全文检索呢？这要从我们生活中的数据说起。","text":"一、总论根据http://lucene.apache.org/java/docs/index.html定义： Lucene是一个高效的，基于Java的全文检索库。 所以在了解Lucene之前要费一番工夫了解一下全文检索。 那么什么叫做全文检索呢？这要从我们生活中的数据说起。 我们生活中的数据总体分为两种：结构化数据和非结构化数据。 结构化数据：指具有固定格式或有限长度的数据，如数据库，元数据等。非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等。当然有的地方还会提到第三种，半结构化数据，如XML，HTML等，当根据需要可按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。 非结构化数据又一种叫法叫全文数据。 按照数据的分类，搜索也分为两种：对结构化数据的搜索：如对数据库的搜索，用SQL语句。再如对元数据的搜索，如利用windows搜索对文件名，类型，修改时间进行搜索等。对非结构化数据的搜索：如利用windows的搜索也可以搜索文件内容，Linux下的grep命令，再如用Google和百度可以搜索大量内容数据。对非结构化数据也即对全文数据的搜索主要有两种方法： 一种是顺序扫描法(Serial Scanning)：所谓顺序扫描，比如要找内容包含某一个字符串的文件，就是一个文档一个文档的看，对于每一个文档，从头看到尾，如果此文档包含此字符串，则此文档为我们要找的文件，接着看下一个文件，直到扫描完所有的文件。如利用windows的搜索也可以搜索文件内容，只是相当的慢。如果你有一个80G硬盘，如果想在上面找到一个内容包含某字符串的文件，不花他几个小时，怕是做不到。Linux下的grep命令也是这一种方式。大家可能觉得这种方法比较原始，但对于小数据量的文件，这种方法还是最直接，最方便的。但是对于大量的文件，这种方法就很慢了。 有人可能会说，对非结构化数据顺序扫描很慢，对结构化数据的搜索却相对较快（由于结构化数据有一定的结构可以采取一定的搜索算法加快速度），那么把我们的非结构化数据想办法弄得有一定结构不就行了吗？ 这种想法很天然，却构成了全文检索的基本思路，也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。 这部分从非结构化数据中提取出的然后重新组织的信息，我们称之索引。 这种说法比较抽象，举几个例子就很容易明白，比如字典，字典的拼音表和部首检字表就相当于字典的索引，对每一个字的解释是非结构化的，如果字典没有音节表和部首检字表，在茫茫辞海中找一个字只能顺序扫描。然而字的某些信息可以提取出来进行结构化处理，比如读音，就比较结构化，分声母和韵母，分别只有几种可以一一列举，于是将读音拿出来按一定的顺序排列，每一项读音都指向此字的详细解释的页数。我们搜索时按结构化的拼音搜到读音，然后按其指向的页数，便可找到我们的非结构化数据——也即对字的解释。 这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search)。 下面这幅图来自《Lucene in action》，但却不仅仅描述了Lucene的检索过程，而是描述了全文检索的一般过程。 全文检索大体分两个过程，索引创建(Indexing)和搜索索引(Search)。 索引创建：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程。于是全文检索就存在三个重要问题： 索引里面究竟存些什么？(Index) 如何创建索引？(Indexing) 如何对索引进行搜索？(Search) 下面我们顺序对每个个问题进行研究。 二、索引里面究竟存些什么索引里面究竟需要存些什么呢？ 首先我们来看为什么顺序扫描的速度慢： 其实是由于我们想要搜索的信息和非结构化数据中所存储的信息不一致造成的。 非结构化数据中所存储的信息是每个文件包含哪些字符串，也即已知文件，欲求字符串相对容易，也即是从文件到字符串的映射。而我们想搜索的信息是哪些文件包含此字符串，也即已知字符串，欲求文件，也即从字符串到文件的映射。两者恰恰相反。于是如果索引总能够保存从字符串到文件的映射，则会大大提高搜索速度。 由于从字符串到文件的映射是文件到字符串映射的反向过程，于是保存这种信息的索引称为反向索引。 反向索引的所保存的信息一般如下： 假设我的文档集合里面有100篇文档，为了方便表示，我们为文档编号从1到100，得到下面的结构 左边保存的是一系列字符串，称为词典。 每个字符串都指向包含此字符串的文档(Document)链表，此文档链表称为倒排表(Posting List)。 有了索引，便使保存的信息和要搜索的信息一致，可以大大加快搜索的速度。 比如说，我们要寻找既包含字符串“lucene”又包含字符串“solr”的文档，我们只需要以下几步： 取出包含字符串“lucene”的文档链表。 取出包含字符串“solr”的文档链表。 通过合并链表，找出既包含“lucene”又包含“solr”的文件。 看到这个地方，有人可能会说，全文检索的确加快了搜索的速度，但是多了索引的过程，两者加起来不一定比顺序扫描快多少。的确，加上索引的过程，全文检索不一定比顺序扫描快，尤其是在数据量小的时候更是如此。而对一个很大量的数据创建索引也是一个很慢的过程。 然而两者还是有区别的，顺序扫描是每次都要扫描，而创建索引的过程仅仅需要一次，以后便是一劳永逸的了，每次搜索，创建索引的过程不必经过，仅仅搜索创建好的索引就可以了。 这也是全文搜索相对于顺序扫描的优势之一：一次索引，多次使用。 三、如何创建索引全文检索的索引创建过程一般有以下几步： 第一步：一些要索引的原文档(Document)。为了方便说明索引创建过程，这里特意用两个文件为例： 文件一：Students should be allowed to go out with their friends, but not allowed to drink beer. 文件二：My friend Jerry went to school to see his students but found them drunk which is not allowed. 第二步：将原文档传给分次组件(Tokenizer)。分词组件(Tokenizer)会做以下几件事情(此过程称为Tokenize)： 将文档分成一个一个单独的单词。 去除标点符号。 去除停词(Stop word)。 所谓停词(Stop word)就是一种语言中最普通的一些单词，由于没有特别的意义，因而大多数情况下不能成为搜索的关键词，因而创建索引时，这种词会被去掉而减少索引的大小。 英语中挺词(Stop word)如：“the”,“a”，“this”等。 对于每一种语言的分词组件(Tokenizer)，都有一个停词(stop word)集合。 经过分词(Tokenizer)后得到的结果称为词元(Token)。 在我们的例子中，便得到以下词元(Token)： “Students”，“allowed”，“go”，“their”，“friends”，“allowed”，“drink”，“beer”，“My”，“friend”，“Jerry”，“went”，“school”，“see”，“his”，“students”，“found”，“them”，“drunk”，“allowed”。 第三步：将得到的词元(Token)传给语言处理组件(Linguistic Processor)。语言处理组件(linguistic processor)主要是对得到的词元(Token)做一些同语言相关的处理。 对于英语，语言处理组件(Linguistic Processor)一般做以下几点： 变为小写(Lowercase)。 将单词缩减为词根形式，如“cars”到“car”等。这种操作称为：stemming。 将单词转变为词根形式，如“drove”到“drive”等。这种操作称为：lemmatization。 Stemming 和 lemmatization的异同： 相同之处：Stemming和lemmatization都要使词汇成为词根形式。两者的方式不同：Stemming采用的是“缩减”的方式：“cars”到“car”，“driving”到“drive”。Lemmatization采用的是“转变”的方式：“drove”到“drove”，“driving”到“drive”。两者的算法不同：Stemming主要是采取某种固定的算法来做这种缩减，如去除“s”，去除“ing”加“e”，将“ational”变为“ate”，将“tional”变为“tion”。Lemmatization主要是采用保存某种字典的方式做这种转变。比如字典中有“driving”到“drive”，“drove”到“drive”，“am, is, are”到“be”的映射，做转变时，只要查字典就可以了。Stemming和lemmatization不是互斥关系，是有交集的，有的词利用这两种方式都能达到相同的转换。 语言处理组件(linguistic processor)的结果称为词(Term)。 在我们的例子中，经过语言处理，得到的词(Term)如下： “student”，“allow”，“go”，“their”，“friend”，“allow”，“drink”，“beer”，“my”，“friend”，“jerry”，“go”，“school”，“see”，“his”，“student”，“find”，“them”，“drink”，“allow”。 也正是因为有语言处理的步骤，才能使搜索drove，而drive也能被搜索出来。 第四步：将得到的词(Term)传给索引组件(Indexer)。索引组件(Indexer)主要做以下几件事情： 利用得到的词(Term)创建一个字典。 在我们的例子中字典如下： 对字典按字母顺序进行排序。 合并相同的词(Term)成为文档倒排(Posting List)链表。 在此表中，有几个定义： Document Frequency 即文档频次，表示总共有多少文件包含此词(Term)。Frequency 即词频率，表示此文件中包含了几个此词(Term)。所以对词(Term) “allow”来讲，总共有两篇文档包含此词(Term)，从而词(Term)后面的文档链表总共有两项，第一项表示包含“allow”的第一篇文档，即1号文档，此文档中，“allow”出现了2次，第二项表示包含“allow”的第二个文档，是2号文档，此文档中，“allow”出现了1次。 到此为止，索引已经创建好了，我们可以通过它很快的找到我们想要的文档。 而且在此过程中，我们惊喜地发现，搜索“drive”，“driving”，“drove”，“driven”也能够被搜到。因为在我们的索引中，“driving”，“drove”，“driven”都会经过语言处理而变成“drive”，在搜索时，如果您输入“driving”，输入的查询语句同样经过我们这里的一到三步，从而变为查询“drive”，从而可以搜索到想要的文档。 三、如何对索引进行搜索？到这里似乎我们可以宣布“我们找到想要的文档了”。 然而事情并没有结束，找到了仅仅是全文检索的一个方面。不是吗？如果仅仅只有一个或十个文档包含我们查询的字符串，我们的确找到了。然而如果结果有一千个，甚至成千上万个呢？那个又是您最想要的文件呢？ 打开Google吧，比如说您想在微软找份工作，于是您输入“Microsoft job”，您却发现总共有22600000个结果返回。好大的数字呀，突然发现找不到是一个问题，找到的太多也是一个问题。在如此多的结果中，如何将最相关的放在最前面呢？ 当然Google做的很不错，您一下就找到了jobs at Microsoft。想象一下，如果前几个全部是“Microsoft does a good job at software industry…”将是多么可怕的事情呀。 如何像Google一样，在成千上万的搜索结果中，找到和查询语句最相关的呢？ 如何判断搜索出的文档和查询语句的相关性呢？ 这要回到我们第三个问题：如何对索引进行搜索？ 搜索主要分为以下几步： 第一步：用户输入查询语句。查询语句同我们普通的语言一样，也是有一定语法的。 不同的查询语句有不同的语法，如SQL语句就有一定的语法。 查询语句的语法根据全文检索系统的实现而不同。最基本的有比如：AND, OR, NOT等。 举个例子，用户输入语句：lucene AND learned NOT hadoop。 说明用户想找一个包含lucene和learned然而不包括hadoop的文档。 第二步：对查询语句进行词法分析，语法分析，及语言处理。由于查询语句有语法，因而也要进行语法分析，语法分析及语言处理。 词法分析主要用来识别单词和关键字。 如上述例子中，经过词法分析，得到单词有lucene，learned，hadoop, 关键字有AND, NOT。 如果在词法分析中发现不合法的关键字，则会出现错误。如lucene AMD learned，其中由于AND拼错，导致AMD作为一个普通的单词参与查询。 语法分析主要是根据查询语句的语法规则来形成一棵语法树。 如果发现查询语句不满足语法规则，则会报错。如lucene NOT AND learned，则会出错。 如上述例子，lucene AND learned NOT hadoop形成的语法树如下： 语言处理同索引过程中的语言处理几乎相同。 如learned变成learn等。 经过第二步，我们得到一棵经过语言处理的语法树 第三步：搜索索引，得到符合语法树的文档。此步骤有分几小步： 首先，在反向索引表中，分别找出包含lucene，learn，hadoop的文档链表。其次，对包含lucene，learn的链表进行合并操作，得到既包含lucene又包含learn的文档链表。然后，将此链表与hadoop的文档链表进行差操作，去除包含hadoop的文档，从而得到既包含lucene又包含learn而且不包含hadoop的文档链表。此文档链表就是我们要找的文档。 第四步：根据得到的文档和查询语句的相关性，对结果进行排序。虽然在上一步，我们得到了想要的文档，然而对于查询结果应该按照与查询语句的相关性进行排序，越相关者越靠前。 如何计算文档和查询语句的相关性呢？ 不如我们把查询语句看作一片短小的文档，对文档与文档之间的相关性(relevance)进行打分(scoring)，分数高的相关性好，就应该排在前面。 那么又怎么对文档之间的关系进行打分呢？ 这可不是一件容易的事情，首先我们看一看判断人之间的关系吧。 首先看一个人，往往有很多要素，如性格，信仰，爱好，衣着，高矮，胖瘦等等。 其次对于人与人之间的关系，不同的要素重要性不同，性格，信仰，爱好可能重要些，衣着，高矮，胖瘦可能就不那么重要了，所以具有相同或相似性格，信仰，爱好的人比较容易成为好的朋友，然而衣着，高矮，胖瘦不同的人，也可以成为好的朋友。 因而判断人与人之间的关系，首先要找出哪些要素对人与人之间的关系最重要，比如性格，信仰，爱好。其次要判断两个人的这些要素之间的关系，比如一个人性格开朗，另一个人性格外向，一个人信仰佛教，另一个信仰上帝，一个人爱好打篮球，另一个爱好踢足球。我们发现，两个人在性格方面都很积极，信仰方面都很善良，爱好方面都爱运动，因而两个人关系应该会很好。 我们再来看看公司之间的关系吧。 首先看一个公司，有很多人组成，如总经理，经理，首席技术官，普通员工，保安，门卫等。 其次对于公司与公司之间的关系，不同的人重要性不同，总经理，经理，首席技术官可能更重要一些，普通员工，保安，门卫可能较不重要一点。所以如果两个公司总经理，经理，首席技术官之间关系比较好，两个公司容易有比较好的关系。然而一位普通员工就算与另一家公司的一位普通员工有血海深仇，怕也难影响两个公司之间的关系。 因而判断公司与公司之间的关系，首先要找出哪些人对公司与公司之间的关系最重要，比如总经理，经理，首席技术官。其次要判断这些人之间的关系，不如两家公司的总经理曾经是同学，经理是老乡，首席技术官曾是创业伙伴。我们发现，两家公司无论总经理，经理，首席技术官，关系都很好，因而两家公司关系应该会很好。 分析了两种关系，下面看一下如何判断文档之间的关系了。 首先，一个文档有很多词(Term)组成，如search, lucene, full-text, this, a, what等。 其次对于文档之间的关系，不同的Term重要性不同，比如对于本篇文档，search, Lucene, full-text就相对重要一些，this, a , what可能相对不重要一些。所以如果两篇文档都包含search, Lucene，fulltext，这两篇文档的相关性好一些，然而就算一篇文档包含this, a, what，另一篇文档不包含this, a, what，也不能影响两篇文档的相关性。 因而判断文档之间的关系，首先找出哪些词(Term)对文档之间的关系最重要，如search, Lucene, fulltext。然后判断这些词(Term)之间的关系。 找出词(Term)对文档的重要性的过程称为计算词的权重(Term weight)的过程。 计算词的权重(term weight)有两个参数，第一个是词(Term)，第二个是文档(Document)。 词的权重(Term weight)表示此词(Term)在此文档中的重要程度，越重要的词(Term)有越大的权重(Term weight)，因而在计算文档之间的相关性中将发挥更大的作用。 判断词(Term)之间的关系从而得到文档相关性的过程应用一种叫做向量空间模型的算法(Vector Space Model)。 下面仔细分析一下这两个过程： 计算权重(Term weight)的过程。影响一个词(Term)在一篇文档中的重要性主要有两个因素： Term Frequency (tf)：即此Term在此文档中出现了多少次。tf 越大说明越重要。Document Frequency (df)：即有多少文档包含次Term。df 越大说明越不重要。容易理解吗？词(Term)在文档中出现的次数越多，说明此词(Term)对该文档越重要，如“搜索”这个词，在本文档中出现的次数很多，说明本文档主要就是讲这方面的事的。然而在一篇英语文档中，this出现的次数更多，就说明越重要吗？不是的，这是由第二个因素进行调整，第二个因素说明，有越多的文档包含此词(Term), 说明此词(Term)太普通，不足以区分这些文档，因而重要性越低。 这也如我们程序员所学的技术，对于程序员本身来说，这项技术掌握越深越好（掌握越深说明花时间看的越多，tf越大），找工作时越有竞争力。然而对于所有程序员来说，这项技术懂得的人越少越好（懂得的人少df小），找工作越有竞争力。人的价值在于不可替代性就是这个道理。 道理明白了，我们来看看公式： 这仅仅只term weight计算公式的简单典型实现。实现全文检索系统的人会有自己的实现，Lucene就与此稍有不同。 判断Term之间的关系从而得到文档相关性的过程，也即向量空间模型的算法(VSM)。我们把文档看作一系列词(Term)，每一个词(Term)都有一个权重(Term weight)，不同的词(Term)根据自己在文档中的权重来影响文档相关性的打分计算。 于是我们把所有此文档中词(term)的权重(term weight) 看作一个向量。 Document = {term1, term2, …… ,term N} Document Vector = {weight1, weight2, …… ,weight N} 同样我们把查询语句看作一个简单的文档，也用向量来表示。 Query = {term1, term 2, …… , term N} Query Vector = {weight1, weight2, …… , weight N} 我们把所有搜索出的文档向量及查询向量放到一个N维空间中，每个词(term)是一维。 如图： 我们认为两个向量之间的夹角越小，相关性越大。 所以我们计算夹角的余弦值作为相关性的打分，夹角越小，余弦值越大，打分越高，相关性越大。 有人可能会问，查询语句一般是很短的，包含的词(Term)是很少的，因而查询向量的维数很小，而文档很长，包含词(Term)很多，文档向量维数很大。你的图中两者维数怎么都是N呢？ 在这里，既然要放到相同的向量空间，自然维数是相同的，不同时，取二者的并集，如果不含某个词(Term)时，则权重(Term Weight)为0。 相关性打分公式如下： 举个例子，查询语句有11个Term，共有三篇文档搜索出来。其中各自的权重(Term weight)，如下表格。 于是计算，三篇文档同查询语句的相关性打分分别为： 于是文档二相关性最高，先返回，其次是文档一，最后是文档三。 到此为止，我们可以找到我们最想要的文档了。 说了这么多，其实还没有进入到Lucene，而仅仅是信息检索技术(Information retrieval)中的基本理论，然而当我们看过Lucene后我们会发现，Lucene是对这种基本理论的一种基本的的实践。所以在以后分析Lucene的文章中，会常常看到以上理论在Lucene中的应用。 在进入Lucene之前，对上述索引创建和搜索过程所一个总结，如图： 索引过程： 1) 有一系列被索引文件 2) 被索引文件经过语法分析和语言处理形成一系列词(Term)。 3) 经过索引创建形成词典和反向索引表。 4) 通过索引存储将索引写入硬盘。 搜索过程： a) 用户输入查询语句。 b) 对查询语句经过语法分析和语言分析得到一系列词(Term)。 c) 通过语法分析得到一个查询树。 d) 通过索引存储将索引读入到内存。 e) 利用查询树搜索索引，从而得到每个词(Term)的文档链表，对文档链表进行交，差，并得到结果文档。 f) 将搜索到的结果文档对查询的相关性进行排序。 g) 返回查询结果给用户。 下面我们可以进入Lucene的世界了。","categories":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/tags/搜索引擎/"},{"name":"apache lucene","slug":"apache-lucene","permalink":"http://hopperclouds.github.io/tags/apache-lucene/"}],"keywords":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}]},{"title":"认识Apache Lucene","slug":"认识Apache Lucene","date":"2016-08-31T10:00:04.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/08/31/认识Apache Lucene/","link":"","permalink":"http://hopperclouds.github.io/2016/08/31/认识Apache Lucene/","excerpt":"&emsp;&emsp;&emsp;&emsp;为了更深入地理解ElasticSearch的工作原理，特别是索引和查询这两个过程，理解Lucene的工作原理至关重要。本质上，ElasticSearch是用Lucene来实现索引的查询功能的。如果读者没有用过Lucene，下面的几个部分将为您介绍Lucene的基本概念。","text":"&emsp;&emsp;&emsp;&emsp;为了更深入地理解ElasticSearch的工作原理，特别是索引和查询这两个过程，理解Lucene的工作原理至关重要。本质上，ElasticSearch是用Lucene来实现索引的查询功能的。如果读者没有用过Lucene，下面的几个部分将为您介绍Lucene的基本概念。 熟悉Lucene&emsp;&emsp;&emsp;&emsp;读者也许会产生疑问，为什么ElasticSearch 的创造者最终采用Lucene而不是自己开发相应功能的组件。我们也不知道为什么，因为我们不是决策者。但是我们可以猜想可能是因为Lucene是一个成熟的、高性能的、可扩展的、轻量级的，而且功能强大的搜索引擎包。Lucene的核心jar包只有一个文件，而且不依赖任何第三方jar包。更重要的是，它提供的索引数据和检索数据的功能开箱即用。当然，Lucene也提供了多语言支持，具有拼写检查、高亮等功能；但是如果你不需要这些功能，你只需要下载Lucene的核心jar包，应用到你的项目 中就可以了。 总体架构介绍Lucene架构之前必须理解一些基本的概念,才能更好的理解Lucene的架构,这些概念是: Document:它是在索引和搜索过程中数据的主要表现形式，或者称“载体”，承载着我们索引和搜索的数据,它由一个或者多个域(Field)组成。 Field*:它是Document的组成部分，由两部分组成，名称(name)和值(value)。 Term:它是搜索的基本单位，其表现形式为文本中的一个词。 Token:它是单个Term在所属Field中文本的呈现形式，包含了Term内容、Term类型、Term在文本中的起始及偏移位置。 Apache Lucene把所有的信息都写入到一个称为倒排索引的数据结构中。这种数据结构把索引中的每个Term与相应的Document映射起来，这与关系型数据库存储数据的方式有很大的不同。读者可以把倒排索引想象成这样的一种数据结构：数据以Term为导向，而不是以Document为导向。 ElasticSearch Servier (document 1)Mastering ElasticSearch (document 2)Apache Solr 4 Cookbook (document 3)所以索引(以一种直观的形式)展现如下： Term count Docs 4 1 Apache 1 Cookbook 1 ElasticSearch 2 Mastering 1 Server 1 Solr 1 正如所看到的那样，每个词都指向它所在的文档号(Document Number/Document ID)。这样的存储方式使得高效的信息检索成为可能，比如基于词的检索(term-based query)。此外，每个词映射着一个数值(Count)，它代表着Term在文档集中出现的频繁程度。当然，Lucene创建的真实索引远比上文复杂和先进。这是因为在Lucene中，词向量(由单独的一个Field形成的小型倒排索引，通过它能够获取这个特殊Field的所有Token信息)可以存储；所有Field的原始信息可以存储；删除Document的标记信息可以存储……。核心在于了解数据的组织方式，而非存储细节。 每个索引被分成了多个段(Segment)，段具有一次写入，多次读取的特点。只要形成了，段就无法被修改。例如：被删除文档的信息被存储到一个单独的文件，但是其它的段文件并没有被修改。 需要注意的是，多个段是可以合并的，这个合并的过程称为segments merge。经过强制合并或者Lucene的合并策略触发的合并操作后，原来的多个段就会被Lucene创建的更大的一个段所代替了。很显然，段合并的过程是一个I/O密集型的任务。这个过程会清理一些信息，比如会删除.del文件。除了精减文件数量，段合并还能够提高搜索的效率，毕竟同样的信息，在一个段中读取会比在多个段中读取要快得多。但是，由于段合并是I/O密集型任务，建议不好强制合并，小心地配置好合并策略就可以了。 分析你的文本问题到这里就变得稍微复杂了一些。传入到Document中的数据是如何转变成倒排索引的？查询语句是如何转换成一个个Term使高效率文本搜索变得可行？这种转换数据的过程就称为文本分析(analysis) 文本分析工作由analyzer组件负责。analyzer由一个分词器(tokenizer)和0个或者多个过滤器(filter)组成,也可能会有0个或者多个字符映射器(character mappers)组成。 Lucene中的tokenizer用来把文本拆分成一个个的Token。Token包含了比较多的信息，比如Term在文本的中的位置及Term原始文本，以及Term的长度。文本经过tokenizer处理后的结果称为token stream。token stream其实就是一个个Token的顺序排列。token stream将等待着filter来处理。 除了tokenizer外，Lucene的另一个重要组成部分就是filter链，filter链将用来处理Token Stream中的每一个token。这些处理方式包括删除Token,改变Token，甚至添加新的Token。Lucene中内置了许多filter，读者也可以轻松地自己实现一个filter。有如下内置的filter： Lowercase filter：把所有token中的字符都变成小写 ASCII folding filter：去除tonken中非ASCII码的部分 Synonyms filter：根据同义词替换规则替换相应的token Multiple language-stemming filters：把Token(实际上是Token的文本内容)转化成词根或者词干的形式。 所以通过Filter可以让analyzer有几乎无限的处理能力：因为新的需求添加新的Filter就可以了。 索引和查询在我们用Lucene实现搜索功能时，也许会有读者不明觉历：上述的原理是如何对索引过程和搜索过程产生影响？ 索引过程：Lucene用用户指定好的analyzer解析用户添加的Document。当然Document中不同的Field可以指定不同的analyzer。如果用户的Document中有title和description两个Field，那么这两个Field可以指定不同的analyzer。 搜索过程：用户的输入查询语句将被选定的查询解析器(query parser)所解析,生成多个Query对象。当然用户也可以选择不解析查询语句，使查询语句保留原始的状态。在ElasticSearch中，有的Query对象会被解析(analyzed)，有的不会，比如：前缀查询(prefix query)就不会被解析，精确匹配查询(match query)就会被解析。对用户来说，理解这一点至关重要。 对于索引过程和搜索过程的数据解析这一环节，我们需要把握的重点在于：倒排索引中词应该和查询语句中的词正确匹配。如果无法匹配，那么Lucene也不会返回我们喜闻乐见的结果。举个例子：如果在索引阶段对文本进行了转小写(lowercasing)和转变成词根形式(stemming)处理，那么查询语句也必须进行相同的处理，不然就搜索结果就会是竹篮打水——一场空。 Lucence查询语言ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。由于这个原因，我们来深入学习Lucene查询语言，了解其庐山真面目吧。 基础语法用户使用Lucene进行查询操作时，输入的查询语句会被分解成一个或者多个Term以及逻辑运算符号。一个Term，在Lucene中可以是一个词，也可以是一个短语(用双引号括引来的多个词)。如果事先设定规则：解析查询语句，那么指定的analyzer就会用来处理查询语句的每个term形成Query对象。 一个Query对象中会存在多个布尔运算符，这些布尔运算符将多个Term关联起来形成查询子句。布尔运算符号有如下类型： AND(与):给定两个Term(左运算对象和右运算对象)，形成一个查询表达式。只有两个Term都匹配成功，查询子句才匹配成功。比如：查询语句”apache AND lucene”的意思是匹配含apache且含lucene的文档。 OR(或):给定的多个Term，只要其中一个匹配成功，其形成的查询表达式就匹配成功。比如查询表达式”apache OR lucene”能够匹配包含“apache”的文档，也能匹配包含”lucene”的文档，还能匹配同时包含这两个Term的文档。 NOT(非): 这意味着对于与查询语句匹配的文档，NOT运算符后面的Term就不能在文档中出现的。例如：查询表达式“lucene NOT elasticsearch”就只能匹配包含lucene但是不含elasticsearch的文档。 此外，我们也许会用到如下的运算符： +这个符号表明：如果想要查询语句与文档匹配，那么给定的Term必须出现在文档中。例如：希望搜索到包含关键词lucene,最好能包含关键词apache的文档，可以用如下的查询表达式：”+lucene apache”。 -这个符号表明：如果想要查询语句与文档匹配，那么给定的Term不能出现在文档中。例如：希望搜索到包含关键词lucene,但是不含关键词elasticsearch的文档，可以用如下的查询表达式：”+lucene -elasticsearch”。 如果在Term前没有指定运算符，那么默认使用OR运算符。此外，也是最后一点：查询表达式可以用小括号组合起来，形成复杂的查询表达式。比如：elasticsearch AND (mastering OR book) 多域查询当然，跟ElasticSearch一样，Lucene中的所有数据都是存储在一个个的Field中，多个Field形成一个Document。如果希望查询指定的Field,就需要在查询表达式中指定Field Name(此域名非彼域名)，后面接一个冒号，紧接着一个查询表达式。例如：查询title域中包含关键词elasticsearch的文档，查询表达式如下： title:elasticsearch也可以把多个查询表达式用于一个域中。例如：查询title域中含关键词elasticsearch并且含短语“mastering book”的文档，查询表达式如下： title:(+elasticsearch +”mastering book”)当然，也可以换一种写法，作用是一样的： +title:elasticsearch +title:”mastering book”) 词语修饰符除了可以应用简单的关键词和查询表达式实现标准的域查询，Lucene还支持往查询表达式中传入修饰符使关键词具有变形能力。最常用的修饰符，也是大家都熟知的，就是通配符。Lucene支持?和*两种通配符。?可以匹配任意单个字符，而*能够匹配多个字符。 请注意出于性能考虑，默认的通配符不能是关键词的首字母。 此外，Lucene支持模糊查询(fuzzy query)和邻近查询(proximity query)。语法规则是查询表达式后面接一个~符号，后面紧跟一个整数。如果查询表达式是单独一个Term，这表示我们的搜索关键词可以由Term变形(替换一个字符，添加一个字符，删除一个字符)而来，即与Term是相似的。这种搜索方式称为模糊搜索(fuzzy search)。在~符号后面的整数表示最大编辑距离。例如：执行查询表达式 “writer~2”能够搜索到含writer和writers的文档。 当~符号用于一个短语时，~后面的整数表示短语中可接收的最大的词编辑距离(短语中替换一个词，添加一个词，删除一个词)。举个例子,查询表达式title:”mastering elasticsearch”只能匹配title域中含”mastering elasticsearch”的文档，而无法匹配含”mastering book elasticsearch”的文档。但是如果查询表达式变成title:”mastering elasticsearch”~2,那么两种文档就都能够成功匹配了。 此外，我们还可以使用加权(boosting)机制来改变关键词的重要程度。加权机制的语法是一个^符号后面接一个浮点数表示权重。如果权重小于1，就会降低关键词的重要程度。同理，如果权重大于1就会增加关键词的重要程度。默认的加权值为1。可以参考 第2章 活用用户查询语言 的 Lucene默认打分规则详解 章节部分的内容来了解更多关于加权(boosting)是如何影响打分排序的。 除了上述的功能外，Lucene还支持区间查询(range searching),其语法是用中括号或者}表示区间。例如：如果我们查询一个数值域(numeric field)，可以用如下查询表达式： price:[10.00 TO 15.00] 这条查询表达式能查询到price域的值在10.00到15.00之间的所有文档。对于string类型的field，区间查询也同样适用。例如： name:[Adam TO Adria] 这条查询表达式能查询到name域中含关键词Adam到关键词Adria之间关键词(字符串升序，且闭区间)的文档。如果希望区间的边界值不会被搜索到，那么就需要用大括号替换原来的中括号。例如，查询price域中价格在10.00(10.00要能够被搜索到)到15.00(15.00不能被搜索到)之间的文档，就需要用如下的查询表达式： price:[10.00 TO 15.00} 处理特殊字符 如果在搜索关键词中出现了如下字符集合中的任意一个字符，就需要用反斜杠(\\)进行转义。字符集合如下： +, -, &amp;&amp;, || , ! , (,) , { } , [ ] , ^, “ , ~, *, ?, : , \\, / 。例如，查询关键词 abc”efg 就需要转义成 abc\\”efg。","categories":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/tags/搜索引擎/"},{"name":"apache lucene","slug":"apache-lucene","permalink":"http://hopperclouds.github.io/tags/apache-lucene/"}],"keywords":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}]},{"title":"从__str__说开去","slug":"从__str__说开去","date":"2016-08-31T08:00:00.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/08/31/从__str__说开去/","link":"","permalink":"http://hopperclouds.github.io/2016/08/31/从__str__说开去/","excerpt":"__str__ 和 __repr__介绍object.__str__是python中一个常见的特殊方法, 会被内置函数被 str 和 print 调用。常常与它一起出现的还有object.__repr__, 类似地, 它会被内置函数 repr 调用。","text":"__str__ 和 __repr__介绍object.__str__是python中一个常见的特殊方法, 会被内置函数被 str 和 print 调用。常常与它一起出现的还有object.__repr__, 类似地, 它会被内置函数 repr 调用。 区别那么 str 和 repr 同样作为”informal string representation of instances”, 有何区别? 用一句话概括就是: repr is for developers, str is for customers. 这点在IDE中调试时得以展现: 123456789101112131415class Student(object): def __init__(self, name, grade): self.name = name self.grade = grade def __str__(self): return '&#123;0&#125;(&#123;1&#125;)'.format(self.name, self.grade) def __repr__(self): return '&lt;Student&gt;'if __name__ == '__main__': student = Student(name='Roy', grade=11) 在debug模式下, pycharm将 student 展示为: 简洁明了。 __unicode__出场率同样高的还有object.__unicode__, 和object.__str__作用类似, 但不同的是, object.__unicode__ 返回的是一个unicode object, 而 object.__str__ 返回的是string object。这会引起一些问题, 特别是当你在使用python2中的unicode_literals时。 unicode_literalsUnicodeEncodeError我们对上面的代码做一些修改: 1234567891011121314151617# -*- coding: utf-8 -*-from __future__ import unicode_literalsclass Student(object): def __init__(self, name, grade): self.name = name self.grade = grade def __str__(self): return '&#123;0&#125;(&#123;1&#125;)'.format(self.name, self.grade) def __repr__(self): return '&lt;Student&gt;' def __unicode__(self): return '&lt;Student&gt;' 改动在于import了unicode_literals, 并为 Student 添加了一个 __unicode__ 方法, 看起来好像没有什么问题。 但当你实例化一个 Student , 并将 name 指定为中文时: 12student = Student(name='罗伊', grade=11)print student 报错了, UnicodeEncodeError 。 你或许精通python2的中文编码问题, 但也许并没有注意到这个问题。在使用django时遇到过 [Bad Unicode data] 这个东西, 问题是一样的, django在项目中也使用了 unicode_literals 。 问题在哪问题在于 object.__str__ 返回的必须为string object, 而使用 unicode_literals 之后返回的为unicode object, python2解释器会尝试用默认的编码(ascii)对其进行encode, 所以报错。 解决问题unicode_literals 在python2中是个利器, 不能不用。接下来我们用两种方法来解决上面这个问题。 patch这是一种经典的方法: 123import sysreload(sys)sys.setdefaultencoding('utf8') 重载 sys 并将 defaultencoding 从 ascii 修改为 utf-8 , 对含中文的unicode object使用utf-8进行encode是可行的。 装饰器123456789def force_encoded_string_output(func): if sys.version_info.major &lt; 3: def _func(*args, **kwargs): return func(*args, **kwargs).encode(&apos;utf-8&apos;) return _func else: return func 使用 force_encoded_string_output 装饰 object.__str__ 即可, 解决的思路和上面类似。 最佳实践当你在python2中同时使用中文, unicode_literals, __str__, __unicode__ 可以考虑下面的方式: 123456789101112from __future__ import unicode_literalsclass Best(object): def __str__(self): return unicode(self).encode('utf-8') def __unicode__(self): s = 'Put your data here.' assert isinstance(s, unicode) return s","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://hopperclouds.github.io/tags/python/"},{"name":"str","slug":"str","permalink":"http://hopperclouds.github.io/tags/str/"},{"name":"unicode_literals","slug":"unicode-literals","permalink":"http://hopperclouds.github.io/tags/unicode-literals/"},{"name":"Kxrr","slug":"Kxrr","permalink":"http://hopperclouds.github.io/tags/Kxrr/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"前端入门之我见","slug":"前端入门之我见","date":"2016-08-30T14:48:37.000Z","updated":"2016-10-10T03:46:48.000Z","comments":true,"path":"2016/08/30/前端入门之我见/","link":"","permalink":"http://hopperclouds.github.io/2016/08/30/前端入门之我见/","excerpt":"作者：Adam at 2016-08-30 22:48:37 这两周陆陆续续进行了两个独立的前端项目，一个是前后端分离的Angular项目，一个是ES6+Nodejs的全栈项目，前者先做，后者差不多刚完成，最明显的感觉就是写了Angular不想写JQuery，写了ES6不想写ES5。","text":"作者：Adam at 2016-08-30 22:48:37 这两周陆陆续续进行了两个独立的前端项目，一个是前后端分离的Angular项目，一个是ES6+Nodejs的全栈项目，前者先做，后者差不多刚完成，最明显的感觉就是写了Angular不想写JQuery，写了ES6不想写ES5。 我就在想，为什么会有这么强烈感觉？是什么导致的？ 首先，我们来看看前端主要做什么？ 一是页面：HTML+CSS样式布局；二是Javascript脚本：根据页面事件响应、控制页面逻辑。 就这么简单。 然后，CSS样式多了，Javascript函数多了，我们就希望代码好维护，方便调用，少写代码，于是就出现了各种CSS／Javascript框架。 随之而来的问题也出现了，逻辑变复杂，这就需要我们把注释要写清楚，甚至完全文档化。 Javascript写法太自由了，写出来效果往往容易有bug，加上不同浏览器的、不同终端的折腾，好吧，我们把单元测试、界面测试补上，这下总可以了吧。 但是，问题并没有结束。 我们开始思考Javascript是否真的适合写前端页面，为什么Javascript写大型项目这么痛苦？为什么要不断重复写写登录注册？为什么要离不开for循环？为什么不能尽可能高的重用代码？ 我们很早就在说OOP、MVC，也有现在的MVVM、SAM，也出了不少经典框架，但Javascript始终还是Javascript，没有class，没有isArray，只有说不清道不明的 prototype 和 __proto__ 。既然我们知道什么样的语法简洁高效，为什么不让Javascript也能这么做呢？所以，Type Script出来了，Webpack/Babel出来了，ES6出来了。 所以，如果现在你想学前端，直接写ES6吧，有了webpack和babel，以前能做的现在都能做，现在能做的，以前不一定能做。 如今前端也再也不是写写页面、做做脚本，不再是网页三剑客的时代。你还需要精通Sublime/Vim这些编辑器，会架构前端开发环境、熟悉Nodejs/NPM，掌握Phantomjs/Jasmine等测试手段，会用JsDoc写文档。当然，最重要的还是要学好ES6。 最后，我总结一下我学习ES6后，发现的一些好处，希望和大家多交流、沟通～ OOP的原配Class，写起来的酸爽倍儿棒只有自己知道 模块化导入，让我可以前后端共享代码 函数参数的扩展是我的最爱，直接让我轻松20% 代码密集度明显好于过去，这是密集恐惧症的福音 Webpack无疑是前端开发自动化的必备神器，你值得拥有～ 你不再需要模版语言，ES6就是最好的模版语言 一切皆Js，HTML是，CSS也是","categories":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}],"tags":[{"name":"ES6","slug":"ES6","permalink":"http://hopperclouds.github.io/tags/ES6/"},{"name":"Webpack","slug":"Webpack","permalink":"http://hopperclouds.github.io/tags/Webpack/"},{"name":"经验总结","slug":"经验总结","permalink":"http://hopperclouds.github.io/tags/经验总结/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}]},{"title":"聘宝招聘Python实习生","slug":"聘宝招聘Python实习生","date":"2015-09-29T02:51:04.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/29/聘宝招聘Python实习生/","link":"","permalink":"http://hopperclouds.github.io/2015/09/29/聘宝招聘Python实习生/","excerpt":"公司情况现在主要做的产品是 http://www.pinbot.me/ ,已经拿到A轮 坐标：四川成都高新区府城大道399天府新谷9号楼二单元1505成都浩泊云动科技有限公司","text":"公司情况现在主要做的产品是 http://www.pinbot.me/ ,已经拿到A轮 坐标：四川成都高新区府城大道399天府新谷9号楼二单元1505成都浩泊云动科技有限公司 我们的研发团队喜欢什么 K.I.S.S 敏捷开发，快速原型和必要的单元测试 使用*nix 有创造性思维，喜欢创造的人 函数式编程和各种高并发的编程语言（Scheme、Clojure、Golang、Elixir） 为什么招实习生成都Python的圈子本来就小，看来看去就那么些人，大牛实在难搞定，所以希望找到一些有兴趣往Python方向发展的人，一起成长。 在这里你能做什么 了解到Python Web开发常用的工具和流程规范 做一些真正有人使用的产品 一起建设团队，给团队带来更高效的流程和工具 做自己想做的产品，如果你有好的创意都可以跟我们产品经理沟通，将创意实现到产品中 我们能提供什么 Mac和双显是我们日常的开发工具 每周免费的零食 技术分享 每月一次的Hack Day 妹子都是女神级别的，养眼提高工作效率 工作描述 负责http://www.pinbot.me/ 网站新功能的开发和日常维护 负责内部CRM管理系统的开发维护 技能要求# coding: utf-8 &quot;&quot;&quot; 对以下技术熟悉或者有强烈兴趣 &quot;&quot;&quot; # 基本技能 BASIC_SKILL = [ &apos;*nix&apos;, &apos;Vim or Emacs&apos;, &apos;Git&apos;, &apos;Unix哲学&apos;, &apos;基础算法和数据结构&apos;, &apos;计算机组成原理&apos;, &apos;网路协议&apos;, ] # 后端技能 BACKEND_SKILL = [ &apos;Python&apos;, &apos;Django&apos;, &apos;Python常用库&apos;, &apos;了解Http 协议&apos;, &apos;NodeJS&apos;, ] # 前端技能 FRONTEND_SKILL = [ &apos;HTML&apos;, &apos;CSS&apos;, &apos;JS&apos;, &apos;AngularJS&apos;, &apos;React&apos;, &apos;JQuery&apos;, ] # 运维 MAINTAIN_SKILL = [ &apos;bash&apos;, &apos;Docker&apos;, &apos;Fabric&apos;, &apos;Ansible&apos;, &apos;SaltStack&apos;, ] # 数据库 DATABASE = [ &apos;MySQL&apos;, &apos;Mongo&apos;, ] ALL_SKILL = set(i.lower() for i in (BASIC_SKILL + BACKEND_SKILL + FRONTEND_SKILL + MAINTAIN_SKILL + DATABASE)) def i_want_you(your_skill): &quot;&quot;&quot; 符合以上任意关键词就可以了 后续可以让我们的算法工程师来做一个测试程序 &gt;&gt;&gt; i_want_you(&apos;Python HTML Docker MySQL&apos;) I want you &gt;&gt;&gt; i_want_you(&apos;java&apos;) hehe &quot;&quot;&quot; your_skill = [i.lower() for i in your_skill.split()] print &apos;I want you&apos; if set(your_skill).intersection(ALL_SKILL) else &apos;hehe&apos; if __name__ == &apos;__main__&apos;: your_skill = raw_input(&apos;Input your skill: &apos;) i_want_you(your_skill) 补充 有github或者bitbucket等开源社区账号优先 有自己博客的优先 联系我简历请投至：dengyu@hopperclouds.com","categories":[{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/categories/招聘/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://hopperclouds.github.io/tags/Python/"},{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/tags/招聘/"}],"keywords":[{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/categories/招聘/"}]},{"title":"聘宝研发团队必备技能","slug":"聘宝研发团队必备技能","date":"2015-09-24T08:09:24.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/24/聘宝研发团队必备技能/","link":"","permalink":"http://hopperclouds.github.io/2015/09/24/聘宝研发团队必备技能/","excerpt":"简介聘宝(www.pinbot.me) 立志做新一代的智能猎头，让企业招聘变得更简单，我们崇尚敏捷，崇尚开源，崇尚K.I.S.S","text":"简介聘宝(www.pinbot.me) 立志做新一代的智能猎头，让企业招聘变得更简单，我们崇尚敏捷，崇尚开源，崇尚K.I.S.S Web研发团队必备技能后端技术Python (我们主要使用的后端语言) Django (我们正在使用的框架) Python常用库(celery, requests, json, bs4...) HTTP协议 (这个必须会) Unit Test (知道什么地方要有测试) 前端技术HTML Javascript (Node是一个趋势，所以必须会) CSS Angular.js React.js 数据库Mysql Mongo Redis 明确知道不同类型数据库的应用场景，了解数据的设计范式和调优 消息队列RabbitMQ 运维相关Docker (很多东西正在尝试用docker去完成，确实很方便) Ansible (服务器配置管理) 开发环境*nix (必须会，不喜欢windows) VIM (运维要用，必须会) Emacs (看个人爱好) Git及Git开发流程 (必须会) 文档markdown rst 职业素养1. 独立思考，好学 2. 沟通能力强 3. 了解Python哲学 4. 读过程序员修炼之道和代码整洁之道等必读书籍 5. 对程序设计有自己的追求 6. 了解软件工程的思想 推荐技术Golang、Clojure(并发是以后的趋势) 函数式编程语言（可能也是以后的趋势） elixir (聘宝会考虑用它做东西) 总结这个是我们团队的后端必备技能，欢迎大家在评论中补充","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://hopperclouds.github.io/tags/javascript/"},{"name":"Python","slug":"Python","permalink":"http://hopperclouds.github.io/tags/Python/"},{"name":"运维","slug":"运维","permalink":"http://hopperclouds.github.io/tags/运维/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"使用Hexo作为博客","slug":"使用Hexo作为博客","date":"2015-09-24T07:29:25.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/24/使用Hexo作为博客/","link":"","permalink":"http://hopperclouds.github.io/2015/09/24/使用Hexo作为博客/","excerpt":"安装和部署请参考下面或自行google 官网 http://wsgzao.github.io/post/hexo-guide/","text":"安装和部署请参考下面或自行google 官网 http://wsgzao.github.io/post/hexo-guide/ 基本使用准备# 安装node 和 cnpm brew install node npm install cnpm -g # 将项目clone 下来 git clone git@github.com:HopperClouds/hopperclouds.github.io.git # 安装hexo 依赖的node库 cnpm install # 遇到问题 # { [Error: Cannot find module &apos;./build/Release/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # { [Error: Cannot find module &apos;./build/default/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # { [Error: Cannot find module &apos;./build/Debug/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # 使用 cnpm install --no-optional 开始写文章hexo new &quot;your title&quot; # 在source/_posts/your\\ title.md 文件 # 在里面使用markdown编辑博客 # 生成文件格式 title: 使用Hexo作为博客 date: 2015-09-24 15:29:25 # 类别 categories: - 其他 # 标签 tags: - 其他 - 开始 --- markdown格式正文内容 生成文章hexo generate # 使用--watch 参数检测文件更新 hexo generate --watch 预览hexo server 发布hexo deploy 将markdown源码push到source分支git push origin master:source 总结静态博客才是写博客的正确姿势 初次使用觉得不像octopress 那样完善，至于为什么不用octopress, 是因为我们是使用Python和JS的团队，Node对我们来说更友好一些。 对于使用Emacs的用户还没有org mode支持，可以hack一下了。","categories":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/categories/其他/"}],"tags":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/tags/其他/"},{"name":"开始","slug":"开始","permalink":"http://hopperclouds.github.io/tags/开始/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/categories/其他/"}]}]}