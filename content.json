{"meta":{"title":"聘宝研发","subtitle":"一群有追求的人","description":"做有趣的事","author":"聘宝研发","url":"http://hopperclouds.github.io"},"pages":[],"posts":[{"title":"","slug":"openvpn","date":"2016-09-08T11:33:18.000Z","updated":"2016-09-08T11:33:18.000Z","comments":true,"path":"2016/09/08/openvpn/","link":"","permalink":"http://hopperclouds.github.io/2016/09/08/openvpn/","excerpt":"","text":"#OpenVPN服务部署使用[TOC] ##1 服务端部署（Ubuntu） ###1.1 安装OpenVPN 所需插件1234$ sudo apt-get install openssl$ sudo apt-get install libssl-dev$ sudo apt-get install libpam0g-dev$ sudo apt-get install liblzo2-dev ###1.2 安装OpenVPN注:以下安装方式任选一种,推荐apt-get方式安装 ####1.2.1 apt-get安装OpenVPN123$apt-get install openvpn$cd /etc/openvpn$mkdir conf log ####1.2.2 源码安装OpenVPN（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 ###1.3 开启内核转发并配置源地址路由12$ echo \"1\" &gt; /proc/sys/net/ipv4/ip_forward $ iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE ###1.4 服务端配置 ####1.4.1 生成密钥123456789$ cd openvpn-2.2.2/easy-rsa/2.0 $ source ./vars # 在此之前，可以修改vars文件对国家省份等修改;配置dh的位数(默认是1024，可以改成export KEY_SIZE=2048)和下文生成的dh2048.pem相对应$ ./clean-all $ ./build-ca $ ./build-key-server server # 产生服务器证书，此处的server是文件名参数，可以任意修改。$ ./build-key-pass client1 # 生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码$ ./build-dh # 产生Diffie Hellman参数至此一个客户端所需的证书已经完毕，都在easy-rsa/2.0/keys文件夹下面，其中ca.crt server.crt server.csr server.key dh1024.pem是服务端所需证书文件，ca.crt ca.key client1.crt client1.csr client1.key是客户端所需证书文件。注：可以继续使用./build-key产生更多客户端证书,一个客户端证书只能同时用于一个客户端连接。 ####1.4.2 服务端配目录及文件123$ cd openvpn &amp;&amp; mkdir conf # openvpn就是第2步中openvpn的安装目录 $ cp openvpn-2.2.2/sample-config-files/server.conf conf/$ cp openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,server.crt,server.csr,server.key,dh1024.pem&#125; conf/ # 拷贝openvpn-2.2.2/easy-rsa/2.0/keys/下的相关证书文件到openvpn/conf/目录下，注意:2048位的key则是dh2048.pem; 1024位的key则是dh1024.pem ####1.4.3 服务端配置文件参数指定123456789101112131415161718192021$ vim conf/server.confdev tapproto tcpport 1194ca /path/to/openvpn/conf/ca.crtcert /path/to/openvpn/conf/server.crtkey /path/to/openvpn/conf/server.keydh /path/to/openvpn/conf/dh1024.pemuser nobodygroup nogroupserver 10.8.0.0 255.255.255.0 # 分配给clinet的ip段second time periodkeepalive 10 120 # 每10秒ping一次，120秒内客户端没有动作就断开连接persist-keypersist-tunverb 4log-append /path/to/openvpn/log/openvpn.logstatus /path/to/openvpn/log/openvpn-status.logclient-to-clientcrl-verify /path/to/openvpn/conf/crl.pem # 客户端证书连接限制comp-lzo ###1.5 启动OpenVPN服务端1sudo /path/to/openvpn/sbin/openvpn --config /path/to/openvpn/conf/server.conf --daemon ###1.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.1 inet 10.8.0.1 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.1 则说明VPN服务端配置成功 ###1.7 设置OpenVPN服务端开机启动123$ vim /etc/rc.localiptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE/path/to/openvpn/sbin/openvpn --config /path/to/openvpn/conf/server.conf --daemon ##2 OpenVPN 客户端部署(MAC系统) ###2.1 安装OpenVPN 所需插件1$ sudo brew install openssl ###2.2 安装OpenVPN注:以下安装方式任选一种,推荐Brew方式安装 ####2.2.1 Brew 安装12345直接brew安装(推荐)$brew install openvpn$cd /usr/local/Cellar/openvpn/2.3.11_1$mkdir conf log$ln -s /usr/local/Cellar/openvpn/2.3.11_1/sbin/openvpn /usr/local/bin/openvpn ####2.2.2 源码安装（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 ###2.3 服务端生成客户端所需密钥(客户端部署可忽略此步骤) ####2.3.1 服务端连接1234服务端所在机器：xxx.xxx.xxx.xxx $ssh root@xxx.xxx.xxx.xxx #连接方式$cd /media/openvpn/ 服务端所在路径$cd /media/openvpn-2.2.2/easy-rsa/2.0 生成密钥所需路径 ####2.3.2 生成密钥12$ source ./vars $ ./build-key-pass client-A #此处设置密码为：openvpn123 注：生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码1$ ./build-dh ####2.3.3设置客户端密钥验证信息12$ vim /media/openvpn/conf/ccd/client-A ifconfig-push 10.8.0.119 255.255.255.0 注：此处的验证信息文件名需要和生成密钥时输入的名字保持一致;10.8.0.119 指客户端被虚拟出来的IP ###2.4 客户端配置 ####2.4.1 拷贝密钥到客户端12$scp root@xxx.xxx.xxx.xxx:/media/openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,ca.key,client-A.crt,client-A.csr,client-A.key&#125; /usr/local/Cellar/openvpn/2.3.11_1/conf/注:密钥可以由维护人员发放,联系刘东; ####2.4.2 配置客户端密码文件12$ vim /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt openvpn123 注:客户端密码文件和服务端生成密钥时输入的密码一致 ####2.4.3 客户端配置文件1234567891011121314151617181920212223$ vim /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf client dev tap proto tcp remote xxx.xxx.xxx.xxx 1194 #指定服务端外网IP及端口nobind user nobody group nogroup ca /usr/local/Cellar/openvpn/2.3.11_1/conf/ca.crt cert /usr/local/Cellar/openvpn/2.3.11_1/conf/client-A.crt key /usr/local/Cellar/openvpn/2.3.11_1/conf/client-A.key ping 15 ping-restart 45 ping-timer-rem persist-key persist-tun ns-cert-type server comp-lzo verb 4 log-append /usr/local/Cellar/openvpn/2.3.11_1/log/openvpn.log status /usr/local/Cellar/openvpn/2.3.11_1/log/openvpn-status.log tcp-queue-limit 4096 # 256 bcast-buffers 4096 ###2.5 启动客户端 ####2.5.1 命令行启动OpenVPN1$ sudo /usr/local/bin/openvpn --config /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf --askpass /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt --daemon ####2.5.2 GUI启动OpenVPN 下载Tunnelblick客户端直接官网下载: https://tunnelblick.net/downloads.html 安装Tunnelblick客户端Tunnelblick具体安装使用流程见：Mac系统Tunnelblick下载以及安装流程 ###2.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.119 inet 10.8.0.119 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.x 则说明VPN客户端配置成功1$ ping 10.8.0.1 #检查是否能ping通内网等机器 ###2.7 服务加入开机自启动12vim /etc/rc.local/usr/local/bin/openvpn --config /usr/local/Cellar/openvpn/2.3.11_1/conf/client.conf --askpass /usr/local/Cellar/openvpn/2.3.11_1/conf/password.txt --daemon ##3 OpenVPN 客户端部署(Ubuntu系统) ###3.1 安装OpenVPN 所需插件1234$ sudo apt-get install openssl$ sudo apt-get install libssl-dev$ sudo apt-get install libpam0g-dev$ sudo apt-get install liblzo2-dev ###3.2 安装OpenVPN注:以下安装方式任选一种,推荐apt-get方式安装 ####3.2.1 apt-get安装OpenVPN123$apt-get install openvpn$cd /etc/openvpn$mkdir conf log ####3.2.2 源码安装OpenVPN（建议使用2.2.2版本）12345$ wget http://swupdate.openvpn.org/community/releases/openvpn-2.2.2.tar.gz $ tar -zxvf openvpn-2.2.2.tar.gz $ mkdir /data/openvpn &amp;&amp; cd openvpn-2.2.2 $ ./configure --enable-password-save --prefix=/etc/openvpn $ make &amp;&amp; sudo make install 注：–enable-password-save该选项是避免手工输入客户端密码；–prefix选项是真正的安装路径 ###3.3 服务端生成客户端所需密钥(客户端部署可忽略此步骤) ####3.3.1 服务端连接1234服务端所在机器：xxx.xxx.xxx.xxx $ssh root@xxx.xxx.xxx.xxx #连接方式$cd /media/openvpn/ 服务端所在路径$cd /media/openvpn-2.2.2/easy-rsa/2.0 生成密钥所需路径 ####3.3.2 生成密钥12$ source ./vars $ ./build-key-pass client-B #此处设置密码为：openvpn123 注：生成客户端key，pass表示需要输入一个密码作为客户端启动时的凭证； ./build-key则不需要输入密码1$ ./build-dh ####3.3.3设置客户端密钥验证信息12$ vim /media/openvpn/conf/ccd/client-B ifconfig-push 10.8.0.120 255.255.255.0 注：此处的验证信息文件名需要和生成密钥时输入的名字保持一致;10.8.0.120 指客户端被虚拟出来的IP ###3.4 客户端配置 ####3.4.1 拷贝密钥到客户端12$scp root@xxx.xxx.xxx.xxx:/media/openvpn-2.2.2/easy-rsa/2.0/keys/&#123;ca.crt,ca.key,client-B.crt,client-B.csr,client-B.key&#125; /etc/openvpn/conf注:密钥可以由维护人员发放,联系刘东; ####3.4.2 配置客户端密码文件12$ vim /etc/openvpn/conf/password.txt openvpn123 注:客户端密码文件和服务端生成密钥时输入的密码一致 ####3.4.3 客户端配置文件12345678910111213141516171819202122232425262728$ vim /etc/openvpn/conf/client.conf client dev tap proto tcp remote xxx.xxx.xxx.xxx 1194 #指定服务端外网IP及端口nobind user nobody group nogroup ca /etc/openvpn/conf/ca.crt cert /etc/openvpn/conf/client-B.crt key /etc/openvpn/conf/client-B.key ping 15 ping-restart 45 ping-timer-rem persist-key persist-tun ns-cert-type server comp-lzo verb 4 log-append /etc/openvpn/log/openvpn.log status /etc/openvpn/log/openvpn-status.log tcp-queue-limit 4096 # 256 bcast-buffers 4096 ###3.5 启动客户端1$ sudo openvpn --config /etc/openvpn/conf/client.conf --askpass /etc/openvpn/conf/password.txt --daemon ###3.6 检查验证12$ ifconfig|grep inet|grep 10.8.0.120 inet 10.8.0.120 netmask 0xffffff00 broadcast 10.8.0.255 注：得到IP为：10.8.0.x 则说明VPN客户端配置成功1$ ping 10.8.0.1 #检查是否能ping通内网等机器 ###3.7 服务加入开机自启动12vim /etc/rc.localopenvpn --config /etc/openvpn/conf/client.conf --askpass /etc/openvpn/conf/password.txt --daemon","categories":[],"tags":[],"keywords":[]},{"title":"django自定义storage","slug":"django自定义storage","date":"2016-09-08T11:31:22.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/09/08/django自定义storage/","link":"","permalink":"http://hopperclouds.github.io/2016/09/08/django自定义storage/","excerpt":"最近遇到了这样的一个问题，由于某些原因，需要把静态文件放到cdn上，之前使用的是django默认的storage（FileSystemStorage）。于是这里需要自定义storage。第一次写storage，过程中遇到一些坑，记录下来。","text":"最近遇到了这样的一个问题，由于某些原因，需要把静态文件放到cdn上，之前使用的是django默认的storage（FileSystemStorage）。于是这里需要自定义storage。第一次写storage，过程中遇到一些坑，记录下来。 什么是storage其实这个玩意要我说明白，好像有点难，于是我就按我的方法说，如果有错，谢谢指正！首先，我们的web中使用了许多的模版文件，静态文件，如js,css，图片这些，我们在配置服务器的时候，让nginx对请求进行分发，将动态请求分发给uWSGI，将静态文件交由nginx处理，这里nginx将从文件系统中读取静态资源，这里的文件系统就是我们当前的storage。但是这里我们是想用cdn，于是我们这里的静态资源不在从服务器上加载，而是从我们的cdn服务提供商那里加载，这里我们又有一个问题了，cdn服务提供商怎么给出正确的资源，于是我们就需要自己来写一个storage，将原来的文件系统更换为cdn提供商的空间。 storage的结构和重写这里就需要参考django的官方文档了(原版,翻译版)，由于我的外语水平不是很好，做的时候为了图效率，就没有花时间去琢磨英文官方文档，所以这里给一个翻译的文档地址，当然，如果你能很快看明白官方的文档，那去读原版是更好的选择。首先，我们看文件系统的基类，其源码位于django/core/files/storage.py文件下。这里我就不贴它的代码了，如果需要查看结构，请自行到该文件下查看！从文档中，我们可以了解的一些东西，这个类的子类需要不带参数实例化，于是我们需要在settings中加入自定义的参数。1234567891011STATICFILES_STORAGE = 'project.storage.CustomStorage'CUSTOM_STORAGE_OPTIONS = &#123; 'AccessKeyId': 'your_accesskeyid', 'AccessKeySecret': 'your_accesskeyidsecret', 'endpoint': 'oss-cn-hangzhou.aliyuncs.com', 'oss_url': 'http://oss-cn-hangzhou.aliyuncs.com', 'bucketname': 'your_bucketname',&#125;COMPRESS_STORAGE = 'project.storage.CustomCompressorFileStorage'STATIC_URL = 'your_cdn_prefix_address' 参数说明： 这里我们指定了STATICFILES_STORAGE为我们自定义的CustomStorage,如果不指定，那么系统将会使用默认的FileSystemStorage CUSTOM_STORAGE_OPTIONS是一个你自定义的Storage初始化参数，这里我用字典来初始化，当然，你可以使用你觉得合理的任何数据类型。 COMPRESS_STORAGE是我们指定的压缩文件的存放位置，与STATICFILES_STORAGE同理。 STATIC_URL这个就是静态文件的路由前缀，例如你的文件系统中路径是’aa/bb.js’，你的cdn地址是’static.cdn.com’，这里就使用cdn地址作为你的STATIC_URL 从文档中，我们可以知道，自定义的storage，必须实现_open,_save两个方法，我们参考源码可以知道，这两个方法分别被save和open两个方法调用，而这两个方法的作用分别是‘打开文件，读取内容’、‘将文件保存到指定的位置’，由此，我们需要自己定义的存储就在这里来实现。由于这里我采用的是阿里云的oss，所以认证的过程，我们放在构造函数中完成，本着D.R.Y的原则，为了让多个自定义的storage可以使用，我们将它放在外部，只在构造函数里来使用它。123456789101112131415def authticate(option): auth = oss2.Auth( option.get('AccessKeyId'), option.get('AccessKeySecret') ) service = oss2.Service( auth, option.get('endpoint') ) bucket = oss2.Bucket( auth, option.get('oss_url'), option.get('bucketname') )return (auth, service, bucket) 认证过后，就可以重写save过程了。123456def _save(self, name, content): self.bucket.put_object( name, content ) return name 这里我们使用的是阿里云的oss，它的save就这么简单。文档可以直接google阿里云oss！这里就不贴出来了！哈哈，这里是不是很简单！其实理解了它的各个方法，真的很简单…………继续，由于open方法是打开本地文件系统的文件，我们就不重写它了。其他的方法。文档中说到，delete()，exists()，listdir()，size()，url() 这几个方法都需要被覆写，不然就会抛出NotImplementedError异常。这里我们通过源码可以解释一下，这些玩意在干嘛。 delete方法：顾名思义，就是删除，此方法被调用时，从storage中删除文件 exists方法：额，还是顾名思义，就是判断是否存在该文件，返回布尔值 listdir方法：返回文件列表 size方法：返回文件大小 url方法：这个方法需要提一下，我在之前重写的时候，直接pass了，所以，我在打开xadmin时，就会一直报错，于是我就找了很久的原因，我在这个函数中下了断点，最后发现，这个函数是必须自己重新写的（如果你的文件是静态文件，可以通过url访问的话）。因为如果不重写它，返回的是一个None，于是该文件就没有url可以访问，在某些需要判断的地方，也会报错！ 最后不同的云服务提供商的上传方式可能不一样，但是原理都是一样的，重写save方法，改为上传到云端，重写需要使用的方法。最后collectstatic,compress即可。","categories":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/tags/django/"},{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/tags/技术/"}],"keywords":[{"name":"django","slug":"django","permalink":"http://hopperclouds.github.io/categories/django/"}]},{"title":"react入门介绍","slug":"react入门介绍","date":"2016-09-06T10:30:30.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/09/06/react入门介绍/","link":"","permalink":"http://hopperclouds.github.io/2016/09/06/react入门介绍/","excerpt":"","text":"react.js介绍react.js的提出react.js的首次提出是在2014年Facebook的f8大会上。顺便科普一下f8大会，f8大会是由Facebook组织的年度的技术峰会，之所以叫f8，就是看大家在8小时以内能做出哪些有意思的东西。react.js称为颠覆式前端UI开发框架。目前基于html的前端开发变得越来越复杂，传统的开发方式基于来自服务器和来自用户输入的交互数据,动态反应到复杂界面的时候，代码量变得越来越大，难以维护。比如，前端开发框架jquey，每次数据更新，必须手动把数据更新渲染到ui界面上,代码量极大。基于此，google推出的angular.js的双向数据绑定很好的解决了这个问题。但是angular.js也有自身的一些不足。1：angular过重，不适用于对性能要求特别高的站点。2：ui组件封装比较复杂，不利于重用。而react解决了所有的这些问题。ReactJS官网地址：http://facebook.github.io/react/Github地址：https://github.com/facebook/react react.js的特点1、就是轻，数据渲染响应非常快。复杂或频繁的DOM操作通常是性能瓶颈产生的原因。React为此引入了虚拟DOM（Virtual DOM）的机制：在浏览器端用Javascript实现了一套DOM API。基于React进行开发时所有的DOM构造都是通过虚拟DOM进行，每当数据变化时，React都会重新构建整个DOM树，然后React将当前整个DOM树和上一次的DOM树进行对比，得到DOM结构的区别，然后仅仅将需要变化的部分进行实际的浏览器DOM更新。尽管每一次都需要构造完整的虚拟DOM树，但是因为虚拟DOM是内存数据，性能是极高的，而对实际DOM进行操作的仅仅是Diff部分，因而能达到提高性能的目的。 2：组件化开发思想。React推荐以组件的方式去重新思考UI构成，将UI上每一个功能相对独立的模块定义成组件，然后将小的组件通过组合或者嵌套的方式构成大的组件，最终完成整体UI的构建。 react试用场景react 这么厉害到底适用于哪些场景呢？1、复杂场景下的高性能要求。2、重用组件库，组件组合。 react html、css基础实践下面让我们来看看一组代码： 1234567891011121314151617181920212223242526272829&lt;html&gt;&lt;head&gt; &lt;script src=\"../build/react.js\"&gt;&lt;/script&gt; &lt;script src=\"../build/react-dom.js\"&gt;&lt;/script&gt; &lt;script src=\"../build/browser.min.js\"&gt;&lt;/script&gt; &lt;style type=\"text/css\"&gt; .redColor&#123; color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"example\"&gt;&lt;/div&gt; &lt;script type=\"text/babel\"&gt; var Hello = React.createClass(&#123; render:function()&#123; var styleObj = &#123; textDecoration:'underline' &#125;; return &lt;div className=\"redColor\" style=&#123;&#123;fontSize:'18px'&#125;&#125;&gt;Hello &#123;this.props.name&#125;&lt;/div&gt; &#125; &#125;); ReactDOM.render( &lt;Hello name=\"World\"/&gt;, document.getElementById('example') ); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 现在来解释一下这段代码1.react用的是jsx，是facebook为react开发的一套语法糖。语法糖是计算机中添加的一种语法，对语言的功能没有影响，但是更方便程序员使用，增加可读性减少程序出错机会。类似的还有CoffeeScript、TypeScript等。最终都被解析库解析成js。这里引入的browser.js 就是jsx的解析库。作用是将 JSX 语法转为 JavaScript 语法。另外 &lt;script&gt; 标签的 type 属性为 text/babel 。表明这是jsx语法。 2.jsx为我们带来的便利就是，我们可以在js里写类dom的结构，比我们用原生js拼接字符串要简单方便许多。jsx语法允许我们生成原生的dom标签，还可以生成自定义标签。比如hello，这些统称为react components.通过调用ReactDOM将react components呈现在页面上。 3.ReactDOM.render是React的最基本方法，用于将模板转为 HTML 语言，并插入指定的 DOM 节点。第一个参数是要插入的components，第二个参数是要插入的容器。自定义的标签是通过React.createClass申明，参数是一个js的对象。return的内容就是渲染的结构。遇到 HTML 标签（以 &lt; 开头），就用 HTML 规则解析；遇到代码块（以 { 开头），就用 JavaScript 规则解析。 4.给标签添加css属性有两种： 一种：用外联样式，注意这里是className，因为这是jsx语法，class在js中已经是一个保留关键字。 二种：内联样式。在react中内联样式必须用样式对象来表示，在react中内联样式必须用样式对象来表示，必须用驼峰。且用｛｛｝｝包裹。这里为什么要用｛｛｝｝，让我们再看看另一种写法就一目了然了。 123456789101112131415&lt;div id=\"example\"&gt;&lt;/div&gt;&lt;script type=\"text/babel\"&gt; var Hello = React.createClass(&#123; render:function()&#123; var styleObj = &#123; fontSize:'18px' &#125;; return &lt;div className=\"redColor\" style=&#123;styleObj&#125;&gt;Hello &#123;this.props.name&#125;&lt;/div&gt; &#125; &#125;); ReactDOM.render( &lt;Hello name=\"World\"/&gt;, document.getElementById('example') );&lt;/script&gt; 这里申明一个样式对象，用｛｝包裹就能以js的方式来解析。和｛｛fontSize:&quot;18px&quot;｝｝异曲同工。可以隐约的看到，react的组件通过样式对象的申明可以，react组件是html、css、js的集合，成为真正意义上的独立组件。 这次我们简单介绍了react的由来、特点、应用场景。以及，jsx语法糖，如何生成自定义标签，插入节点，添加css样式，这些都是react的基础，接下来，我们继续react compenents的生命周期。","categories":[],"tags":[],"keywords":[]},{"title":"Python-Web并发重复数据防守策略","slug":"Python-Web并发重复数据防守策略","date":"2016-09-02T09:51:45.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/09/02/Python-Web并发重复数据防守策略/","link":"","permalink":"http://hopperclouds.github.io/2016/09/02/Python-Web并发重复数据防守策略/","excerpt":"","text":"作者：jackie 1.重复数据提交原因 恶意用户脚本攻击 web页面按钮卡顿重复点击引起 2.服务器优化方向 web服务器层防御，如nginx可以限制单一IP每秒钟的访问次数 应用层防御，通过web应用程序进行控制 数据层防御 3.常规防冲击 nginx 配置 –访问速率控制12345server &#123; ... location /download/ &#123; limit_conn addr 100; #单一IP每秒钟最多访问100次 &#125; 在代理层防御主要应对于大规模高并发，例如有恶意用户高速率抓取本网站数据，导致网站服务性能下降时，就需要进行IP访问速率限制；但是考虑到国内网络环境，基本绝大用户都是共享公共IP进行上网，所以此限制也并不是一定会打开。 黑名单机制 –防恶意攻击 网络服务商控制，例如使用阿里云的可以通过阿里云的安全策略配置进行设置黑名单。 服务器 本地防火墙策略 web服务器 nginx配置黑名单 web应用中通过缓存黑名单进行控制 4.异常访问带来的数据重复如何规避 数据表多字段进行联合唯一索引，通过数据库的限制进行脏数据的排除。 (推荐) 数据库加锁，分悲观锁和乐观锁，具体概念不做讲述，一旦加了锁，也就给开发者自己加了锁，自己琢磨去吧。 具体业务进行单一服务化，单实例进行处理，可通过MQ与主业务服务进行交互。（推荐） 5.具体的某个应用服务如何进行访问速率限制 直接上代码了，通过redis的原子操作机制设定计数器，也可称为限速器。123456789101112131415161718192021def limit_api_call(key, limit, timeout): \"\"\" API限速器 :param key: :param limit:限制次数 :param timeout: 单位时间 :return: True or False \"\"\" lua_incr = \"\"\" local current current = redis.call(\"incr\",KEYS[1]) if tonumber(current) == 1 then redis.call(\"expire\",KEYS[1],ARGV[1]) end return current \"\"\" current = client.eval(lua_incr, 1, key, timeout) current = int(current) if current &gt; limit: return False return True Reids官方文档中也提供了其他几种实现方式，但是除了是用lua脚本原子操作进行辅助，其他都只能概率限制，无法准确限速。","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://hopperclouds.github.io/tags/python/"},{"name":"HTTP","slug":"HTTP","permalink":"http://hopperclouds.github.io/tags/HTTP/"},{"name":"并发","slug":"并发","permalink":"http://hopperclouds.github.io/tags/并发/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"JavaScript之递归","slug":"JavaScript之递归","date":"2016-09-01T16:52:45.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/09/02/JavaScript之递归/","link":"","permalink":"http://hopperclouds.github.io/2016/09/02/JavaScript之递归/","excerpt":"","text":"作者：纯利 那么什么叫递归呢？所谓递归函数就是在函数体内调用本函数。最简单的例子就是计算阶乘。0和1的阶乘都会被定义为1，更大的数的阶乘是通过计算11…来求得的，每次增加1，直至达到要计算阶乘的那个数。 递归的缺点：如果递归函数的终止条件不明确或者缺少终止条件会导致函数长时间运行，是用户界面处于假死状态。值得注意的是：浏览器对递归的支持熟练与JS调用栈大小直接相关，当使用太多递归甚至超过最大调用栈容量时，浏览器会报错误信息，各个浏览器对报错的提示信息也不一样。 下面我们先来看一下一个经典的递归阶乘函数：1234567function test(num)&#123; if(num &lt;= 1)&#123; return 1; &#125;else&#123; return num * test(num-1); &#125;&#125; 上面的的这个函数表面上没有什么问题，但是以下的代码却可能会导致问题：123var f = test;test = null;console.log(f(2));//报错 Uncaught TypeError: test is not a function 指向原始函数的引用就剩下一个，当调用f()函数时，而test已经不再是一个函数了，所以会导致错误，但是我们可以使用arguments.callee来解决这个问题。 大家都知道，arguments.callee是一个指向正在执行的函数的指针，因此可以用它来实现函数的递归调用,看如下代码：1234567function test(num)&#123; if(num &lt;= 1)&#123; return 1; &#125;else&#123; return num * arguments.callee(num-1); &#125;&#125; 这样即使函数赋值给了另外一个变量，f()函数依然是有效的，所以递归调用能正常完成。而且这种方式在严格模式和非严格模式下都可以使用哦。","categories":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://hopperclouds.github.io/tags/javascript/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}]},{"title":"数据处理/分析/可视化飞艇(zeppelin)介绍","slug":"数据处理-分析-可视化飞艇-zeppelin-介绍","date":"2016-08-31T17:35:55.000Z","updated":"2016-08-31T17:35:55.000Z","comments":true,"path":"2016/09/01/数据处理-分析-可视化飞艇-zeppelin-介绍/","link":"","permalink":"http://hopperclouds.github.io/2016/09/01/数据处理-分析-可视化飞艇-zeppelin-介绍/","excerpt":"","text":"author: likaiguo Zeppelin(飞艇)Zeppelin思维导图 推荐查看思维导图中的各个链接,尤其是官方文档和中文翻译. 快速搭建Zeppelin环境安装过程 到官网下载二进制包（http://zeppelin.apache.org/download.html） 解压到本地(保证已经设置好Java环境) 运行Zeppelin服务bin/zeppelin-daemon.sh start|stop|restart 浏览器中打开：http://localhost:8080 即可进入Zeppelin首页。 Zeppelin是什么?A web-based notebook that enables interactive data analytics.You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more. 一款基于web页面的笔记本(类似ipython中的notebook),其提供交互式数据分析功能.使用Zeppelin(飞艇)我们能使用如SQL,Scala等后端语言制作出数据驱动的,交互式的并且易于协作的文档. Zeppelin基本概念1.支持多种后端语言,Interpreter(解释器) 抽象出解释器概念,运行各种语言和数据处理后端工具.在Zeppelin中解释器被设计为可插拔的模块.目前支持各种各样的解释器,如上图所示包括Apache Spark, Python, JDBC, Markdown and Shell等等. 同时也可以写自己需要的解释器. 在现有的解释器的基础上配置对应的参数生成新的解释器 写相关的Java或者scala程序开发更加特定的解释器[参考文献2] 2.强大的数据可视化能力 Zeppelin具有较为常用的数据可视化的图表. 如上图所示,表格,柱状图,饼图,趋势图,散点图一应俱全. 数据可视化不仅限于Spark SQL,任意一种语言的表格输出都能被完美转译成对应的图表. 并且能够导出对应的CSV等类型数据. 3.数据透视表Apache Zeppelin aggregates values and displays them in pivot chart with simple drag and drop. You can easily create chart with multiple aggregated values including sum, count, average, min, max. 飞艇能够在页面上通过简单的拖拽进行各种聚合操作,并且展示出对应的数据透视表.同时也可以很容易通过求和,计数,平均,最小,最大创建各种聚合值的图表. 4.动态表格Zeppelin可以通过动态表格方式在notebook中添加诸如: 文本框,复选框,单选框等表单元素.通过这种方式,我们可以快速进行对应的动态操作. 典型应用: 这里${maxAge=30}的写法表示一个文本框元素,并且默认值为30。当修改对应的值是下方的图表会对应产生变化。 https://zeppelin.apache.org/docs/latest/manual/dynamicform.html 文档很重要. 遇到一个奇怪的问题:当使用下拉框时,对应的值可以实时变化. 其他如文本框,复选框都不实时变化,需要点击三角形run按钮才能生效. 5.将notebook共享给他人,更好的协作 可以直接将写好的notebook发送给其他人,放入工程的notebook目录下即可 可以将生成的图表共享给他人(复制对应的link,参见文献2和官方文档) Zeppelin使用场景(特点)?apache zeppelin应该会很吸引分布式计算、数据分析从业者,是个值得把玩的算比较前卫的项目。 代码量少， 模块很清楚， 可以尝试接入多种不同计算引擎， 实时任务运行、可视化效果 没有过多复杂的操作，只是区分了多个notebook， 每个notebook里做单独的分析处理工作，流程和结果会被保存下来。 此外，为spark做了更好的支持，比如默认是scala环境，默认sc已经创建好，即spark local可跑，默认spark sql有可视化效果。 一站式数据分析: 文档,不同工具集一应俱全 Zeppelin怎样服务于我们的业务? 应用于快速导入数据并且进行可视化 将多种数据处理技术和语言融合在一起 优美文档书写 快速给客户提供数据可视化服务 Zeppelin常见问题参考文献 Apache Zeppelin简介 Apache Zeppelin安装及介绍 让Spark如虎添翼的Zeppelin – 基础篇 Zeppelin 小试牛刀 – 使用Zeppelin展示MySQL的数据 Hadoop - Zeppelin 使用心得","categories":[{"name":"大数据","slug":"大数据","permalink":"http://hopperclouds.github.io/categories/大数据/"}],"tags":[{"name":"spark","slug":"spark","permalink":"http://hopperclouds.github.io/tags/spark/"},{"name":"pyspark","slug":"pyspark","permalink":"http://hopperclouds.github.io/tags/pyspark/"}],"keywords":[{"name":"大数据","slug":"大数据","permalink":"http://hopperclouds.github.io/categories/大数据/"}]},{"title":"认识Apache Lucene","slug":"认识Apache Lucene","date":"2016-08-31T10:00:04.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/08/31/认识Apache Lucene/","link":"","permalink":"http://hopperclouds.github.io/2016/08/31/认识Apache Lucene/","excerpt":"","text":"&emsp;&emsp;&emsp;&emsp;为了更深入地理解ElasticSearch的工作原理，特别是索引和查询这两个过程，理解Lucene的工作原理至关重要。本质上，ElasticSearch是用Lucene来实现索引的查询功能的。如果读者没有用过Lucene，下面的几个部分将为您介绍Lucene的基本概念。 熟悉Lucene&emsp;&emsp;&emsp;&emsp;读者也许会产生疑问，为什么ElasticSearch 的创造者最终采用Lucene而不是自己开发相应功能的组件。我们也不知道为什么，因为我们不是决策者。但是我们可以猜想可能是因为Lucene是一个成熟的、高性能的、可扩展的、轻量级的，而且功能强大的搜索引擎包。Lucene的核心jar包只有一个文件，而且不依赖任何第三方jar包。更重要的是，它提供的索引数据和检索数据的功能开箱即用。当然，Lucene也提供了多语言支持，具有拼写检查、高亮等功能；但是如果你不需要这些功能，你只需要下载Lucene的核心jar包，应用到你的项目 中就可以了。 总体架构介绍Lucene架构之前必须理解一些基本的概念,才能更好的理解Lucene的架构,这些概念是: Document:它是在索引和搜索过程中数据的主要表现形式，或者称“载体”，承载着我们索引和搜索的数据,它由一个或者多个域(Field)组成。 Field*:它是Document的组成部分，由两部分组成，名称(name)和值(value)。 Term:它是搜索的基本单位，其表现形式为文本中的一个词。 Token:它是单个Term在所属Field中文本的呈现形式，包含了Term内容、Term类型、Term在文本中的起始及偏移位置。 Apache Lucene把所有的信息都写入到一个称为倒排索引的数据结构中。这种数据结构把索引中的每个Term与相应的Document映射起来，这与关系型数据库存储数据的方式有很大的不同。读者可以把倒排索引想象成这样的一种数据结构：数据以Term为导向，而不是以Document为导向。 ElasticSearch Servier (document 1)Mastering ElasticSearch (document 2)Apache Solr 4 Cookbook (document 3)所以索引(以一种直观的形式)展现如下： Term count Docs 4 1 Apache 1 Cookbook 1 ElasticSearch 2 Mastering 1 Server 1 Solr 1 正如所看到的那样，每个词都指向它所在的文档号(Document Number/Document ID)。这样的存储方式使得高效的信息检索成为可能，比如基于词的检索(term-based query)。此外，每个词映射着一个数值(Count)，它代表着Term在文档集中出现的频繁程度。当然，Lucene创建的真实索引远比上文复杂和先进。这是因为在Lucene中，词向量(由单独的一个Field形成的小型倒排索引，通过它能够获取这个特殊Field的所有Token信息)可以存储；所有Field的原始信息可以存储；删除Document的标记信息可以存储……。核心在于了解数据的组织方式，而非存储细节。 每个索引被分成了多个段(Segment)，段具有一次写入，多次读取的特点。只要形成了，段就无法被修改。例如：被删除文档的信息被存储到一个单独的文件，但是其它的段文件并没有被修改。 需要注意的是，多个段是可以合并的，这个合并的过程称为segments merge。经过强制合并或者Lucene的合并策略触发的合并操作后，原来的多个段就会被Lucene创建的更大的一个段所代替了。很显然，段合并的过程是一个I/O密集型的任务。这个过程会清理一些信息，比如会删除.del文件。除了精减文件数量，段合并还能够提高搜索的效率，毕竟同样的信息，在一个段中读取会比在多个段中读取要快得多。但是，由于段合并是I/O密集型任务，建议不好强制合并，小心地配置好合并策略就可以了。 分析你的文本问题到这里就变得稍微复杂了一些。传入到Document中的数据是如何转变成倒排索引的？查询语句是如何转换成一个个Term使高效率文本搜索变得可行？这种转换数据的过程就称为文本分析(analysis) 文本分析工作由analyzer组件负责。analyzer由一个分词器(tokenizer)和0个或者多个过滤器(filter)组成,也可能会有0个或者多个字符映射器(character mappers)组成。 Lucene中的tokenizer用来把文本拆分成一个个的Token。Token包含了比较多的信息，比如Term在文本的中的位置及Term原始文本，以及Term的长度。文本经过tokenizer处理后的结果称为token stream。token stream其实就是一个个Token的顺序排列。token stream将等待着filter来处理。 除了tokenizer外，Lucene的另一个重要组成部分就是filter链，filter链将用来处理Token Stream中的每一个token。这些处理方式包括删除Token,改变Token，甚至添加新的Token。Lucene中内置了许多filter，读者也可以轻松地自己实现一个filter。有如下内置的filter： Lowercase filter：把所有token中的字符都变成小写 ASCII folding filter：去除tonken中非ASCII码的部分 Synonyms filter：根据同义词替换规则替换相应的token Multiple language-stemming filters：把Token(实际上是Token的文本内容)转化成词根或者词干的形式。 所以通过Filter可以让analyzer有几乎无限的处理能力：因为新的需求添加新的Filter就可以了。 索引和查询在我们用Lucene实现搜索功能时，也许会有读者不明觉历：上述的原理是如何对索引过程和搜索过程产生影响？ 索引过程：Lucene用用户指定好的analyzer解析用户添加的Document。当然Document中不同的Field可以指定不同的analyzer。如果用户的Document中有title和description两个Field，那么这两个Field可以指定不同的analyzer。 搜索过程：用户的输入查询语句将被选定的查询解析器(query parser)所解析,生成多个Query对象。当然用户也可以选择不解析查询语句，使查询语句保留原始的状态。在ElasticSearch中，有的Query对象会被解析(analyzed)，有的不会，比如：前缀查询(prefix query)就不会被解析，精确匹配查询(match query)就会被解析。对用户来说，理解这一点至关重要。 对于索引过程和搜索过程的数据解析这一环节，我们需要把握的重点在于：倒排索引中词应该和查询语句中的词正确匹配。如果无法匹配，那么Lucene也不会返回我们喜闻乐见的结果。举个例子：如果在索引阶段对文本进行了转小写(lowercasing)和转变成词根形式(stemming)处理，那么查询语句也必须进行相同的处理，不然就搜索结果就会是竹篮打水——一场空。 Lucence查询语言ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。由于这个原因，我们来深入学习Lucene查询语言，了解其庐山真面目吧。 基础语法用户使用Lucene进行查询操作时，输入的查询语句会被分解成一个或者多个Term以及逻辑运算符号。一个Term，在Lucene中可以是一个词，也可以是一个短语(用双引号括引来的多个词)。如果事先设定规则：解析查询语句，那么指定的analyzer就会用来处理查询语句的每个term形成Query对象。 一个Query对象中会存在多个布尔运算符，这些布尔运算符将多个Term关联起来形成查询子句。布尔运算符号有如下类型： AND(与):给定两个Term(左运算对象和右运算对象)，形成一个查询表达式。只有两个Term都匹配成功，查询子句才匹配成功。比如：查询语句”apache AND lucene”的意思是匹配含apache且含lucene的文档。 OR(或):给定的多个Term，只要其中一个匹配成功，其形成的查询表达式就匹配成功。比如查询表达式”apache OR lucene”能够匹配包含“apache”的文档，也能匹配包含”lucene”的文档，还能匹配同时包含这两个Term的文档。 NOT(非): 这意味着对于与查询语句匹配的文档，NOT运算符后面的Term就不能在文档中出现的。例如：查询表达式“lucene NOT elasticsearch”就只能匹配包含lucene但是不含elasticsearch的文档。 此外，我们也许会用到如下的运算符： +这个符号表明：如果想要查询语句与文档匹配，那么给定的Term必须出现在文档中。例如：希望搜索到包含关键词lucene,最好能包含关键词apache的文档，可以用如下的查询表达式：”+lucene apache”。 -这个符号表明：如果想要查询语句与文档匹配，那么给定的Term不能出现在文档中。例如：希望搜索到包含关键词lucene,但是不含关键词elasticsearch的文档，可以用如下的查询表达式：”+lucene -elasticsearch”。 如果在Term前没有指定运算符，那么默认使用OR运算符。此外，也是最后一点：查询表达式可以用小括号组合起来，形成复杂的查询表达式。比如：elasticsearch AND (mastering OR book) 多域查询当然，跟ElasticSearch一样，Lucene中的所有数据都是存储在一个个的Field中，多个Field形成一个Document。如果希望查询指定的Field,就需要在查询表达式中指定Field Name(此域名非彼域名)，后面接一个冒号，紧接着一个查询表达式。例如：查询title域中包含关键词elasticsearch的文档，查询表达式如下： title:elasticsearch也可以把多个查询表达式用于一个域中。例如：查询title域中含关键词elasticsearch并且含短语“mastering book”的文档，查询表达式如下： title:(+elasticsearch +”mastering book”)当然，也可以换一种写法，作用是一样的： +title:elasticsearch +title:”mastering book”) 词语修饰符除了可以应用简单的关键词和查询表达式实现标准的域查询，Lucene还支持往查询表达式中传入修饰符使关键词具有变形能力。最常用的修饰符，也是大家都熟知的，就是通配符。Lucene支持?和*两种通配符。?可以匹配任意单个字符，而*能够匹配多个字符。 请注意出于性能考虑，默认的通配符不能是关键词的首字母。 此外，Lucene支持模糊查询(fuzzy query)和邻近查询(proximity query)。语法规则是查询表达式后面接一个~符号，后面紧跟一个整数。如果查询表达式是单独一个Term，这表示我们的搜索关键词可以由Term变形(替换一个字符，添加一个字符，删除一个字符)而来，即与Term是相似的。这种搜索方式称为模糊搜索(fuzzy search)。在~符号后面的整数表示最大编辑距离。例如：执行查询表达式 “writer~2”能够搜索到含writer和writers的文档。 当~符号用于一个短语时，~后面的整数表示短语中可接收的最大的词编辑距离(短语中替换一个词，添加一个词，删除一个词)。举个例子,查询表达式title:”mastering elasticsearch”只能匹配title域中含”mastering elasticsearch”的文档，而无法匹配含”mastering book elasticsearch”的文档。但是如果查询表达式变成title:”mastering elasticsearch”~2,那么两种文档就都能够成功匹配了。 此外，我们还可以使用加权(boosting)机制来改变关键词的重要程度。加权机制的语法是一个^符号后面接一个浮点数表示权重。如果权重小于1，就会降低关键词的重要程度。同理，如果权重大于1就会增加关键词的重要程度。默认的加权值为1。可以参考 第2章 活用用户查询语言 的 Lucene默认打分规则详解 章节部分的内容来了解更多关于加权(boosting)是如何影响打分排序的。 除了上述的功能外，Lucene还支持区间查询(range searching),其语法是用中括号或者}表示区间。例如：如果我们查询一个数值域(numeric field)，可以用如下查询表达式： price:[10.00 TO 15.00] 这条查询表达式能查询到price域的值在10.00到15.00之间的所有文档。对于string类型的field，区间查询也同样适用。例如： name:[Adam TO Adria] 这条查询表达式能查询到name域中含关键词Adam到关键词Adria之间关键词(字符串升序，且闭区间)的文档。如果希望区间的边界值不会被搜索到，那么就需要用大括号替换原来的中括号。例如，查询price域中价格在10.00(10.00要能够被搜索到)到15.00(15.00不能被搜索到)之间的文档，就需要用如下的查询表达式： price:[10.00 TO 15.00} 处理特殊字符 如果在搜索关键词中出现了如下字符集合中的任意一个字符，就需要用反斜杠(\\)进行转义。字符集合如下： +, -, &amp;&amp;, || , ! , (,) , { } , [ ] , ^, “ , ~, *, ?, : , \\, / 。例如，查询关键词 abc”efg 就需要转义成 abc\\”efg。","categories":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/tags/搜索引擎/"},{"name":"apache lucene","slug":"apache-lucene","permalink":"http://hopperclouds.github.io/tags/apache-lucene/"}],"keywords":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"http://hopperclouds.github.io/categories/搜索引擎/"}]},{"title":"从__str__说开去","slug":"从__str__说开去","date":"2016-08-31T08:00:00.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/08/31/从__str__说开去/","link":"","permalink":"http://hopperclouds.github.io/2016/08/31/从__str__说开去/","excerpt":"","text":"__str__ 和 __repr__介绍object.__str__是python中一个常见的特殊方法, 会被内置函数被 str 和 print 调用。常常与它一起出现的还有object.__repr__, 类似地, 它会被内置函数 repr 调用。 区别那么 str 和 repr 同样作为”informal string representation of instances”, 有何区别? 用一句话概括就是: repr is for developers, str is for customers. 这点在IDE中调试时得以展现: 123456789101112131415class Student(object): def __init__(self, name, grade): self.name = name self.grade = grade def __str__(self): return '&#123;0&#125;(&#123;1&#125;)'.format(self.name, self.grade) def __repr__(self): return '&lt;Student&gt;'if __name__ == '__main__': student = Student(name='Roy', grade=11) 在debug模式下, pycharm将 student 展示为: 简洁明了。 __unicode__出场率同样高的还有object.__unicode__, 和object.__str__作用类似, 但不同的是, object.__unicode__ 返回的是一个unicode object, 而 object.__str__ 返回的是string object。这会引起一些问题, 特别是当你在使用python2中的unicode_literals时。 unicode_literalsUnicodeEncodeError我们对上面的代码做一些修改: 1234567891011121314151617# -*- coding: utf-8 -*-from __future__ import unicode_literalsclass Student(object): def __init__(self, name, grade): self.name = name self.grade = grade def __str__(self): return '&#123;0&#125;(&#123;1&#125;)'.format(self.name, self.grade) def __repr__(self): return '&lt;Student&gt;' def __unicode__(self): return '&lt;Student&gt;' 改动在于import了unicode_literals, 并为 Student 添加了一个 __unicode__ 方法, 看起来好像没有什么问题。 但当你实例化一个 Student , 并将 name 指定为中文时: 12student = Student(name='罗伊', grade=11)print student 报错了, UnicodeEncodeError 。 你或许精通python2的中文编码问题, 但也许并没有注意到这个问题。在使用django时遇到过 [Bad Unicode data] 这个东西, 问题是一样的, django在项目中也使用了 unicode_literals 。 问题在哪问题在于 object.__str__ 返回的必须为string object, 而使用 unicode_literals 之后返回的为unicode object, python2解释器会尝试用默认的编码(ascii)对其进行encode, 所以报错。 解决问题unicode_literals 在python2中是个利器, 不能不用。接下来我们用两种方法来解决上面这个问题。 patch这是一种经典的方法: 123import sysreload(sys)sys.setdefaultencoding('utf8') 重载 sys 并将 defaultencoding 从 ascii 修改为 utf-8 , 对含中文的unicode object使用utf-8进行encode是可行的。 装饰器123456789def force_encoded_string_output(func): if sys.version_info.major &lt; 3: def _func(*args, **kwargs): return func(*args, **kwargs).encode('utf-8') return _func else: return func 使用 force_encoded_string_output 装饰 object.__str__ 即可, 解决的思路和上面类似。 最佳实践当你在python2中同时使用中文, unicode_literals, __str__, __unicode__ 可以考虑下面的方式: 123456789101112from __future__ import unicode_literalsclass Best(object): def __str__(self): return unicode(self).encode('utf-8') def __unicode__(self): s = 'Put your data here.' assert isinstance(s, unicode) return s","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://hopperclouds.github.io/tags/python/"},{"name":"str","slug":"str","permalink":"http://hopperclouds.github.io/tags/str/"},{"name":"unicode_literals","slug":"unicode-literals","permalink":"http://hopperclouds.github.io/tags/unicode-literals/"},{"name":"Kxrr","slug":"Kxrr","permalink":"http://hopperclouds.github.io/tags/Kxrr/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"前端入门之我见","slug":"前端入门之我见","date":"2016-08-30T14:48:37.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2016/08/30/前端入门之我见/","link":"","permalink":"http://hopperclouds.github.io/2016/08/30/前端入门之我见/","excerpt":"","text":"作者：Adam at 2016-08-30 22:48:37 这两周陆陆续续进行了两个独立的前端项目，一个是前后端分离的Angular项目，一个是ES6+Nodejs的全栈项目，前者先做，后者差不多刚完成，最明显的感觉就是写了Angular不想写JQuery，写了ES6不想写ES5。 我就在想，为什么会有这么强烈感觉？是什么导致的？ 首先，我们来看看前端主要做什么？ 一是页面：HTML+CSS样式布局；二是Javascript脚本：根据页面事件响应、控制页面逻辑。 就这么简单。 然后，CSS样式多了，Javascript函数多了，我们就希望代码好维护，方便调用，少写代码，于是就出现了各种CSS／Javascript框架。 随之而来的问题也出现了，逻辑变复杂，这就需要我们把注释要写清楚，甚至完全文档化。 Javascript写法太自由了，写出来效果往往容易有bug，加上不同浏览器的、不同终端的折腾，好吧，我们把单元测试、界面测试补上，这下总可以了吧。 但是，问题并没有结束。 我们开始思考Javascript是否真的适合写前端页面，为什么Javascript写大型项目这么痛苦？为什么要不断重复写写登录注册？为什么要离不开for循环？为什么不能尽可能高的重用代码？ 我们很早就在说OOP、MVC，也有现在的MVVM、SAM，也出了不少经典框架，但Javascript始终还是Javascript，没有class，没有isArray，只有说不清道不明的 prototype 和 __proto__ 。既然我们知道什么样的语法简洁高效，为什么不让Javascript也能这么做呢？所以，Type Script出来了，Webpack/Babel出来了，ES6出来了。 所以，如果现在你想学前端，直接写ES6吧，有了webpack和babel，以前能做的现在都能做，现在能做的，以前不一定能做。 如今前端也再也不是写写页面、做做脚本，不再是网页三剑客的时代。你还需要精通Sublime/Vim这些编辑器，会架构前端开发环境、熟悉Nodejs/NPM，掌握Phantomjs/Jasmine等测试手段，会用JsDoc写文档。当然，最重要的还是要学好ES6。 最后，我总结一下我学习ES6后，发现的一些好处，希望和大家多交流、沟通～ OOP的原配Class，写起来的酸爽倍儿棒只有自己知道 模块化导入，让我可以前后端共享代码 函数参数的扩展是我的最爱，直接让我轻松20% 代码密集度明显好于过去，这是密集恐惧症的福音 Webpack无疑是前端开发自动化的必备神器，你值得拥有～ 你不再需要模版语言，ES6就是最好的模版语言 一切皆Js，HTML是，CSS也是","categories":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}],"tags":[{"name":"ES6","slug":"ES6","permalink":"http://hopperclouds.github.io/tags/ES6/"},{"name":"Webpack","slug":"Webpack","permalink":"http://hopperclouds.github.io/tags/Webpack/"},{"name":"经验总结","slug":"经验总结","permalink":"http://hopperclouds.github.io/tags/经验总结/"}],"keywords":[{"name":"blog","slug":"blog","permalink":"http://hopperclouds.github.io/categories/blog/"}]},{"title":"聘宝招聘Python实习生","slug":"聘宝招聘Python实习生","date":"2015-09-29T02:51:04.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/29/聘宝招聘Python实习生/","link":"","permalink":"http://hopperclouds.github.io/2015/09/29/聘宝招聘Python实习生/","excerpt":"公司情况现在主要做的产品是 http://www.pinbot.me/ ,已经拿到A轮 坐标：四川成都高新区府城大道399天府新谷9号楼二单元1505成都浩泊云动科技有限公司","text":"公司情况现在主要做的产品是 http://www.pinbot.me/ ,已经拿到A轮 坐标：四川成都高新区府城大道399天府新谷9号楼二单元1505成都浩泊云动科技有限公司 我们的研发团队喜欢什么 K.I.S.S 敏捷开发，快速原型和必要的单元测试 使用*nix 有创造性思维，喜欢创造的人 函数式编程和各种高并发的编程语言（Scheme、Clojure、Golang、Elixir） 为什么招实习生成都Python的圈子本来就小，看来看去就那么些人，大牛实在难搞定，所以希望找到一些有兴趣往Python方向发展的人，一起成长。 在这里你能做什么 了解到Python Web开发常用的工具和流程规范 做一些真正有人使用的产品 一起建设团队，给团队带来更高效的流程和工具 做自己想做的产品，如果你有好的创意都可以跟我们产品经理沟通，将创意实现到产品中 我们能提供什么 Mac和双显是我们日常的开发工具 每周免费的零食 技术分享 每月一次的Hack Day 妹子都是女神级别的，养眼提高工作效率 工作描述 负责http://www.pinbot.me/ 网站新功能的开发和日常维护 负责内部CRM管理系统的开发维护 技能要求# coding: utf-8 &quot;&quot;&quot; 对以下技术熟悉或者有强烈兴趣 &quot;&quot;&quot; # 基本技能 BASIC_SKILL = [ &apos;*nix&apos;, &apos;Vim or Emacs&apos;, &apos;Git&apos;, &apos;Unix哲学&apos;, &apos;基础算法和数据结构&apos;, &apos;计算机组成原理&apos;, &apos;网路协议&apos;, ] # 后端技能 BACKEND_SKILL = [ &apos;Python&apos;, &apos;Django&apos;, &apos;Python常用库&apos;, &apos;了解Http 协议&apos;, &apos;NodeJS&apos;, ] # 前端技能 FRONTEND_SKILL = [ &apos;HTML&apos;, &apos;CSS&apos;, &apos;JS&apos;, &apos;AngularJS&apos;, &apos;React&apos;, &apos;JQuery&apos;, ] # 运维 MAINTAIN_SKILL = [ &apos;bash&apos;, &apos;Docker&apos;, &apos;Fabric&apos;, &apos;Ansible&apos;, &apos;SaltStack&apos;, ] # 数据库 DATABASE = [ &apos;MySQL&apos;, &apos;Mongo&apos;, ] ALL_SKILL = set(i.lower() for i in (BASIC_SKILL + BACKEND_SKILL + FRONTEND_SKILL + MAINTAIN_SKILL + DATABASE)) def i_want_you(your_skill): &quot;&quot;&quot; 符合以上任意关键词就可以了 后续可以让我们的算法工程师来做一个测试程序 &gt;&gt;&gt; i_want_you(&apos;Python HTML Docker MySQL&apos;) I want you &gt;&gt;&gt; i_want_you(&apos;java&apos;) hehe &quot;&quot;&quot; your_skill = [i.lower() for i in your_skill.split()] print &apos;I want you&apos; if set(your_skill).intersection(ALL_SKILL) else &apos;hehe&apos; if __name__ == &apos;__main__&apos;: your_skill = raw_input(&apos;Input your skill: &apos;) i_want_you(your_skill) 补充 有github或者bitbucket等开源社区账号优先 有自己博客的优先 联系我简历请投至：dengyu@hopperclouds.com","categories":[{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/categories/招聘/"}],"tags":[{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/tags/招聘/"},{"name":"Python","slug":"Python","permalink":"http://hopperclouds.github.io/tags/Python/"}],"keywords":[{"name":"招聘","slug":"招聘","permalink":"http://hopperclouds.github.io/categories/招聘/"}]},{"title":"聘宝研发团队必备技能","slug":"聘宝研发团队必备技能","date":"2015-09-24T08:09:24.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/24/聘宝研发团队必备技能/","link":"","permalink":"http://hopperclouds.github.io/2015/09/24/聘宝研发团队必备技能/","excerpt":"简介聘宝(www.pinbot.me) 立志做新一代的智能猎头，让企业招聘变得更简单，我们崇尚敏捷，崇尚开源，崇尚K.I.S.S","text":"简介聘宝(www.pinbot.me) 立志做新一代的智能猎头，让企业招聘变得更简单，我们崇尚敏捷，崇尚开源，崇尚K.I.S.S Web研发团队必备技能后端技术Python (我们主要使用的后端语言) Django (我们正在使用的框架) Python常用库(celery, requests, json, bs4...) HTTP协议 (这个必须会) Unit Test (知道什么地方要有测试) 前端技术HTML Javascript (Node是一个趋势，所以必须会) CSS Angular.js React.js 数据库Mysql Mongo Redis 明确知道不同类型数据库的应用场景，了解数据的设计范式和调优 消息队列RabbitMQ 运维相关Docker (很多东西正在尝试用docker去完成，确实很方便) Ansible (服务器配置管理) 开发环境*nix (必须会，不喜欢windows) VIM (运维要用，必须会) Emacs (看个人爱好) Git及Git开发流程 (必须会) 文档markdown rst 职业素养1. 独立思考，好学 2. 沟通能力强 3. 了解Python哲学 4. 读过程序员修炼之道和代码整洁之道等必读书籍 5. 对程序设计有自己的追求 6. 了解软件工程的思想 推荐技术Golang、Clojure(并发是以后的趋势) 函数式编程语言（可能也是以后的趋势） elixir (聘宝会考虑用它做东西) 总结这个是我们团队的后端必备技能，欢迎大家在评论中补充","categories":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://hopperclouds.github.io/tags/javascript/"},{"name":"Python","slug":"Python","permalink":"http://hopperclouds.github.io/tags/Python/"},{"name":"运维","slug":"运维","permalink":"http://hopperclouds.github.io/tags/运维/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"http://hopperclouds.github.io/categories/技术/"}]},{"title":"使用Hexo作为博客","slug":"使用Hexo作为博客","date":"2015-09-24T07:29:25.000Z","updated":"2016-09-08T11:31:22.000Z","comments":true,"path":"2015/09/24/使用Hexo作为博客/","link":"","permalink":"http://hopperclouds.github.io/2015/09/24/使用Hexo作为博客/","excerpt":"安装和部署请参考下面或自行google 官网 http://wsgzao.github.io/post/hexo-guide/","text":"安装和部署请参考下面或自行google 官网 http://wsgzao.github.io/post/hexo-guide/ 基本使用准备# 安装node 和 cnpm brew install node npm install cnpm -g # 将项目clone 下来 git clone git@github.com:HopperClouds/hopperclouds.github.io.git # 安装hexo 依赖的node库 cnpm install # 遇到问题 # { [Error: Cannot find module &apos;./build/Release/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # { [Error: Cannot find module &apos;./build/default/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # { [Error: Cannot find module &apos;./build/Debug/DTraceProviderBindings&apos; ] code: &apos;MODULE_NOT_FOUND&apos; } # 使用 cnpm install --no-optional 开始写文章hexo new &quot;your title&quot; # 在source/_posts/your\\ title.md 文件 # 在里面使用markdown编辑博客 # 生成文件格式 title: 使用Hexo作为博客 date: 2015-09-24 15:29:25 # 类别 categories: - 其他 # 标签 tags: - 其他 - 开始 --- markdown格式正文内容 生成文章hexo generate # 使用--watch 参数检测文件更新 hexo generate --watch 预览hexo server 发布hexo deploy 将markdown源码push到source分支git push origin master:source 总结静态博客才是写博客的正确姿势 初次使用觉得不像octopress 那样完善，至于为什么不用octopress, 是因为我们是使用Python和JS的团队，Node对我们来说更友好一些。 对于使用Emacs的用户还没有org mode支持，可以hack一下了。","categories":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/categories/其他/"}],"tags":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/tags/其他/"},{"name":"开始","slug":"开始","permalink":"http://hopperclouds.github.io/tags/开始/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"http://hopperclouds.github.io/categories/其他/"}]}]}